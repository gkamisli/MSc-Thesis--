{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Explanation\n",
    "\n",
    "**trainRNN_HBTRC_AttentionModel_dropout.ipynb:**\n",
    "<br> This notebook is to load HBTRC examples from 'preprocessData_HBTRC.pickle', create an \"Attention Network\" and train the network with respect to a range of dropout rates\n",
    "\n",
    "**Processes are as follows:**\n",
    "<br> 1) Load all variables from 'preprocessData_HBTRC.pickle'\n",
    "<br> 2) Parameter and hyperparameter assignments (location: **3rd cell**)\n",
    "<br> 3) Create LSTM cells with Dropout Wrappers for gene A and gene B (function: **dropoutWrapper** in **trainRNN_network_utils.py**)\n",
    "<br> 4) Using LSTM cells, create multi-layer dynamic model from fixed length sequences (function: **dynamicLSTM_Attention** in **trainRNN_network_utils.py**)\n",
    "<br> 5) Create an attention mechanism based on a fully-connected layer of states and output, which is followed by a tanh layer to calculate scores. Then, calculate attention weights and context vector using softmax and dense layers \n",
    "<br> 6) Create a single output from a concatenation of context vectors of gene A and gene B\n",
    "<br> 7) Pass the output through a **dense** layer and make prediction\n",
    "<br> 8) Before starting the training: concatenate rSnpG_tr_nXSN and rRnaG_nXS where G represents gene A and gene B (function: **input_reshape** in **trainRNN_utils.py**)\n",
    "<br> 9) Train the network: every epoch (i.e., iteration) shuffle the data within each class (function: **shuffle_classes** in **trainRNN_utils.py**) and train in batches (function: **extract_batch_size** in **trainRNN_utils.py**)\n",
    "<br> 10) Plot results with **plot_inputs** in **trainRNN_plot_utils.py**)\n",
    "<br> 11) Save them in \"resultsAttentionDropout_HBTRC.pickle\" to be called when necessary\n",
    "\n",
    "**Variables created:**\n",
    "<br> 1) **trainLosses**: Train losses, dictionary, keys of ([0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "<br> 2) **testLosses**: Test losses, dictionary, keys of ([0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "<br> 3) **F1_scores**: F1_scores, dictionary, keys of ([0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "<br> 4) **trainAccuracy**: Train accuracy, dictionary, keys of ([0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "<br> 5) **attention_matrixA**: Attention weights of gene A, dictionary, keys of ([0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "<br> 6) **attention_matrixB**: Attention weights of gene B, dictionary, keys of ([0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "<br> 7) **tst_prediction**: Test predictions, dictionary, keys of ([0.4, 0.5, 0.6, 0.7, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.core.debugger import set_trace #set_trace()\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[ \"CUDA_VISIBLE_DEVICES\" ] = \"3\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from pickle.\n",
      "All samples loaded\n",
      "Number of training samples (transcripts) of gene A: 1500\n",
      "Number of training samples (transcripts) of gene B: 1500\n",
      "Number of test samples (transcripts) of gene A: 45\n",
      "Number of test samples (transcripts) of gene B: 45\n",
      "Number of subjects iSnum: 434\n",
      "Number of SNPs iNnum: 100\n",
      "Number of association classes iCnum: 3\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "# Load data form the pickle produced by \"preprocessData_HBTRC.ipynb\"\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('preprocessData_HBTRC.pickle', 'rb') as f:\n",
    "    rSnpA_nXSN = pickle.load( f )\n",
    "    rSnpB_nXSN = pickle.load( f )\n",
    "    rRnaA_nXS = pickle.load( f )\n",
    "    rRnaB_nXS = pickle.load( f )\n",
    "    rRelated_nXC = pickle.load( f )\n",
    "    rSnpA_tr_nXSN = pickle.load( f )\n",
    "    rSnpB_tr_nXSN = pickle.load( f )\n",
    "    rRnaA_tr_nXS = pickle.load( f )\n",
    "    rRnaB_tr_nXS = pickle.load( f )\n",
    "    rRelated_tr_nXC = pickle.load( f )\n",
    "    rSnpA_tst_nXSN = pickle.load( f )\n",
    "    rSnpB_tst_nXSN = pickle.load( f )\n",
    "    rRnaA_tst_nXS = pickle.load( f )\n",
    "    rRnaB_tst_nXS = pickle.load( f )\n",
    "    rRelated_tst_nXC = pickle.load( f )\n",
    "    sGeneNames_nX2 = pickle.load( f )\n",
    "    sGeneNames_tr_nX2 = pickle.load( f )\n",
    "    sGeneNames_tst_nX2 = pickle.load( f )\n",
    "    nRs = pickle.load( f )\n",
    "    nSs = pickle.load( f )\n",
    "    print( 'Data loaded from pickle.' )\n",
    "\n",
    "\n",
    "# Check the input dimensions\n",
    "assert( len( rSnpA_nXSN.shape ) == 3 )\n",
    "assert( len( rSnpB_nXSN.shape ) == 3 )\n",
    "assert( len( rRnaA_nXS.shape ) == 2 )\n",
    "assert( len( rRnaB_nXS.shape ) == 2)\n",
    "assert( len( rRelated_nXC.shape ) == 2 )\n",
    "assert( len( rSnpA_tr_nXSN.shape ) == 3 )\n",
    "assert( len( rSnpB_tr_nXSN.shape ) == 3 )\n",
    "assert( len( rRnaA_tr_nXS.shape ) == 2 )\n",
    "assert( len( rRnaB_tr_nXS.shape ) == 2 )\n",
    "assert( len( rRelated_tr_nXC.shape ) == 2 )\n",
    "assert( len( rSnpA_tst_nXSN.shape ) == 3 )\n",
    "assert( len( rSnpB_tst_nXSN.shape ) == 3 )\n",
    "assert( len( rRnaA_tst_nXS.shape ) == 2 )\n",
    "assert( len( rRnaB_tst_nXS.shape ) == 2 )\n",
    "assert( len( rRelated_tst_nXC.shape ) == 2)\n",
    "assert( rSnpA_nXSN.shape[ 0 ] == rRnaA_nXS.shape[0] )\n",
    "assert( rSnpA_nXSN.shape[ 0 ] == rRnaB_nXS.shape[0] )\n",
    "assert( rSnpB_nXSN.shape[ 0 ] == rRnaA_nXS.shape[0] )\n",
    "assert( rSnpB_nXSN.shape[ 0 ] == rRnaB_nXS.shape[0] )\n",
    "assert( rSnpA_nXSN.shape[ 0 ] == rRelated_nXC.shape[ 0 ] )\n",
    "assert( rSnpA_nXSN.shape[ 1 ] == rRnaA_nXS.shape[ 1 ] )\n",
    "assert( rSnpB_nXSN.shape[ 1 ] == rRnaB_nXS.shape[ 1 ] )\n",
    "assert( rRelated_nXC.shape[ 1 ] == 3 )\n",
    "\n",
    "iSnum = rSnpA_nXSN.shape[ 1 ] # Number of subjects\n",
    "iNnum = rSnpA_nXSN.shape[ 2 ] # Number of snps\n",
    "iCnum = rRelated_nXC.shape[ 1 ] # Number of classes\n",
    "\n",
    "print('All samples loaded' )\n",
    "print('Number of training samples (transcripts) of gene A: {}'.format( rSnpA_tr_nXSN.shape[ 0 ] ) )\n",
    "print('Number of training samples (transcripts) of gene B: {}'.format( rSnpB_tr_nXSN.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene A: {}'.format( rSnpA_tst_nXSN.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene B: {}'.format( rSnpB_tst_nXSN.shape[ 0 ] ) )\n",
    "print('Number of subjects iSnum: {}'.format( rSnpA_nXSN.shape[ 1 ] ) )\n",
    "print('Number of SNPs iNnum: {}'.format( rSnpA_nXSN.shape[ 2 ] ) )\n",
    "print('Number of association classes iCnum: {}'.format( rRelated_nXC.shape[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "## Input data\n",
    "time_steps = iNnum + 1                              # number of snps + number of rnas\n",
    "n_input = iSnum                                     # number of subjects\n",
    "\n",
    "## LSTM's internal structure\n",
    "n_hidden = 32                                       # number of nodes in hidden layer \n",
    "n_classes = iCnum                                   # number of classes\n",
    "n_layer = 3                                         # number of layers\n",
    "dropouts = [0.4, 0.5, 0.6, 0.7, 0.8]                # dropout percentage\n",
    "\n",
    "## Training data\n",
    "learning_rate = 0.001\n",
    "batch_size = 150\n",
    "n_epoch = 200\n",
    "n_batch = rSnpA_tr_nXSN.shape[0] // batch_size   # number of batches\n",
    "lambda_l2_reg = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/HBTRC/trainRNN_network_utils.py:15: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/HBTRC/trainRNN_network_utils.py:70: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/HBTRC/trainRNN_network_utils.py:74: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/HBTRC/trainRNN_network_utils.py:99: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:1472: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:2176: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.1375489234924316: Accuracy = 0.4333333373069763\n",
      "Performance on test set: : Loss = 1.1500471830368042: Accuracy = 0.6436781630457463\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.1392288208007812: Accuracy = 0.4333333373069763\n",
      "Performance on test set: : Loss = 1.154417634010315: Accuracy = 0.5584677646575607\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.1148695945739746: Accuracy = 0.4266666769981384\n",
      "Performance on test set: : Loss = 1.1747138500213623: Accuracy = 0.5298558751318327\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.0925726890563965: Accuracy = 0.4399999976158142\n",
      "Performance on test set: : Loss = 1.154104471206665: Accuracy = 0.5175983371934043\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.0464141368865967: Accuracy = 0.47999998927116394\n",
      "Performance on test set: : Loss = 1.1845983266830444: Accuracy = 0.5157284565807678\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 1.1127967834472656: Accuracy = 0.3933333456516266\n",
      "Performance on test set: : Loss = 1.2017419338226318: Accuracy = 0.5143449654625009\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 1.007421851158142: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.1707894802093506: Accuracy = 0.5061102748310067\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 0.9968542456626892: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.1680223941802979: Accuracy = 0.4925768872051963\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 0.9958880543708801: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.2599607706069946: Accuracy = 0.4850071585368798\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.8581019043922424: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.208319067955017: Accuracy = 0.47699288384252736\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.8166647553443909: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.321294903755188: Accuracy = 0.4600882613431248\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.7759262323379517: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.397126317024231: Accuracy = 0.43578154818303344\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.8659114837646484: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.302215576171875: Accuracy = 0.4196570633763386\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.64239102602005: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.481998324394226: Accuracy = 0.41867372180787116\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.6928339600563049: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.4361085891723633: Accuracy = 0.4169118717514362\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 0.6475006937980652: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.0966510772705078: Accuracy = 0.425224183806371\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.5989198684692383: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.1271843910217285: Accuracy = 0.4306141558825301\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.6454047560691833: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.519550085067749: Accuracy = 0.4358347090532\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.5583885908126831: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.196353793144226: Accuracy = 0.44587533517041944\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.6130990982055664: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.689332127571106: Accuracy = 0.4539284844272079\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.5628460645675659: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.3389333486557007: Accuracy = 0.4620080603813047\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.5682401061058044: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.405585527420044: Accuracy = 0.4693433027543568\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.5676937103271484: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.5325535535812378: Accuracy = 0.4793926328625802\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.5458856821060181: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.2177075147628784: Accuracy = 0.4865017836969038\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.5237762331962585: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.186361312866211: Accuracy = 0.49573725525829027\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.5737118124961853: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.420042634010315: Accuracy = 0.5018919870197547\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.5539178252220154: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.2304251194000244: Accuracy = 0.5064463283169546\n",
      "\n",
      "Data shuffled. Epoch:  27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.5634247660636902: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.2634577751159668: Accuracy = 0.5124543874751611\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.5305390357971191: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.8670077323913574: Accuracy = 0.5188571317299855\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.5252467393875122: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.5677350759506226: Accuracy = 0.5229007758838163\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.5284802317619324: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.3484827280044556: Accuracy = 0.5270988614258805\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.5279062986373901: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.6393933296203613: Accuracy = 0.5324941548591345\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.5150183439254761: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.584202527999878: Accuracy = 0.5367919433467134\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.5006900429725647: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.6304384469985962: Accuracy = 0.5408901383172899\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.5228906869888306: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.3681466579437256: Accuracy = 0.5447209700484504\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.5247212648391724: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.4940985441207886: Accuracy = 0.5480277048131719\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.5259078741073608: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.6318118572235107: Accuracy = 0.5506669739982102\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.5268917083740234: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.2437937259674072: Accuracy = 0.5532035957231908\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.5072208046913147: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.3388359546661377: Accuracy = 0.5552480179790427\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.5083192586898804: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.7466294765472412: Accuracy = 0.558828284423799\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.5206269025802612: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.7586549520492554: Accuracy = 0.5608476896614936\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.522641122341156: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.6232935190200806: Accuracy = 0.5632924619434553\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.48437729477882385: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.527985692024231: Accuracy = 0.5655578229604887\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.5056958794593811: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.5285829305648804: Accuracy = 0.5673385652877375\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.5043792724609375: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.5801551342010498: Accuracy = 0.5693236512973895\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.5143654942512512: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.5610077381134033: Accuracy = 0.5704595028343884\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.4915485680103302: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.6707791090011597: Accuracy = 0.5724535388743063\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.4992525279521942: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.8886998891830444: Accuracy = 0.5732710839259046\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.4861678183078766: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.7760945558547974: Accuracy = 0.5743902147080059\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.526638925075531: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.0410876274108887: Accuracy = 0.5753296140371142\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.5028130412101746: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.5611367225646973: Accuracy = 0.5764681346525108\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.4828905165195465: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.8728786706924438: Accuracy = 0.5768852468560172\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.47152355313301086: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.961521029472351: Accuracy = 0.5779260071252398\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.48478901386260986: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.466787815093994: Accuracy = 0.5786694502955209\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.481882780790329: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.1880645751953125: Accuracy = 0.5784298701287569\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.48906952142715454: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.5225043296813965: Accuracy = 0.578517423005013\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.5087486505508423: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.2356104850769043: Accuracy = 0.5778623959846028\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.48689138889312744: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.854219913482666: Accuracy = 0.5787583405428866\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.4909115135669708: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.829413890838623: Accuracy = 0.578626795599748\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.4755402207374573: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.029599905014038: Accuracy = 0.5789715925076436\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.4723496437072754: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.5372941493988037: Accuracy = 0.5783468644867434\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.4988899827003479: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.250389814376831: Accuracy = 0.5780692518639758\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.4669041037559509: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.3411498069763184: Accuracy = 0.5782611827963957\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.4633602797985077: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.988495945930481: Accuracy = 0.577996607643656\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.48404866456985474: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.44714093208313: Accuracy = 0.5782437230382965\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.46342921257019043: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 2.2957491874694824: Accuracy = 0.5785753567060994\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.4714408814907074: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.380873203277588: Accuracy = 0.5790192995779692\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.4792611598968506: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.66546893119812: Accuracy = 0.5794597434876774\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.5020779371261597: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.634012460708618: Accuracy = 0.5790464480170087\n",
      "\n",
      "Data shuffled. Epoch:  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.4981778562068939: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.381173610687256: Accuracy = 0.5783338142988379\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.4615168869495392: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.2030656337738037: Accuracy = 0.579048305336212\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.4184589087963104: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.7963625192642212: Accuracy = 0.5788742846290019\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.46648162603378296: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.46749210357666: Accuracy = 0.5786236628522688\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.4371525049209595: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.3281307220458984: Accuracy = 0.5792557051247933\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.4623967111110687: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.0513243675231934: Accuracy = 0.5790502284932405\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.46803203225135803: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 2.2497141361236572: Accuracy = 0.5790091552660012\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.46710845828056335: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.0675158500671387: Accuracy = 0.5790097040863055\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.4629078805446625: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.127288579940796: Accuracy = 0.5781007317707217\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.45741668343544006: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.3253350257873535: Accuracy = 0.5783921601584547\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.4502726197242737: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.404770612716675: Accuracy = 0.5784747102260672\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.4963524341583252: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 2.521782875061035: Accuracy = 0.5784575258682275\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.473062127828598: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.1645374298095703: Accuracy = 0.5783536749225894\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.41266924142837524: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.084794521331787: Accuracy = 0.5784618702006329\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.43782007694244385: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.132300615310669: Accuracy = 0.5786666392348041\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.4126315116882324: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.1489367485046387: Accuracy = 0.5787707725989024\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.4720555543899536: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.5799615383148193: Accuracy = 0.5793090069725999\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.4122585654258728: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.575576066970825: Accuracy = 0.5798288793969604\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.46779826283454895: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 3.082750082015991: Accuracy = 0.5800799206189973\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.5066848993301392: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.179943084716797: Accuracy = 0.5795990325556031\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.43546488881111145: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.22517728805542: Accuracy = 0.5793022853550397\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.4598379135131836: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.314983367919922: Accuracy = 0.5787107921611395\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.4929008483886719: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.3987252712249756: Accuracy = 0.578481691824782\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.45817723870277405: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.175487518310547: Accuracy = 0.5790963264956398\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.4400177597999573: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.6968801021575928: Accuracy = 0.5788624321784089\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.4441455006599426: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.36018443107605: Accuracy = 0.5793692673128208\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.4254944920539856: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.507661819458008: Accuracy = 0.5792750334666759\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.4167397618293762: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.362262010574341: Accuracy = 0.5794607018407958\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.4244515597820282: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.281865358352661: Accuracy = 0.5800950600970067\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.40828168392181396: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.5870351791381836: Accuracy = 0.5803868642177261\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.41974976658821106: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.9141147136688232: Accuracy = 0.5803017731403477\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.40832096338272095: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.113649606704712: Accuracy = 0.580445827657449\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.40283533930778503: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.6577165126800537: Accuracy = 0.5806107553645498\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.4309907555580139: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 2.5387775897979736: Accuracy = 0.5812159696117506\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.42233455181121826: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.62383770942688: Accuracy = 0.5810042071027081\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.4112546145915985: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.6657252311706543: Accuracy = 0.5811992720714586\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.41579103469848633: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.7614567279815674: Accuracy = 0.5810746680930724\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.3793789744377136: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.539541006088257: Accuracy = 0.5816041937358997\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.4346871078014374: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.397524356842041: Accuracy = 0.5817950718993697\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.435555636882782: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.511000633239746: Accuracy = 0.5817028350845511\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.40678492188453674: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.0913758277893066: Accuracy = 0.5820610650332414\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.38334891200065613: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.555055618286133: Accuracy = 0.5825308510290723\n",
      "\n",
      "Data shuffled. Epoch:  111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.40730875730514526: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.5779898166656494: Accuracy = 0.5832498950556083\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.420929878950119: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.635117530822754: Accuracy = 0.5833501491805878\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.3963993787765503: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.4302585124969482: Accuracy = 0.5839046990923339\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.38987284898757935: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.9330735206604004: Accuracy = 0.5848978679338448\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.44735658168792725: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.5845484733581543: Accuracy = 0.5857855813611622\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.44000375270843506: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.9257616996765137: Accuracy = 0.5866549185704808\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.3479848802089691: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.1116793155670166: Accuracy = 0.5871976377649274\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.34446412324905396: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.058964967727661: Accuracy = 0.587586061292208\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.4383774697780609: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.2508721351623535: Accuracy = 0.5882997222858644\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.38872137665748596: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.905015707015991: Accuracy = 0.588764284445724\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.43757736682891846: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.778090476989746: Accuracy = 0.5894609474100854\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.39365991950035095: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.0935750007629395: Accuracy = 0.589839197663301\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.45573243498802185: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.6537678241729736: Accuracy = 0.5899978743085753\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.3614887297153473: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.9189367294311523: Accuracy = 0.5902995681434385\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.3810846209526062: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.340886116027832: Accuracy = 0.590727144785651\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.3820410966873169: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.8600220680236816: Accuracy = 0.591039762130028\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.36157462000846863: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.836758852005005: Accuracy = 0.5914039902070508\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.38416051864624023: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.0871453285217285: Accuracy = 0.5919638993846155\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.4146910309791565: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.2813446521759033: Accuracy = 0.5924420554647735\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.4524453282356262: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.928062915802002: Accuracy = 0.5927831624495449\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.37260857224464417: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.5362720489501953: Accuracy = 0.5934754144706209\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.3574296534061432: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.944392204284668: Accuracy = 0.5940380197012989\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.3541138172149658: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.095287322998047: Accuracy = 0.5944745381142412\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.37115439772605896: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.2192468643188477: Accuracy = 0.5949192398252244\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.3572777509689331: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.122457504272461: Accuracy = 0.5954096171362359\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.3542695641517639: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.844691753387451: Accuracy = 0.5957534701248018\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.3876452147960663: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.852165460586548: Accuracy = 0.5960400555122662\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.35514897108078003: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.255568742752075: Accuracy = 0.5967022286465383\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.3984794616699219: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.591906785964966: Accuracy = 0.5972988832388748\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.339283287525177: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.470512866973877: Accuracy = 0.5978367562778074\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.36939525604248047: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.8848628997802734: Accuracy = 0.5984538799330468\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.4221934378147125: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.917001724243164: Accuracy = 0.5988334505668067\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.4052095413208008: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.0610294342041016: Accuracy = 0.5992628158689016\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.3532784581184387: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.3780672550201416: Accuracy = 0.5998924030155398\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.36026114225387573: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.3831787109375: Accuracy = 0.6005609417595656\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.3554554283618927: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.2396700382232666: Accuracy = 0.6008580523082329\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.35971158742904663: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.9403021335601807: Accuracy = 0.6011776782320982\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.3624188005924225: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.453867197036743: Accuracy = 0.6016631750685213\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.4129101634025574: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.6536295413970947: Accuracy = 0.6023102802363409\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.3960880935192108: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.343289613723755: Accuracy = 0.6026477304731819\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.36358824372291565: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.9825527667999268: Accuracy = 0.6031236307385154\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.38524192571640015: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.8698151111602783: Accuracy = 0.6035481592701802\n",
      "\n",
      "Data shuffled. Epoch:  153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.3717081844806671: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.8267431259155273: Accuracy = 0.6041175846767852\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.39030721783638: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.9620933532714844: Accuracy = 0.6047081757781115\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.35568177700042725: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.969320774078369: Accuracy = 0.6053411617792607\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.37431371212005615: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.926046133041382: Accuracy = 0.6059630616640024\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.37784498929977417: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.1441471576690674: Accuracy = 0.6063534588855052\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.3479453921318054: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.291903257369995: Accuracy = 0.606771416571354\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.38691475987434387: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.3935720920562744: Accuracy = 0.6070989126373734\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.3436172604560852: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.9506421089172363: Accuracy = 0.6075809933564847\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.3634703457355499: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.2857933044433594: Accuracy = 0.6080142325922185\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.3505971133708954: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.242096185684204: Accuracy = 0.6082628893588318\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.2886112928390503: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 3.2729601860046387: Accuracy = 0.6086175953621173\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.3796940743923187: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.1963305473327637: Accuracy = 0.608926101889919\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.3765285611152649: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.0204362869262695: Accuracy = 0.6094476236138245\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.327420175075531: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.077812433242798: Accuracy = 0.6097017602504626\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.37594375014305115: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.1814053058624268: Accuracy = 0.6099626550903766\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.3982548415660858: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.056610345840454: Accuracy = 0.6104627272471459\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.32614782452583313: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.1985392570495605: Accuracy = 0.6107912480698269\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.361672580242157: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.4857537746429443: Accuracy = 0.6112988202114589\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.37152600288391113: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.0228044986724854: Accuracy = 0.6115873008961142\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.3554036021232605: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.583692789077759: Accuracy = 0.6117819509833202\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.3917277753353119: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.1198055744171143: Accuracy = 0.6119534484279785\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.378846675157547: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.8992505073547363: Accuracy = 0.6122489589248533\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.42260119318962097: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 3.1527011394500732: Accuracy = 0.6124388304507098\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.3630008399486542: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.0900638103485107: Accuracy = 0.6126905737794093\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.3231848180294037: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.0017521381378174: Accuracy = 0.6128564407112819\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.36564990878105164: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.144181251525879: Accuracy = 0.6131345909213433\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.3642435073852539: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.666175603866577: Accuracy = 0.6134290714169943\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.3277943432331085: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.4235405921936035: Accuracy = 0.6136736503818367\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.32529211044311523: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.0448479652404785: Accuracy = 0.6139020923646021\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.3513471484184265: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.2347652912139893: Accuracy = 0.6143135319164379\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.3309914469718933: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 3.029618740081787: Accuracy = 0.6145514465123532\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.37594637274742126: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.0413479804992676: Accuracy = 0.614960144311155\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.32962217926979065: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.398244857788086: Accuracy = 0.6153110674079953\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.37202194333076477: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.083766460418701: Accuracy = 0.6155974855474112\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.3586410880088806: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.5299153327941895: Accuracy = 0.6158426497111171\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.3716222643852234: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.5815484523773193: Accuracy = 0.6160772536740845\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.39115700125694275: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.9512529373168945: Accuracy = 0.6163387879887898\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.349939227104187: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.0345661640167236: Accuracy = 0.6165877876469956\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.3411816656589508: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.262716770172119: Accuracy = 0.6166952688296787\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.3730238378047943: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.7972359657287598: Accuracy = 0.6169758478087923\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.3103565573692322: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.9139695167541504: Accuracy = 0.6172425371213354\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.37346020340919495: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.5726399421691895: Accuracy = 0.6175594974385155\n",
      "\n",
      "Data shuffled. Epoch:  195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.34157171845436096: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.3800504207611084: Accuracy = 0.6177501844189939\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.36203494668006897: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.3492586612701416: Accuracy = 0.6179001206885696\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.3197115957736969: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.5235421657562256: Accuracy = 0.6180306835702852\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.3790404498577118: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.518397808074951: Accuracy = 0.6181860014179816\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.288536936044693: Accuracy = 0.9133333563804626\n",
      "Performance on test set: : Loss = 3.5726335048675537: Accuracy = 0.6184002435239728\n",
      "\n",
      "Optimisation finished!\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.1453230381011963: Accuracy = 0.3933333456516266\n",
      "Performance on test set: : Loss = 1.1491509675979614: Accuracy = 0.490825734304882\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.0928096771240234: Accuracy = 0.46666666865348816\n",
      "Performance on test set: : Loss = 1.1556535959243774: Accuracy = 0.5189075396029478\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.111167311668396: Accuracy = 0.4399999976158142\n",
      "Performance on test set: : Loss = 1.1531999111175537: Accuracy = 0.49365301580376103\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.10382878780365: Accuracy = 0.41333332657814026\n",
      "Performance on test set: : Loss = 1.164790391921997: Accuracy = 0.4955752111016186\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.0215213298797607: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.1809070110321045: Accuracy = 0.5018420210096395\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 0.9519235491752625: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.107351541519165: Accuracy = 0.5327194426480099\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 0.8122673630714417: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.1706005334854126: Accuracy = 0.5675307566282338\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 0.8420892953872681: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.2590702772140503: Accuracy = 0.6019865625592404\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 0.9103187918663025: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.3201518058776855: Accuracy = 0.6256246039839792\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.8318056464195251: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.1900135278701782: Accuracy = 0.646820496344523\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.7983617186546326: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.1508644819259644: Accuracy = 0.6633086652032842\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.731201708316803: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.2531187534332275: Accuracy = 0.6754285287340382\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.6597002744674683: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.306594729423523: Accuracy = 0.6774575219929768\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.6719412803649902: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.3508776426315308: Accuracy = 0.6780075796479914\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.7767031788825989: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.4561859369277954: Accuracy = 0.6771418590907803\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 0.5721502900123596: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.5229095220565796: Accuracy = 0.6744462841527304\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.6194587349891663: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.3891767263412476: Accuracy = 0.675361709908116\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.5689458250999451: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.4852980375289917: Accuracy = 0.6727994714917603\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.5895962715148926: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.4886835813522339: Accuracy = 0.6737653721851479\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.5286659002304077: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.6850272417068481: Accuracy = 0.672631573642452\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.5689893960952759: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.4079829454421997: Accuracy = 0.6727485292045888\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.6023087501525879: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.5246814489364624: Accuracy = 0.6739182769496121\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.533434271812439: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.2425929307937622: Accuracy = 0.6749022005040682\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.522355318069458: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.538672924041748: Accuracy = 0.6755502998197054\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.5506887435913086: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.3520493507385254: Accuracy = 0.6765267692575732\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.5322988033294678: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.7435712814331055: Accuracy = 0.6780583979105406\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.6300883889198303: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.6633144617080688: Accuracy = 0.6765402792651722\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.5179237127304077: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.339003562927246: Accuracy = 0.6767099177113203\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.531950056552887: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.4691169261932373: Accuracy = 0.6774768215215987\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.5102456212043762: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.5193268060684204: Accuracy = 0.6783569867324367\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.5133646130561829: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.5010652542114258: Accuracy = 0.6772834307979911\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.5137547254562378: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.584714412689209: Accuracy = 0.6779015374667532\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.5006570219993591: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.581073522567749: Accuracy = 0.677226226876136\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.5737833380699158: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.4816604852676392: Accuracy = 0.6769719130518961\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.5461156368255615: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 2.0077404975891113: Accuracy = 0.6770323475639795\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.5255987644195557: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.7682347297668457: Accuracy = 0.6772836987324772\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.5076895356178284: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.6602638959884644: Accuracy = 0.6768539758746074\n",
      "\n",
      "Data shuffled. Epoch:  37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.5114935040473938: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.5134329795837402: Accuracy = 0.6754373390069426\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.5099542737007141: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.6271723508834839: Accuracy = 0.6754997883603816\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.5025768280029297: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.9384100437164307: Accuracy = 0.675532170158538\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.4664887487888336: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.5239254236221313: Accuracy = 0.67553188834799\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.4989672899246216: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.5952311754226685: Accuracy = 0.676907083809895\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.474386990070343: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.5755451917648315: Accuracy = 0.677297892750497\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.5011025071144104: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.7305980920791626: Accuracy = 0.6766643360711716\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.47426554560661316: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.8137825727462769: Accuracy = 0.6761626341672371\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.43517792224884033: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.700490117073059: Accuracy = 0.6758895246138836\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.4879390597343445: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.595246434211731: Accuracy = 0.6750584807674965\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.49701979756355286: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.695772647857666: Accuracy = 0.6731983224161471\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.4601876735687256: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.792884349822998: Accuracy = 0.673614004448137\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.4668933153152466: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.1503303050994873: Accuracy = 0.6723820630610097\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.49275100231170654: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.8205525875091553: Accuracy = 0.6717711708712746\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.4776206314563751: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 2.2186806201934814: Accuracy = 0.6692465851326417\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.4442266821861267: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.7918143272399902: Accuracy = 0.6681781795075155\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.47737589478492737: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.7719892263412476: Accuracy = 0.6676035441354694\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.44078266620635986: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.841493010520935: Accuracy = 0.6670933868348972\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.48292866349220276: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.0727200508117676: Accuracy = 0.6651631506372384\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.4495697617530823: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.687355875968933: Accuracy = 0.6647967950621371\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.45021048188209534: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.7698642015457153: Accuracy = 0.6651283370957816\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.45782825350761414: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.355210542678833: Accuracy = 0.6654693127516247\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.45111405849456787: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.8086708784103394: Accuracy = 0.6671001103656073\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.45752084255218506: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.9336904287338257: Accuracy = 0.664692607126451\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.4567945897579193: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.625280737876892: Accuracy = 0.6647838486197307\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.4189381003379822: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.9055743217468262: Accuracy = 0.6633099943588765\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.4478335678577423: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.699303388595581: Accuracy = 0.662406581741165\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.48136648535728455: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.03078031539917: Accuracy = 0.6622219566183025\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.42226704955101013: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.7041935920715332: Accuracy = 0.6607163051309644\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.4412854015827179: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.8197087049484253: Accuracy = 0.658593157764496\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.42360833287239075: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.9257502555847168: Accuracy = 0.6582662453503886\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.4142224192619324: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.752598762512207: Accuracy = 0.6570713059238598\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.40232136845588684: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.8592926263809204: Accuracy = 0.6563439361460793\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.41278591752052307: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.9419938325881958: Accuracy = 0.6556855994332514\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.43094921112060547: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.100194215774536: Accuracy = 0.6545378280736738\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.4510064721107483: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.9598287343978882: Accuracy = 0.6537320451198719\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.4264451563358307: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.141056537628174: Accuracy = 0.6526369972487411\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.4171144962310791: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.238356113433838: Accuracy = 0.65132907534209\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.42176392674446106: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.4452154636383057: Accuracy = 0.6496878816419787\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.4083902835845947: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.6717159748077393: Accuracy = 0.6493072974502329\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.42160260677337646: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.2369601726531982: Accuracy = 0.6472146131187884\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.41737452149391174: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.8391188383102417: Accuracy = 0.6468908058502388\n",
      "\n",
      "Data shuffled. Epoch:  79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.44991591572761536: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.4326353073120117: Accuracy = 0.6454644947450353\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.40277186036109924: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.0456416606903076: Accuracy = 0.6445815993362346\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.3686796724796295: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.6884758472442627: Accuracy = 0.6447890041400108\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.405781090259552: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.522512912750244: Accuracy = 0.6432486011699307\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.4126685857772827: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.46989107131958: Accuracy = 0.6423453423654486\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.3849518895149231: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.1432738304138184: Accuracy = 0.6415373729725469\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.3870943784713745: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.5106170177459717: Accuracy = 0.6409846603224385\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.3823268413543701: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.0939581394195557: Accuracy = 0.639985952999001\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.39688795804977417: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.714097261428833: Accuracy = 0.6399079956012569\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.4048417806625366: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.3844165802001953: Accuracy = 0.6384550383055151\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.41766229271888733: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.9264307022094727: Accuracy = 0.6386169371334064\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.32521775364875793: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.751282215118408: Accuracy = 0.6385392778856901\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.3386266827583313: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.801297187805176: Accuracy = 0.6379120305449649\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.41788503527641296: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.0582449436187744: Accuracy = 0.6377216979907039\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.419401615858078: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.267953634262085: Accuracy = 0.6372413502199273\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.4424363076686859: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.5258584022521973: Accuracy = 0.6367119499587\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.4463968276977539: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.8327953815460205: Accuracy = 0.6354949725341215\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.3510536849498749: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.437572479248047: Accuracy = 0.6364552514911409\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.4052478075027466: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.0577847957611084: Accuracy = 0.6354034059410006\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.39286091923713684: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.466121196746826: Accuracy = 0.6350894555467353\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.3973727524280548: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.673081874847412: Accuracy = 0.6352262703319991\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.35615652799606323: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.45944881439209: Accuracy = 0.6338991291094145\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.4157070815563202: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.450594425201416: Accuracy = 0.632908514577691\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.3955094516277313: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.051499843597412: Accuracy = 0.6323468923733471\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.3772047758102417: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.6790809631347656: Accuracy = 0.6312803060449966\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.37963056564331055: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.288612127304077: Accuracy = 0.6297993071538123\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.3858942985534668: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.5809733867645264: Accuracy = 0.6293237303526608\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.36405450105667114: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.2060673236846924: Accuracy = 0.6287769243761394\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.3731900155544281: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.8668839931488037: Accuracy = 0.6286972798805675\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.4272972643375397: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.5843327045440674: Accuracy = 0.6278722361649391\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.38597869873046875: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.1488871574401855: Accuracy = 0.6265069002399479\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.4096163511276245: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.6540541648864746: Accuracy = 0.626881319096052\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.3483395278453827: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.1656413078308105: Accuracy = 0.6264755609493987\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.35791558027267456: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.9112298488616943: Accuracy = 0.625903045879181\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.351710706949234: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.5528767108917236: Accuracy = 0.6246188841078968\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.3865334689617157: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.787334680557251: Accuracy = 0.6239778111749275\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.3272832930088043: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.2709412574768066: Accuracy = 0.623800014314037\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.36347851157188416: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.6004586219787598: Accuracy = 0.6229638891747546\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.42073315382003784: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.0953001976013184: Accuracy = 0.6220242525408999\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.3957814872264862: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.9247379302978516: Accuracy = 0.621197793971746\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.3760680854320526: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.0954477787017822: Accuracy = 0.619607494539634\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.3929261863231659: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.2583916187286377: Accuracy = 0.6195138148718968\n",
      "\n",
      "Data shuffled. Epoch:  121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.37179139256477356: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.8228063583374023: Accuracy = 0.6190041645530402\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.33895421028137207: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.5455570220947266: Accuracy = 0.6180171877983668\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.3922390937805176: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 3.0551977157592773: Accuracy = 0.6174736053965693\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.38303983211517334: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.144392251968384: Accuracy = 0.616480669066192\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.37276601791381836: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.33514142036438: Accuracy = 0.6151453523654423\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.3627890348434448: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.139319896697998: Accuracy = 0.6151164405337598\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.33801189064979553: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.189359426498413: Accuracy = 0.615132648233405\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.40913277864456177: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.9871127605438232: Accuracy = 0.6144964337987157\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.34803369641304016: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.1563470363616943: Accuracy = 0.613423473076018\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.380461186170578: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.5883047580718994: Accuracy = 0.6131408795408857\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.3228617310523987: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.989816188812256: Accuracy = 0.6131922327287743\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.31466177105903625: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.9102118015289307: Accuracy = 0.612965518099116\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.36904802918434143: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.681225538253784: Accuracy = 0.6128437114546879\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.3332529067993164: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.793025016784668: Accuracy = 0.6118263491981418\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.3830045759677887: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.4579529762268066: Accuracy = 0.6111840888782953\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.3483058512210846: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.6598918437957764: Accuracy = 0.6113413093278006\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.3240923583507538: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.3231289386749268: Accuracy = 0.6110541038432302\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.29021918773651123: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 3.6730685234069824: Accuracy = 0.6106209435399164\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.376497358083725: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.1616034507751465: Accuracy = 0.6099643082825974\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.4117690920829773: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.72973895072937: Accuracy = 0.608682274032009\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.4061674177646637: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.346212387084961: Accuracy = 0.6083628863063463\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.3146684169769287: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.855158567428589: Accuracy = 0.6083460877974115\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.33812665939331055: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.0359930992126465: Accuracy = 0.6077130530633463\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.3379112184047699: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.5906260013580322: Accuracy = 0.6071273825836969\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.34685030579566956: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.2888245582580566: Accuracy = 0.6066775166939817\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.3375580906867981: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.156324625015259: Accuracy = 0.6059834135953445\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.35824599862098694: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.2031619548797607: Accuracy = 0.605982238643692\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.2996578514575958: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 4.2602643966674805: Accuracy = 0.6059579731867814\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.29460617899894714: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 3.221796989440918: Accuracy = 0.6048818917731741\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.3556215167045593: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.868130922317505: Accuracy = 0.6044614388048206\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.3179239332675934: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 3.2003350257873535: Accuracy = 0.6035852300604252\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.28571051359176636: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.2236719131469727: Accuracy = 0.6032627489823144\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.38211503624916077: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.1955487728118896: Accuracy = 0.6027495414009211\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.3264053761959076: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.8905537128448486: Accuracy = 0.6025433698499497\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.35161641240119934: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 4.208903789520264: Accuracy = 0.6025598666709842\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.3799916207790375: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.047111749649048: Accuracy = 0.6018292267822803\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.3932507336139679: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.9875080585479736: Accuracy = 0.6015525463999174\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.332907497882843: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.9191372394561768: Accuracy = 0.6018257969006174\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.31089773774147034: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.242302894592285: Accuracy = 0.6018241712152851\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.3403857946395874: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.096942186355591: Accuracy = 0.6011282988467422\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.4169062674045563: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.739192008972168: Accuracy = 0.6010652776379365\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.33493396639823914: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.67474627494812: Accuracy = 0.6009446573517143\n",
      "\n",
      "Data shuffled. Epoch:  163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.3210092782974243: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.8049893379211426: Accuracy = 0.6002826498676561\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.3535480499267578: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.495943784713745: Accuracy = 0.599663721046081\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.3818883001804352: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.192755699157715: Accuracy = 0.5991639544840662\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.31960102915763855: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.384045362472534: Accuracy = 0.5986176461919628\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.3318902850151062: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.175180435180664: Accuracy = 0.5980348403064548\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.40619516372680664: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.4596028327941895: Accuracy = 0.5979149164922979\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.3668142557144165: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.388899326324463: Accuracy = 0.5980464358804369\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.32969361543655396: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.000771999359131: Accuracy = 0.5972825466097246\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.3895956873893738: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.8456661701202393: Accuracy = 0.5976637386352048\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.34306520223617554: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.654029607772827: Accuracy = 0.5970269553711898\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.3641590178012848: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.5300333499908447: Accuracy = 0.5963650496042283\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.30084899067878723: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.8824243545532227: Accuracy = 0.5960172031789773\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.354234904050827: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.131411075592041: Accuracy = 0.5953174104943004\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.36944133043289185: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.839005470275879: Accuracy = 0.5948799796054873\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.34810659289360046: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.761704444885254: Accuracy = 0.5948873940945179\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.28512364625930786: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 3.3846845626831055: Accuracy = 0.5946420560934413\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.3688581585884094: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.169926643371582: Accuracy = 0.5942941398075681\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.31261706352233887: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.120535373687744: Accuracy = 0.5939749839185923\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.31237030029296875: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.414316177368164: Accuracy = 0.5938466193413693\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.3967377245426178: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.2599878311157227: Accuracy = 0.5933031096701024\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.3435232639312744: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.2917520999908447: Accuracy = 0.5933528437391518\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.3285425007343292: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.2111456394195557: Accuracy = 0.5925559057743116\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.2764321565628052: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 3.0535969734191895: Accuracy = 0.5917825366888764\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.36889857053756714: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.3567962646484375: Accuracy = 0.5908877595669768\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.325040340423584: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.5925910472869873: Accuracy = 0.5901587117842205\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.34210410714149475: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.4821534156799316: Accuracy = 0.5903849660362351\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.34374234080314636: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 4.026652812957764: Accuracy = 0.5902861342827445\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.3139037787914276: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 4.252199172973633: Accuracy = 0.5898544663718385\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.3176254630088806: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.868349552154541: Accuracy = 0.5891596981172151\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.376631498336792: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.825378179550171: Accuracy = 0.5886756861551254\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.32958853244781494: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.574432134628296: Accuracy = 0.5881892860314982\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.34346693754196167: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.5107662677764893: Accuracy = 0.5877749870059559\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.32566723227500916: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 4.490677356719971: Accuracy = 0.5877701853754896\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.3586098849773407: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.6523807048797607: Accuracy = 0.5873355899749735\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.27328550815582275: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 3.9929745197296143: Accuracy = 0.5871879779280841\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.32454439997673035: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.2093050479888916: Accuracy = 0.5868750890749289\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.3751693069934845: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.482595443725586: Accuracy = 0.5870301500215638\n",
      "\n",
      "Optimisation finished!\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.145381212234497: Accuracy = 0.3866666555404663\n",
      "Performance on test set: : Loss = 1.144452452659607: Accuracy = 0.5\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.122840404510498: Accuracy = 0.4266666769981384\n",
      "Performance on test set: : Loss = 1.1426597833633423: Accuracy = 0.4983534328328776\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.0647584199905396: Accuracy = 0.4333333373069763\n",
      "Performance on test set: : Loss = 1.1958712339401245: Accuracy = 0.5210674384897724\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.0368199348449707: Accuracy = 0.46000000834465027\n",
      "Performance on test set: : Loss = 1.2302992343902588: Accuracy = 0.5084745912547518\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 0.9614145755767822: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.2264699935913086: Accuracy = 0.48965521840703996\n",
      "\n",
      "Data shuffled. Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.7877025604248047: Accuracy = 0.5666666626930237\n",
      "Performance on test set: : Loss = 1.469942569732666: Accuracy = 0.4639823032829744\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 1.0872671604156494: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.5972638130187988: Accuracy = 0.43662430358798376\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 1.0646843910217285: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.1670583486557007: Accuracy = 0.4378731680839515\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 1.0565266609191895: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.1682740449905396: Accuracy = 0.4662095703439263\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.9454669952392578: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.1422449350357056: Accuracy = 0.4494835972600722\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.8466415405273438: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.374595046043396: Accuracy = 0.43995045105900393\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.7665396928787231: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.521627426147461: Accuracy = 0.42933948903685915\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.6750186681747437: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.4336944818496704: Accuracy = 0.4215246842734344\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.7020605802536011: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.3336442708969116: Accuracy = 0.4122703384493638\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.6818826198577881: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.4576126337051392: Accuracy = 0.4058431542785056\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 0.5991264581680298: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.5554118156433105: Accuracy = 0.4058577149233057\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.6341991424560547: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.7666445970535278: Accuracy = 0.40625439871254215\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.5857529640197754: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.625450611114502: Accuracy = 0.4063500687403308\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.5870473384857178: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.532128095626831: Accuracy = 0.41110415579981263\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.553223192691803: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.5701634883880615: Accuracy = 0.4167065276818701\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.5476523637771606: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.5874484777450562: Accuracy = 0.42462798101942567\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.6087122559547424: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.8119442462921143: Accuracy = 0.4314150091895223\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.5588656663894653: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.7951422929763794: Accuracy = 0.4387776036335148\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.5580698847770691: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.6499078273773193: Accuracy = 0.44600195468837756\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.5532413125038147: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.4344197511672974: Accuracy = 0.4548886259359749\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.550621509552002: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.6120737791061401: Accuracy = 0.46274865437270996\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.5332615971565247: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.6703447103500366: Accuracy = 0.4696995506647936\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.5500410199165344: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.7716983556747437: Accuracy = 0.4778657739601091\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.5120007395744324: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.6036120653152466: Accuracy = 0.48581505263284963\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.5306112766265869: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.8672019243240356: Accuracy = 0.49352048354960043\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.49486908316612244: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.7103769779205322: Accuracy = 0.499665327978581\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.5048764944076538: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.8099900484085083: Accuracy = 0.5059895363759408\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.5115477442741394: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.8573625087738037: Accuracy = 0.51203102404304\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.4826884865760803: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.2184553146362305: Accuracy = 0.5175396784332356\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.4892398715019226: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.6502490043640137: Accuracy = 0.5209592615893137\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.48876887559890747: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.459089994430542: Accuracy = 0.5248646534843571\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.488092303276062: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.002520799636841: Accuracy = 0.5287861856697013\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.4879924952983856: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.8685582876205444: Accuracy = 0.5306049792660907\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.4924306869506836: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.010669231414795: Accuracy = 0.5338811534165512\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.49414509534835815: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.0922162532806396: Accuracy = 0.5358069231149947\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.48138925433158875: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 2.275191307067871: Accuracy = 0.5380091000104991\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.49348947405815125: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.2423691749572754: Accuracy = 0.5400567761578574\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.46989312767982483: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.0213446617126465: Accuracy = 0.5417930663248463\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.4867537319660187: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.370209217071533: Accuracy = 0.5445079514423278\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.4590372145175934: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 2.100794553756714: Accuracy = 0.5464606467116214\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.513591468334198: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.0206003189086914: Accuracy = 0.5463504858232286\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.5060572028160095: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.185852289199829: Accuracy = 0.5473895177547652\n",
      "\n",
      "Data shuffled. Epoch:  47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.5035605430603027: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.993377685546875: Accuracy = 0.5485121761214238\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.4890609681606293: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.8269448280334473: Accuracy = 0.5505828294885026\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.44498831033706665: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.077326536178589: Accuracy = 0.5514646973086247\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.47651147842407227: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.04413104057312: Accuracy = 0.5530103284895823\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.4212692975997925: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.9712340831756592: Accuracy = 0.5542790889449953\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.4508281946182251: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.0159852504730225: Accuracy = 0.5561835896729505\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.44196847081184387: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.9473841190338135: Accuracy = 0.5576334322219839\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.4141976237297058: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.8789252042770386: Accuracy = 0.5590516069281408\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.41221415996551514: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.090891122817993: Accuracy = 0.5601658326265476\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.45741888880729675: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.8821314573287964: Accuracy = 0.5612620258063046\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.43074271082878113: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.2530131340026855: Accuracy = 0.5616896648322524\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.4027595818042755: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.7471377849578857: Accuracy = 0.5621785114528539\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.4553855359554291: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.585432529449463: Accuracy = 0.5622884460186598\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.4846652150154114: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.750124454498291: Accuracy = 0.5629412780753583\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.42540401220321655: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.1497018337249756: Accuracy = 0.5639254578416636\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.4727933704853058: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.5251262187957764: Accuracy = 0.5645743534810913\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.395489364862442: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.6404595375061035: Accuracy = 0.5644188801143557\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.4100407660007477: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.513662099838257: Accuracy = 0.5634489935182423\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.41044485569000244: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.618321180343628: Accuracy = 0.5641423984401218\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.4672452211380005: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.542271137237549: Accuracy = 0.56433498562124\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.4243983328342438: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.100667953491211: Accuracy = 0.5649160892879505\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.44969746470451355: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.5035741329193115: Accuracy = 0.5652230560402086\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.44606825709342957: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.681605100631714: Accuracy = 0.5651827083001246\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.41694173216819763: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.7742085456848145: Accuracy = 0.5650709607073541\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.6945542097091675: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.0019476413726807: Accuracy = 0.5647204871869013\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.44075286388397217: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.169210910797119: Accuracy = 0.5648205169464379\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.4626326560974121: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 3.094712257385254: Accuracy = 0.5651398900240534\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.4448748826980591: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.9731171131134033: Accuracy = 0.5628877845344451\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.4765835106372833: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.0926456451416016: Accuracy = 0.5617414954126032\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.46931666135787964: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.0388898849487305: Accuracy = 0.5626179482878346\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.43778014183044434: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.1560163497924805: Accuracy = 0.5619228153403861\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.40139448642730713: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.115262269973755: Accuracy = 0.5615953219911084\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.41764625906944275: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.5201048851013184: Accuracy = 0.5620019428600362\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.44883835315704346: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.202740430831909: Accuracy = 0.5609641823873786\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.40655866265296936: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.728512763977051: Accuracy = 0.560557263829154\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.4286389648914337: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.022040367126465: Accuracy = 0.560565615668391\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.4310649633407593: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.4097437858581543: Accuracy = 0.5593464534606053\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.43001997470855713: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.510209560394287: Accuracy = 0.5608875257273548\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.42348042130470276: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.2106990814208984: Accuracy = 0.5601834836036648\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.4353710412979126: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.903333902359009: Accuracy = 0.5602844250825627\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.4456718862056732: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.2059497833251953: Accuracy = 0.5613597302611407\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.42418935894966125: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.002760887145996: Accuracy = 0.5611094066576702\n",
      "\n",
      "Data shuffled. Epoch:  89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.3964155912399292: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.6469123363494873: Accuracy = 0.5605219123872267\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.365352064371109: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.5873332023620605: Accuracy = 0.5597476565533516\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.4481755495071411: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.6123225688934326: Accuracy = 0.5595766385072698\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.4291318356990814: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.727222442626953: Accuracy = 0.5590344005121812\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.349998414516449: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.2927300930023193: Accuracy = 0.5589584396082686\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.4368073642253876: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.907438039779663: Accuracy = 0.5592851727635345\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.41473162174224854: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.877479314804077: Accuracy = 0.5581101153297193\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.37817123532295227: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.627124786376953: Accuracy = 0.5579659582621469\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.3934892416000366: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.619615316390991: Accuracy = 0.5581651352712289\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.3729601800441742: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.6508076190948486: Accuracy = 0.5570552240102561\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.3667128384113312: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.3713881969451904: Accuracy = 0.5572951422416123\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.3485144376754761: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.670792579650879: Accuracy = 0.5583103460188512\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.3721890151500702: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.069634437561035: Accuracy = 0.5575939309989794\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.41534367203712463: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.7262277603149414: Accuracy = 0.5570145736724347\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.34297648072242737: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.2746665477752686: Accuracy = 0.5580108061843942\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.40008655190467834: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 3.609635353088379: Accuracy = 0.5577120749476661\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.43659520149230957: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.7430033683776855: Accuracy = 0.55734569376923\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.4142131507396698: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.637749671936035: Accuracy = 0.5579234943945702\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.37720608711242676: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.6609418392181396: Accuracy = 0.5575737762560226\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.35817086696624756: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.773329973220825: Accuracy = 0.5576124908826582\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.37340837717056274: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.3964173793792725: Accuracy = 0.5578618131652534\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.3676339089870453: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.130239248275757: Accuracy = 0.559076670909386\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.36019039154052734: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.6812856197357178: Accuracy = 0.5591251399089714\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.41916611790657043: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.5433287620544434: Accuracy = 0.5583200749156491\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.3875761032104492: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.5051109790802: Accuracy = 0.5592304915208365\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.39655449986457825: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.76692533493042: Accuracy = 0.5587050634324123\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.46128737926483154: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.31634783744812: Accuracy = 0.5593010304632793\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.34966766834259033: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.1971726417541504: Accuracy = 0.5603670189388212\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.37068313360214233: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.9298319816589355: Accuracy = 0.5604263887088691\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.35629019141197205: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.5827763080596924: Accuracy = 0.5602009128506145\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.3228374719619751: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.939114809036255: Accuracy = 0.5612275420835009\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.4051557779312134: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.805752992630005: Accuracy = 0.560650836679966\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.35929203033447266: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.82326602935791: Accuracy = 0.5619697676340295\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.31991276144981384: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.8990588188171387: Accuracy = 0.5630323840978452\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.4083879590034485: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.7438366413116455: Accuracy = 0.5636777886476\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.3829830288887024: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.41339373588562: Accuracy = 0.5643417223594756\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.33294832706451416: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.5373196601867676: Accuracy = 0.5643625665170735\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.31566911935806274: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.9813131093978882: Accuracy = 0.565021765738878\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.3774465322494507: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.5054538249969482: Accuracy = 0.5658219047486176\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.3933848738670349: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.53153133392334: Accuracy = 0.5652709915273545\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.40328243374824524: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.7168619632720947: Accuracy = 0.5658427093956252\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.3780941963195801: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.9314188957214355: Accuracy = 0.5662570041913412\n",
      "\n",
      "Data shuffled. Epoch:  131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.40130650997161865: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.9748597145080566: Accuracy = 0.5668994825069597\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.31914445757865906: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.908702850341797: Accuracy = 0.5677057129681112\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.37568968534469604: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.4657769203186035: Accuracy = 0.5682022743971679\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.3278880715370178: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.937110424041748: Accuracy = 0.5683732931478062\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.30534660816192627: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.9840197563171387: Accuracy = 0.5684238262251561\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.3434239327907562: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.404221534729004: Accuracy = 0.5693421062385791\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.36728134751319885: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.885793447494507: Accuracy = 0.569579724158481\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.40997540950775146: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.445941925048828: Accuracy = 0.5701764125584873\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.3438071310520172: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.1747868061065674: Accuracy = 0.5703903002489052\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.3298693001270294: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.9573004245758057: Accuracy = 0.5703931958186053\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.3658071756362915: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.063188314437866: Accuracy = 0.5702119654203355\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.3221386969089508: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.2647135257720947: Accuracy = 0.5707602001400691\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.31964346766471863: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.600680112838745: Accuracy = 0.5714329988342443\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.3455978035926819: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.7103893756866455: Accuracy = 0.5717489525658148\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.3341244161128998: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.8988280296325684: Accuracy = 0.5723475824235384\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.45599547028541565: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.925600290298462: Accuracy = 0.572090517400901\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.3343539535999298: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.467695474624634: Accuracy = 0.5727727552054312\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.34823668003082275: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.897916078567505: Accuracy = 0.5727338260562377\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.34767019748687744: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.6438651084899902: Accuracy = 0.5734102149598447\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.3215745985507965: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 3.3152527809143066: Accuracy = 0.5739800769138231\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.34391579031944275: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.3467857837677: Accuracy = 0.5736008108782044\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.3170396089553833: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.664905071258545: Accuracy = 0.5739797259618294\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.3446626663208008: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.7814321517944336: Accuracy = 0.5743245140930522\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.36696648597717285: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.94398832321167: Accuracy = 0.5742894949733116\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.40696340799331665: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.0158731937408447: Accuracy = 0.5744780911199165\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.36125263571739197: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.6124205589294434: Accuracy = 0.5750219025435394\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.344463050365448: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.8998470306396484: Accuracy = 0.5752840009636695\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.352768212556839: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.959796190261841: Accuracy = 0.5759464002084311\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.3285403549671173: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.2269086837768555: Accuracy = 0.5759066613230536\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.36344537138938904: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.1569275856018066: Accuracy = 0.5770246530407538\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.35570189356803894: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.167957305908203: Accuracy = 0.5772116496978803\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.3453603982925415: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.565284013748169: Accuracy = 0.5777783766527221\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.34191572666168213: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.6296355724334717: Accuracy = 0.5780259506982431\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.38338062167167664: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.30500864982605: Accuracy = 0.5779898643061248\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.3286620080471039: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.011805534362793: Accuracy = 0.5782651482759491\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.338661789894104: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.4551401138305664: Accuracy = 0.5787990105358449\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.3298359513282776: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.5667755603790283: Accuracy = 0.579293453483212\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.33623331785202026: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.0259785652160645: Accuracy = 0.5792550148698488\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.3285648822784424: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.8900442123413086: Accuracy = 0.5793646419388215\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.3408358693122864: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.1545770168304443: Accuracy = 0.5798977439399218\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.3717486560344696: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.7336153984069824: Accuracy = 0.5798895336839407\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.37572017312049866: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.703631639480591: Accuracy = 0.5801230478907179\n",
      "\n",
      "Data shuffled. Epoch:  173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.307062566280365: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.278684377670288: Accuracy = 0.5801850380459876\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.36255210638046265: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.9748666286468506: Accuracy = 0.5802903219695821\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.4234374761581421: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 3.06591796875: Accuracy = 0.5808504702305626\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.3543025255203247: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.8983805179595947: Accuracy = 0.580895917253543\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.3505418002605438: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.4678683280944824: Accuracy = 0.5812787294552252\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.3551916480064392: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.8600924015045166: Accuracy = 0.5814935964502376\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.31353893876075745: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.407339096069336: Accuracy = 0.5814272582295904\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.3183181881904602: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.6928622722625732: Accuracy = 0.5813505924736524\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.36804482340812683: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.853294610977173: Accuracy = 0.5813491450747866\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.3463752269744873: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.1897826194763184: Accuracy = 0.5816224914227407\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.3474612534046173: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.564188241958618: Accuracy = 0.5817877023623081\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.33088600635528564: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.8619747161865234: Accuracy = 0.5817168300998979\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.346206396818161: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.9558918476104736: Accuracy = 0.5819232476230819\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.3610706329345703: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.403925895690918: Accuracy = 0.5825398325542982\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.37823301553726196: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.58779239654541: Accuracy = 0.5828183285267239\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.36737260222435: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.2009541988372803: Accuracy = 0.5827521746329358\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.31660154461860657: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.608215570449829: Accuracy = 0.5834384591661405\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.3635295331478119: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.170818328857422: Accuracy = 0.5836670598295666\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.28606656193733215: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.745734930038452: Accuracy = 0.5840476781591225\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.37186476588249207: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.2580831050872803: Accuracy = 0.5845530450335056\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.3371546268463135: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.15726900100708: Accuracy = 0.5846742806444761\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.3268231749534607: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.734046459197998: Accuracy = 0.5849509103185687\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.4272034168243408: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.2355146408081055: Accuracy = 0.5856893046244096\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.32086309790611267: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 4.063989162445068: Accuracy = 0.5860908410618235\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.33827629685401917: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.8354055881500244: Accuracy = 0.5861877580393712\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.3313940465450287: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.577486753463745: Accuracy = 0.5860810287437508\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.32205694913864136: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.3502893447875977: Accuracy = 0.5860105016953956\n",
      "\n",
      "Optimisation finished!\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.1107432842254639: Accuracy = 0.41333332657814026\n",
      "Performance on test set: : Loss = 1.1645729541778564: Accuracy = 0.5534591028590989\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.1057244539260864: Accuracy = 0.47333332896232605\n",
      "Performance on test set: : Loss = 1.167873501777649: Accuracy = 0.5248962728478002\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.1221660375595093: Accuracy = 0.3799999952316284\n",
      "Performance on test set: : Loss = 1.1575613021850586: Accuracy = 0.5274725447930492\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.107000470161438: Accuracy = 0.41333332657814026\n",
      "Performance on test set: : Loss = 1.162436842918396: Accuracy = 0.5183273260632933\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.0941075086593628: Accuracy = 0.46666666865348816\n",
      "Performance on test set: : Loss = 1.144163727760315: Accuracy = 0.5219893217754514\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 0.9907364845275879: Accuracy = 0.47333332896232605\n",
      "Performance on test set: : Loss = 1.2325615882873535: Accuracy = 0.5127850372244832\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 0.8994372487068176: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.2833529710769653: Accuracy = 0.49834086782233894\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 0.8792459964752197: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.4027433395385742: Accuracy = 0.4750476981552889\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 0.7310943007469177: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.2680383920669556: Accuracy = 0.4554258651612377\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.7158718109130859: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.5227160453796387: Accuracy = 0.44540293299554146\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.671609103679657: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.8310672044754028: Accuracy = 0.4474393331888519\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.8303861618041992: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.379317283630371: Accuracy = 0.4434250909758379\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.6093724966049194: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.7415072917938232: Accuracy = 0.4498147991220957\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.6725184917449951: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.7758300304412842: Accuracy = 0.44959711794972124\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.5615596175193787: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.6023727655410767: Accuracy = 0.4562749083047856\n",
      "\n",
      "Data shuffled. Epoch:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.5367133617401123: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.698639988899231: Accuracy = 0.46248922167939654\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.5370010733604431: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.399477243423462: Accuracy = 0.4726294224531032\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.5495967268943787: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.6980046033859253: Accuracy = 0.4750031862071618\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.6166722178459167: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.5570886135101318: Accuracy = 0.478543924898806\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.5384612679481506: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.6781978607177734: Accuracy = 0.4836571421976787\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.5581472516059875: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 2.0559816360473633: Accuracy = 0.48777305174641816\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.5619820356369019: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.160177230834961: Accuracy = 0.48684621695707203\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.5543337464332581: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.7773654460906982: Accuracy = 0.492118535873474\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.5522425174713135: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.7515051364898682: Accuracy = 0.4943585856783239\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.5524351000785828: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.0239412784576416: Accuracy = 0.49795691434827033\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.5280348658561707: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.8702054023742676: Accuracy = 0.5014826896990193\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.5142393708229065: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.9898436069488525: Accuracy = 0.5070775854557679\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.5075547099113464: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.118027448654175: Accuracy = 0.5090439060406872\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.5236454010009766: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.9922034740447998: Accuracy = 0.5095193490376095\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.5485909581184387: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 2.4919090270996094: Accuracy = 0.5136924553497592\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.517259418964386: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.6696410179138184: Accuracy = 0.5109894651509937\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.520607054233551: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.8891239166259766: Accuracy = 0.5122727176497842\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.5164710879325867: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 2.2040932178497314: Accuracy = 0.5164557056838205\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.48593321442604065: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.58719539642334: Accuracy = 0.5179235321592506\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.5260538458824158: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.765005111694336: Accuracy = 0.5187620896183555\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.4960038661956787: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.5402472019195557: Accuracy = 0.5196514980972828\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.474254310131073: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.4698076248168945: Accuracy = 0.520663177706916\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.527898371219635: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.4677467346191406: Accuracy = 0.5190467625229456\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.5056939721107483: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 2.3168952465057373: Accuracy = 0.520566969958837\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.529646635055542: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.1234405040740967: Accuracy = 0.5216998839238319\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.5135233402252197: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.9699734449386597: Accuracy = 0.5226323698758008\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.48187610507011414: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.301309585571289: Accuracy = 0.5190166331169347\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.48597896099090576: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.1831257343292236: Accuracy = 0.5181445428393612\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.4990927577018738: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 3.09783673286438: Accuracy = 0.520682800021052\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.5031160712242126: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 3.2177116870880127: Accuracy = 0.5200000241326378\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.46075886487960815: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.5443499088287354: Accuracy = 0.5203450776023085\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.47443312406539917: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.792266607284546: Accuracy = 0.5187890409966317\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.5120171904563904: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 3.8994953632354736: Accuracy = 0.5186161555186348\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.46582555770874023: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.7675836086273193: Accuracy = 0.5170583309085188\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.4941970705986023: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 4.25191068649292: Accuracy = 0.5175906742353903\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.4638921618461609: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.9016451835632324: Accuracy = 0.5138715952382565\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.5005334615707397: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.515805721282959: Accuracy = 0.5127175949929522\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.492195725440979: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.3864331245422363: Accuracy = 0.511884861525301\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.4680824279785156: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.5386996269226074: Accuracy = 0.5107726078151419\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.44082534313201904: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.327164649963379: Accuracy = 0.5079102057517665\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.46738165616989136: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.2679061889648438: Accuracy = 0.5088824783231706\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.4847147762775421: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.728604555130005: Accuracy = 0.5069611205006218\n",
      "\n",
      "Data shuffled. Epoch:  57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.468209832906723: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 3.2433269023895264: Accuracy = 0.507429831237192\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.4404065012931824: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.044050693511963: Accuracy = 0.5067285453702209\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.4702926576137543: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.326354503631592: Accuracy = 0.5057086139882114\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.4217087924480438: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.8203961849212646: Accuracy = 0.5039729934680195\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.45297476649284363: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.527419090270996: Accuracy = 0.5037998853643052\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.4356604516506195: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 3.682288646697998: Accuracy = 0.501981900976336\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.4313908517360687: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.6350088119506836: Accuracy = 0.502451775848848\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.447920024394989: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.373047351837158: Accuracy = 0.5026255746125812\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.44920796155929565: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.8256142139434814: Accuracy = 0.5048503567588303\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.43722856044769287: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.828582525253296: Accuracy = 0.504813242208347\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.48764678835868835: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.453871965408325: Accuracy = 0.5066818840584869\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.4640229344367981: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.579392194747925: Accuracy = 0.5053175607003995\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.42459163069725037: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.4757537841796875: Accuracy = 0.5049178200753714\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.4108004570007324: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.249272584915161: Accuracy = 0.5047210810550957\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.41573965549468994: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.599696636199951: Accuracy = 0.5031658879589145\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.44857844710350037: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.2504401206970215: Accuracy = 0.503216856364064\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.4341212511062622: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.6107099056243896: Accuracy = 0.5034367154647507\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.4415326416492462: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.898627281188965: Accuracy = 0.5027970444706207\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.44644713401794434: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.316622257232666: Accuracy = 0.5029868370005722\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.43867039680480957: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.71651554107666: Accuracy = 0.5028894559417584\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.7923696041107178: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 5.2041707038879395: Accuracy = 0.5008984449857121\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.5479484796524048: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 3.190575122833252: Accuracy = 0.4997525379044176\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.4863682687282562: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.8039408922195435: Accuracy = 0.500545642371276\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.43479111790657043: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.5182416439056396: Accuracy = 0.5014594061783622\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.498085081577301: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.3455278873443604: Accuracy = 0.5022245547932771\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.4896541237831116: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.9663587808609009: Accuracy = 0.5024878216116505\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.4387550354003906: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.6474478244781494: Accuracy = 0.5021862761287902\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.45926588773727417: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.7008492946624756: Accuracy = 0.5019995728048723\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.4041641652584076: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.6049535274505615: Accuracy = 0.502550144094977\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.41483569145202637: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.601656675338745: Accuracy = 0.5043634123526262\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.39717474579811096: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.011854410171509: Accuracy = 0.5046271169887618\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.36989152431488037: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.635385513305664: Accuracy = 0.5051790895085368\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.44760096073150635: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.5750255584716797: Accuracy = 0.5063896899318032\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.40238621830940247: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.7071611881256104: Accuracy = 0.5070465018809704\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.4722609519958496: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.305222511291504: Accuracy = 0.5081718483977463\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.48871180415153503: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.073075532913208: Accuracy = 0.5084287060057807\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.4098967909812927: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.732764959335327: Accuracy = 0.5086437436544046\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.41384679079055786: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.7118148803710938: Accuracy = 0.5084476465034559\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.3976375460624695: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.1339197158813477: Accuracy = 0.5098674663536499\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.3913225531578064: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.856980800628662: Accuracy = 0.5101786027928352\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.4319874048233032: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.412407875061035: Accuracy = 0.5115367161230924\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.48434579372406006: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.4900782108306885: Accuracy = 0.5129435131929818\n",
      "\n",
      "Data shuffled. Epoch:  99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.4172610938549042: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.8080267906188965: Accuracy = 0.514307914722834\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.4679044187068939: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.662155866622925: Accuracy = 0.514595580031257\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.429576575756073: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.518099546432495: Accuracy = 0.5161492629038066\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.431307315826416: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.139387369155884: Accuracy = 0.5161176084112344\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.42278361320495605: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.577599287033081: Accuracy = 0.5171370931521692\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.39222291111946106: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.2657511234283447: Accuracy = 0.5169163838104731\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.3594352602958679: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.990025520324707: Accuracy = 0.5174512842932607\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.3516786992549896: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.5284502506256104: Accuracy = 0.5179016780069939\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.4161486327648163: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.0096964836120605: Accuracy = 0.5177444268873238\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.4042520821094513: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.800786256790161: Accuracy = 0.5184023283774284\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.35505250096321106: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.749890089035034: Accuracy = 0.5188945461302241\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.35781070590019226: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.939307928085327: Accuracy = 0.5188409988712617\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.3900478780269623: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.950510263442993: Accuracy = 0.5191396056936148\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.38317057490348816: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.920977830886841: Accuracy = 0.5203386429054143\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.38585636019706726: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.4883906841278076: Accuracy = 0.5208637409015332\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.38420769572257996: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.1415822505950928: Accuracy = 0.5217391304347826\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.3375200629234314: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.5941479206085205: Accuracy = 0.5222048005316542\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.3714112639427185: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.411170482635498: Accuracy = 0.522777199847842\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.3091154992580414: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.1481544971466064: Accuracy = 0.5229980233300066\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.4492025375366211: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.523242950439453: Accuracy = 0.5239932842649125\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.4361099898815155: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.9268929958343506: Accuracy = 0.5244281521857401\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.3701654374599457: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.193061590194702: Accuracy = 0.5245882970386294\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.47287455201148987: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.425185441970825: Accuracy = 0.5253243288644724\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.3823412358760834: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.566603899002075: Accuracy = 0.5259758577009463\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.4676056504249573: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.35932993888855: Accuracy = 0.5257471299943254\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.44846197962760925: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.808027744293213: Accuracy = 0.5263597613461997\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.4106442630290985: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 3.2181644439697266: Accuracy = 0.5260862742718483\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.3448801040649414: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.282353639602661: Accuracy = 0.5267522029734962\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.38341882824897766: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.851640462875366: Accuracy = 0.5276325857039734\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.3793599605560303: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.664592981338501: Accuracy = 0.5284298535128958\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.3293875753879547: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.4724619388580322: Accuracy = 0.5287492340644901\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.32837238907814026: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.801692008972168: Accuracy = 0.5294920875293999\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.3941537141799927: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.3229241371154785: Accuracy = 0.5299133626028215\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.3783586621284485: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.8012092113494873: Accuracy = 0.5307490463134885\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.42263656854629517: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.1503732204437256: Accuracy = 0.531090661699414\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.42805215716362: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.491391897201538: Accuracy = 0.5322345705073364\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.38448214530944824: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.359748601913452: Accuracy = 0.5324532878157382\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.3865779638290405: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.693507671356201: Accuracy = 0.5329021215132921\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.4189540147781372: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.2360711097717285: Accuracy = 0.5326079668070234\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.35974064469337463: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.38067364692688: Accuracy = 0.5337905793694431\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.37009838223457336: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.09000301361084: Accuracy = 0.5343011742738193\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.3599087595939636: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.6268677711486816: Accuracy = 0.5343797504809138\n",
      "\n",
      "Data shuffled. Epoch:  141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.3699284493923187: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.978797674179077: Accuracy = 0.5347601505878131\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.35705697536468506: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.650428295135498: Accuracy = 0.5347882140535096\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.41277581453323364: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.4838368892669678: Accuracy = 0.5354567726272408\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.4094064235687256: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.040377140045166: Accuracy = 0.5360266328564371\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.47701722383499146: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.947176218032837: Accuracy = 0.5360991032181802\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.41771334409713745: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.2158477306365967: Accuracy = 0.5352995486143679\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.4211461544036865: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.060478448867798: Accuracy = 0.5356292982518666\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.4189920425415039: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.686774730682373: Accuracy = 0.535942552034987\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.34840744733810425: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.788059711456299: Accuracy = 0.5362500014593751\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.3488115072250366: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.9444587230682373: Accuracy = 0.536290796384013\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.315696656703949: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.986067056655884: Accuracy = 0.5367497442425906\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.32974904775619507: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.8129844665527344: Accuracy = 0.5368098427863451\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.37546396255493164: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.7899134159088135: Accuracy = 0.5371927600856848\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.33749547600746155: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.8762526512145996: Accuracy = 0.5377989981907787\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.38788026571273804: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.75770902633667: Accuracy = 0.537849848230416\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.3474993407726288: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.7187998294830322: Accuracy = 0.5385609410706607\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.3351444900035858: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.7671685218811035: Accuracy = 0.5388762446519242\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.36701393127441406: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.6400511264801025: Accuracy = 0.5385237169835443\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.38852354884147644: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.2660064697265625: Accuracy = 0.5386164958797354\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.3542996942996979: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.780604124069214: Accuracy = 0.5390158402996627\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.33300814032554626: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.1154062747955322: Accuracy = 0.5390605303801916\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.3403981029987335: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.694798469543457: Accuracy = 0.5389176821788402\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.36121833324432373: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.829396963119507: Accuracy = 0.5394976980857766\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.32643312215805054: Accuracy = 0.9066666960716248\n",
      "Performance on test set: : Loss = 2.7869179248809814: Accuracy = 0.5398930156013021\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.3436054289340973: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.5646138191223145: Accuracy = 0.5392746452221806\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.34360378980636597: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.130082130432129: Accuracy = 0.5395010071647958\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.3342379629611969: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.437760829925537: Accuracy = 0.5404232688748842\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.3619343638420105: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.7551872730255127: Accuracy = 0.5408830493996093\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.37730759382247925: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.587790012359619: Accuracy = 0.5411154742123556\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.2950323820114136: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.401618003845215: Accuracy = 0.5414119113605832\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.36687546968460083: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.027378559112549: Accuracy = 0.5419715583526142\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.3573097884654999: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.981072425842285: Accuracy = 0.5419703292437877\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.39537474513053894: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.110121726989746: Accuracy = 0.5418841650840177\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.402998685836792: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.6508023738861084: Accuracy = 0.5423493484500069\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.32817748188972473: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.3331429958343506: Accuracy = 0.5424741537936835\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.3316056728363037: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.201956272125244: Accuracy = 0.5425557659658208\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.3798816502094269: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.9013044834136963: Accuracy = 0.5426017792189025\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.36864638328552246: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.4261786937713623: Accuracy = 0.5434337781910312\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.37867191433906555: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.0917694568634033: Accuracy = 0.5438604885463016\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.3521679937839508: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.093195915222168: Accuracy = 0.5439708148173154\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.30857372283935547: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.524195671081543: Accuracy = 0.5440372472902759\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.34963417053222656: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.3816182613372803: Accuracy = 0.5441030003404778\n",
      "\n",
      "Data shuffled. Epoch:  183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.36232200264930725: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.5911686420440674: Accuracy = 0.5448382653986407\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.3765561282634735: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.1440229415893555: Accuracy = 0.544890155650886\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.3644564747810364: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.6613354682922363: Accuracy = 0.5450796547323534\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.34425848722457886: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.007601499557495: Accuracy = 0.5456266788853212\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.3362971246242523: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.6543664932250977: Accuracy = 0.5455911253391101\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.3523872494697571: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.66852068901062: Accuracy = 0.545950426014854\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.32685983180999756: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.369366407394409: Accuracy = 0.5468282222838838\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.3737780451774597: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.8641228675842285: Accuracy = 0.5468488233830051\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.39413031935691833: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.2998149394989014: Accuracy = 0.5469369921097226\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.3738558888435364: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.3117737770080566: Accuracy = 0.5472936802666664\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.3711123466491699: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.1905291080474854: Accuracy = 0.5478011476868729\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.3306563198566437: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.1525628566741943: Accuracy = 0.5489040555167953\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.32825934886932373: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.195727586746216: Accuracy = 0.5490831292323757\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.4097994267940521: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.276000738143921: Accuracy = 0.5493937235775571\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.334334135055542: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.908193588256836: Accuracy = 0.5500626037843024\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.3451818823814392: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.203948974609375: Accuracy = 0.550277124614857\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.3493858575820923: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.186187982559204: Accuracy = 0.5502466772210154\n",
      "\n",
      "Optimisation finished!\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.1739956140518188: Accuracy = 0.41333332657814026\n",
      "Performance on test set: : Loss = 1.1484673023223877: Accuracy = 0.5485232200144896\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.1516430377960205: Accuracy = 0.3199999928474426\n",
      "Performance on test set: : Loss = 1.158638596534729: Accuracy = 0.5402650536918231\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.0849026441574097: Accuracy = 0.41333332657814026\n",
      "Performance on test set: : Loss = 1.1416237354278564: Accuracy = 0.5261726697538873\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.0820012092590332: Accuracy = 0.41999998688697815\n",
      "Performance on test set: : Loss = 1.1861790418624878: Accuracy = 0.5338006831441972\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.0292476415634155: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.1802157163619995: Accuracy = 0.5605884981151974\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 1.026518702507019: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.2492073774337769: Accuracy = 0.5827855819393158\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 1.0396941900253296: Accuracy = 0.46000000834465027\n",
      "Performance on test set: : Loss = 1.1815624237060547: Accuracy = 0.5868870195254303\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 0.9066725373268127: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.259205937385559: Accuracy = 0.5968779112316245\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 0.8129129409790039: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.2950462102890015: Accuracy = 0.6201029259013802\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.857113242149353: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.1620123386383057: Accuracy = 0.6293952222566784\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.681810736656189: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.1768749952316284: Accuracy = 0.6325004374667196\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.6613525152206421: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.2503966093063354: Accuracy = 0.6353284669618855\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.5956678986549377: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.15995192527771: Accuracy = 0.6316075976117081\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.6005641222000122: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.1543680429458618: Accuracy = 0.6385770157516194\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.5863926410675049: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.070703387260437: Accuracy = 0.6424343275028668\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 0.5857587456703186: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.0668600797653198: Accuracy = 0.6476614121732855\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.5300270318984985: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 0.985060453414917: Accuracy = 0.6518767750223242\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.5591736435890198: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.0474352836608887: Accuracy = 0.6567935783686942\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.5402202606201172: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.1676249504089355: Accuracy = 0.6585366325825168\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.537847638130188: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.251347541809082: Accuracy = 0.6598216242531375\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.5396022200584412: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.065935492515564: Accuracy = 0.663808649674693\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.5833756923675537: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.018300175666809: Accuracy = 0.6675401324495785\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.5243313312530518: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.1992794275283813: Accuracy = 0.6707431552904413\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.5233781337738037: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.3509327173233032: Accuracy = 0.6716429397481851\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.5884571075439453: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.196714162826538: Accuracy = 0.6719419033636795\n",
      "\n",
      "Data shuffled. Epoch:  25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.5466911196708679: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.8497751951217651: Accuracy = 0.6721759032866961\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.5355507135391235: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.1650753021240234: Accuracy = 0.6723462046024442\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.5349249839782715: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.2941792011260986: Accuracy = 0.6743290300584335\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.5210047364234924: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.5544650554656982: Accuracy = 0.6742127375581661\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.5223917365074158: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.6382544040679932: Accuracy = 0.6750827364805178\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.5219006538391113: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.4414070844650269: Accuracy = 0.6743203922978231\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.5191549062728882: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.6043673753738403: Accuracy = 0.6754340289750119\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.5285959243774414: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.4077624082565308: Accuracy = 0.6759254285529916\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.5136030316352844: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.5060240030288696: Accuracy = 0.674337413226862\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.49875736236572266: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.4763202667236328: Accuracy = 0.6734324682274668\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.4953934848308563: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.7210198640823364: Accuracy = 0.6719220155874335\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.5195949077606201: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.9222639799118042: Accuracy = 0.6715572491986584\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.47370392084121704: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.4822142124176025: Accuracy = 0.6702222142809094\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.5076009631156921: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.9786481857299805: Accuracy = 0.6702942266311017\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.47547364234924316: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.3410992622375488: Accuracy = 0.669048811544917\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.5013675689697266: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.5774129629135132: Accuracy = 0.6690538763631263\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.4849332571029663: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.8374133110046387: Accuracy = 0.6671758219604953\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.49420180916786194: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.7989822626113892: Accuracy = 0.664464448855282\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.4962516129016876: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.5925209522247314: Accuracy = 0.6646304894418885\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.523864209651947: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.659546971321106: Accuracy = 0.6632080940354947\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.47390517592430115: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.7911454439163208: Accuracy = 0.6624493391666186\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.49806085228919983: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.634108304977417: Accuracy = 0.6620477192380414\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.5268146395683289: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.9932085275650024: Accuracy = 0.6601671620769883\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.4687526822090149: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.923287272453308: Accuracy = 0.6591681213115416\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.47132501006126404: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.7255479097366333: Accuracy = 0.6581016122740175\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.49496668577194214: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 3.3506531715393066: Accuracy = 0.6566939386249218\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.5266698598861694: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.6181596517562866: Accuracy = 0.6554528529596955\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.4516976475715637: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.855186104774475: Accuracy = 0.6530924119521287\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.4621342420578003: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.8131340742111206: Accuracy = 0.6521055822234081\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.47482284903526306: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.7321375608444214: Accuracy = 0.6503904763436191\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.42775416374206543: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.029991626739502: Accuracy = 0.6493407570965055\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.4770190417766571: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.9136251211166382: Accuracy = 0.6487700633516422\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.5128393173217773: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.64154052734375: Accuracy = 0.6470726712560453\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.46025964617729187: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.488842725753784: Accuracy = 0.645201804989765\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.4752849340438843: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.0866596698760986: Accuracy = 0.6450019788212691\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.5192057490348816: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 3.301304817199707: Accuracy = 0.6432348183746651\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.4106896221637726: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.285238742828369: Accuracy = 0.6415011040114021\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.4212894141674042: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.725039482116699: Accuracy = 0.639930185003603\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.47336089611053467: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.994401454925537: Accuracy = 0.6385449459306726\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.42650648951530457: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.4630229473114014: Accuracy = 0.6362809113076193\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.46568745374679565: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.491342544555664: Accuracy = 0.6349605121475155\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.47029587626457214: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.3059580326080322: Accuracy = 0.6338281482331941\n",
      "\n",
      "Data shuffled. Epoch:  67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.45638900995254517: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.9758070707321167: Accuracy = 0.6328207299729787\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.47272536158561707: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.0114290714263916: Accuracy = 0.6329056059463741\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.4132501184940338: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.7026076316833496: Accuracy = 0.6317072234188071\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.4271678030490875: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.392810821533203: Accuracy = 0.6306331766925168\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.4249647259712219: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.3841047286987305: Accuracy = 0.6293644355865733\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.44606974720954895: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 3.3663418292999268: Accuracy = 0.6291773312794023\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.4356512427330017: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.599431037902832: Accuracy = 0.6284745586914892\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.38484662771224976: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.5018222332000732: Accuracy = 0.6271037458100646\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.433564692735672: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.8749053478240967: Accuracy = 0.626839103849528\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.431325227022171: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.1888277530670166: Accuracy = 0.625155614714557\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.41904231905937195: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.4552526473999023: Accuracy = 0.6234259306025557\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.432569682598114: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.88956356048584: Accuracy = 0.6218785781877585\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.45205193758010864: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.373682975769043: Accuracy = 0.620565209729756\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.4510411024093628: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.211205005645752: Accuracy = 0.6192646794135157\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.43518367409706116: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 3.0763118267059326: Accuracy = 0.6188378215084783\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.3925011157989502: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.5634562969207764: Accuracy = 0.6174819102990586\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.4262525737285614: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.5538620948791504: Accuracy = 0.6175022179213971\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.35748159885406494: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.718606472015381: Accuracy = 0.6166571804789821\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.4706312119960785: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.1797640323638916: Accuracy = 0.6158767047438723\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.3840966522693634: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.1286356449127197: Accuracy = 0.6152604424266094\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.4081100523471832: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.7237753868103027: Accuracy = 0.6140743764108215\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.4170757234096527: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.028153419494629: Accuracy = 0.6137066676196198\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.41403263807296753: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.3842837810516357: Accuracy = 0.6127338202625423\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.39159488677978516: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.2187492847442627: Accuracy = 0.6117599976643815\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.41481366753578186: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.235130786895752: Accuracy = 0.6109323605851729\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.4562305808067322: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.1069843769073486: Accuracy = 0.6102539263458653\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.3902512788772583: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.100616216659546: Accuracy = 0.6096974987980475\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.3876435458660126: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.0330262184143066: Accuracy = 0.608394279252192\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.4095061719417572: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.6253631114959717: Accuracy = 0.6080258891491418\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.39480575919151306: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.2819414138793945: Accuracy = 0.6077863435566105\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.39498665928840637: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.812652349472046: Accuracy = 0.6066798274958264\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.39831098914146423: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.3351902961730957: Accuracy = 0.6060593614164875\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.38914400339126587: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 4.038787364959717: Accuracy = 0.6056830770248595\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.4266480505466461: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 3.722972869873047: Accuracy = 0.6042322740068397\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.4448005259037018: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.0828537940979004: Accuracy = 0.6041244323424478\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.38199764490127563: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.468831777572632: Accuracy = 0.6044452934433867\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.4532790184020996: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.5511739253997803: Accuracy = 0.602965870008417\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.4111565053462982: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.1666884422302246: Accuracy = 0.601969933736972\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.3789469003677368: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.6951091289520264: Accuracy = 0.601982328961876\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.38099274039268494: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.3452799320220947: Accuracy = 0.6017675382274791\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.42941609025001526: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.7488250732421875: Accuracy = 0.601541181069208\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.4230038821697235: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.637101173400879: Accuracy = 0.6014450656082383\n",
      "\n",
      "Data shuffled. Epoch:  109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.42932674288749695: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.9211859703063965: Accuracy = 0.60057772670456\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.41674646735191345: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.285639524459839: Accuracy = 0.60013588900352\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.39842379093170166: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.311455011367798: Accuracy = 0.6001454625563811\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.44872498512268066: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.776102066040039: Accuracy = 0.5994445389909991\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.3618215024471283: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.954038143157959: Accuracy = 0.5992133030405715\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.3956238329410553: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.550239086151123: Accuracy = 0.5991312820639886\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.3760928809642792: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.7613143920898438: Accuracy = 0.5986315532831945\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.4236496388912201: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.9865074157714844: Accuracy = 0.5977693647890474\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.3783666491508484: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.931936025619507: Accuracy = 0.5978239908100987\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.464321494102478: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.2707738876342773: Accuracy = 0.5981734359703333\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.3993331789970398: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.371656894683838: Accuracy = 0.5979167685294576\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.36080431938171387: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.0317654609680176: Accuracy = 0.5979718600942444\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.3966621160507202: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.408402442932129: Accuracy = 0.5973313667950183\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.3794911503791809: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.6832275390625: Accuracy = 0.5973832093311162\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.3458355963230133: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.8643791675567627: Accuracy = 0.5968031281367226\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.435067355632782: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.809114694595337: Accuracy = 0.5961862158074767\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.2813604176044464: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.9728403091430664: Accuracy = 0.5960144676401772\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.38995397090911865: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 4.439940452575684: Accuracy = 0.5960192591807785\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.38189393281936646: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.949484348297119: Accuracy = 0.5957779579098668\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.3993094265460968: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 5.012358665466309: Accuracy = 0.5953452776629623\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.3476186692714691: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.2141530513763428: Accuracy = 0.5950181716474401\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.3954223096370697: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.266860008239746: Accuracy = 0.5950689702884938\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.3465786874294281: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.6946566104888916: Accuracy = 0.5951038567207753\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.37307748198509216: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.031608819961548: Accuracy = 0.5958511558855485\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.37439197301864624: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.4885714054107666: Accuracy = 0.595513666649817\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.3626573979854584: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.8627054691314697: Accuracy = 0.595541193993773\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.3480836749076843: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.380420207977295: Accuracy = 0.5960902968655748\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.32887715101242065: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.4181668758392334: Accuracy = 0.5959293027750575\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.3231973946094513: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.029088258743286: Accuracy = 0.5966889688588406\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.41891932487487793: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.2593986988067627: Accuracy = 0.5967886215182552\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.45877355337142944: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.147487163543701: Accuracy = 0.5963017312664393\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.35966402292251587: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.166142463684082: Accuracy = 0.5965171364378349\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.37872931361198425: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.997610092163086: Accuracy = 0.5964841979945215\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.41808658838272095: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.0897305011749268: Accuracy = 0.595831044989512\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.3566441833972931: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.7238690853118896: Accuracy = 0.5965563760510939\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.45074138045310974: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.7257120609283447: Accuracy = 0.5966874218597336\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.4363265335559845: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.9707250595092773: Accuracy = 0.5961651167083717\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.3904077708721161: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.737377166748047: Accuracy = 0.5959346257664425\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.4106152653694153: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.1904234886169434: Accuracy = 0.596380773140195\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.3374146521091461: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.613959312438965: Accuracy = 0.5961076830659483\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.40604352951049805: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.4794013500213623: Accuracy = 0.5963803430182563\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.3621384799480438: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.6392524242401123: Accuracy = 0.5964290018285561\n",
      "\n",
      "Data shuffled. Epoch:  151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.41530469059944153: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.34248423576355: Accuracy = 0.5965821663575879\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.3916817307472229: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.298912525177002: Accuracy = 0.5967759238933867\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.3263241946697235: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.1404740810394287: Accuracy = 0.597039041957416\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.36564767360687256: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.35819673538208: Accuracy = 0.5968997758625006\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.42741841077804565: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.301903009414673: Accuracy = 0.5969852498730399\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.3705125153064728: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.4868266582489014: Accuracy = 0.5969784207048341\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.3291530907154083: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.79995059967041: Accuracy = 0.5973133479176577\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.39604243636131287: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.5680623054504395: Accuracy = 0.5973792752667616\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.38589826226234436: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.382451057434082: Accuracy = 0.5976281411549239\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.3873431086540222: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.5226736068725586: Accuracy = 0.5976350397773156\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.3260994553565979: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.7361013889312744: Accuracy = 0.5972278465845838\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.3669097423553467: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.5287563800811768: Accuracy = 0.5972851422890054\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.43787866830825806: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.4619622230529785: Accuracy = 0.5970443099425345\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.37045779824256897: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.09680438041687: Accuracy = 0.5977517948298215\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.33969971537590027: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.7100436687469482: Accuracy = 0.5975654436595639\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.35032933950424194: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.578151226043701: Accuracy = 0.5973934013709156\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.3991425037384033: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.655862331390381: Accuracy = 0.5972140952292134\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.3684801757335663: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.2970221042633057: Accuracy = 0.5975020626413862\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.4218466579914093: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 3.9607415199279785: Accuracy = 0.5978581493925883\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.37915369868278503: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.2107553482055664: Accuracy = 0.5977897548236429\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.33528459072113037: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.093761444091797: Accuracy = 0.5976755164902975\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.3303452730178833: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.207944631576538: Accuracy = 0.597618774560075\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.36911433935165405: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.1601672172546387: Accuracy = 0.5976772017011461\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.38389256596565247: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.4243099689483643: Accuracy = 0.5980291870183282\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.3727686405181885: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.7641866207122803: Accuracy = 0.5982329778090482\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.3845832049846649: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.6428072452545166: Accuracy = 0.5983787828542111\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.32564446330070496: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.6780781745910645: Accuracy = 0.5983579143211806\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.38368889689445496: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.3477091789245605: Accuracy = 0.5988162923466115\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.31599608063697815: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.4885036945343018: Accuracy = 0.5986753824810843\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.41615739464759827: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.4954111576080322: Accuracy = 0.5992303583834452\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.3682413101196289: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.4728963375091553: Accuracy = 0.5994943428357654\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.40100401639938354: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.9543190002441406: Accuracy = 0.5998643641024933\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.35458388924598694: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.397865056991577: Accuracy = 0.5998452215839915\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.37487441301345825: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 4.323259353637695: Accuracy = 0.5996414066212098\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.37273579835891724: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.353314161300659: Accuracy = 0.5996739766423377\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.3291160464286804: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.1784017086029053: Accuracy = 0.5999804127354277\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.38375717401504517: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.932621479034424: Accuracy = 0.6006120748018783\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.37900277972221375: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.157217025756836: Accuracy = 0.6004927392017724\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.35542821884155273: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.3430237770080566: Accuracy = 0.6010951365663059\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.4327380955219269: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.9452064037323: Accuracy = 0.6010023233686466\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.3904111087322235: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 3.1908586025238037: Accuracy = 0.6012060521291218\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.3607514202594757: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.5406150817871094: Accuracy = 0.6013783181470909\n",
      "\n",
      "Data shuffled. Epoch:  193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.3299492597579956: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.509446620941162: Accuracy = 0.6012059209939817\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.3813638389110565: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.4549145698547363: Accuracy = 0.6009105225883493\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.2997725009918213: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 3.3590760231018066: Accuracy = 0.601162412135993\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.37630903720855713: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.2964460849761963: Accuracy = 0.6009114803520916\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.3218667507171631: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.6977949142456055: Accuracy = 0.6012226974035209\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.34943366050720215: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.5721163749694824: Accuracy = 0.6010819520091573\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.3426089286804199: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.399834632873535: Accuracy = 0.6009730916875203\n",
      "\n",
      "Optimisation finished!\n"
     ]
    }
   ],
   "source": [
    "%run trainRNN_utils.py\n",
    "%run trainRNN_network_utils.py\n",
    "\n",
    "trainLosses = {}\n",
    "testLosses = {}\n",
    "F1_scores = {}\n",
    "trainAccuracy = {}\n",
    "attention_matrixA = {}\n",
    "attention_matrixB = {}\n",
    "tst_prediction = {}\n",
    "\n",
    "for dropout in dropouts:\n",
    "\n",
    "    # Create network\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Gene A and Gene B input and output placeholders\n",
    "    ## Input placeholders\n",
    "    with tf.variable_scope('geneA'):\n",
    "\n",
    "        rSnpRnaA_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum + 1, iSnum])\n",
    "\n",
    "        hidden_output_A, current_state_A = dynamicLSTM_Attention(rSnpRnaA_pXNS, \n",
    "                                                                 n_layer, \n",
    "                                                                 n_hidden, \n",
    "                                                                 dropout)\n",
    "\n",
    "    hidden_state_A = current_state_A[-1].h\n",
    "\n",
    "    with tf.variable_scope('geneB'):\n",
    "\n",
    "        rSnpRnaB_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum + 1, iSnum])\n",
    "\n",
    "        hidden_output_B, current_state_B = dynamicLSTM_Attention(rSnpRnaB_pXNS, \n",
    "                                                                 n_layer, \n",
    "                                                                 n_hidden, \n",
    "                                                                 dropout)\n",
    "\n",
    "    hidden_state_B = current_state_B[-1].h\n",
    "\n",
    "    rRelated_pXC = tf.placeholder(tf.float32, \n",
    "                                  shape = [None, iCnum],\n",
    "                                  name = 'rRelated_pXC')\n",
    "\n",
    "    context_vectorA, attention_weightsA = attention(hidden_state_A, hidden_output_A, n_hidden)\n",
    "    context_vectorB, attention_weightsB = attention(hidden_state_B, hidden_output_B, n_hidden)\n",
    "\n",
    "    encoding = tf.concat((context_vectorA, context_vectorB), axis=1)\n",
    "\n",
    "    # Dense Layer\n",
    "    logits = tf.layers.dense(encoding,\n",
    "                            units = n_classes, \n",
    "                            activation = None,\n",
    "                            kernel_regularizer=tf.contrib.layers.l2_regularizer(0.4),\n",
    "                            kernel_initializer = tf.initializers.random_normal() )\n",
    "\n",
    "    prediction = tf.argmax(logits, 1)\n",
    "\n",
    "    l2 = lambda_l2_reg * sum(\n",
    "        tf.nn.l2_loss(tf_var)\n",
    "            for tf_var in tf.trainable_variables()\n",
    "            if not (\"bias\" in tf_var.name))\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                                         labels=tf.argmax(rRelated_pXC,1)) + l2)\n",
    "\n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Accuracy; precision, and recall for f1 score\n",
    "    correct_pred = tf.equal(prediction, tf.argmax(rRelated_pXC,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Precision and recall\n",
    "    rec, rec_op = tf.metrics.recall(labels = tf.argmax(rRelated_pXC, 1), predictions = prediction)\n",
    "    pre, pre_op = tf.metrics.precision(labels = tf.argmax(rRelated_pXC, 1), predictions = prediction)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        \n",
    "        # Train the network \n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        train_f1_score = [None] * n_epoch\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        test_f1_score = []\n",
    "\n",
    "        # Reshape and retrive the merged training and test data\n",
    "        rSnpRnaA_tr_nXNS = input_reshape(rSnpA_tr_nXSN, rRnaA_tr_nXS)\n",
    "        rSnpRnaB_tr_nXNS = input_reshape(rSnpB_tr_nXSN, rRnaB_tr_nXS)\n",
    "        rSnpRnaA_tst_nXNS = input_reshape(rSnpA_tst_nXSN, rRnaA_tst_nXS)\n",
    "        rSnpRnaB_tst_nXNS = input_reshape(rSnpB_tst_nXSN, rRnaB_tst_nXS)\n",
    "\n",
    "        for epoch_idx in range(n_epoch): \n",
    "\n",
    "            print(\"Data shuffled.\" + \\\n",
    "                  \" Epoch: \", epoch_idx)\n",
    "\n",
    "            # Shuffle classes\n",
    "            rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS = shuffle_classes(rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS)\n",
    "\n",
    "            for batch_idx in range(n_batch):\n",
    "\n",
    "                batch_rSnpRnaA_tXNS = extract_batch_size(rSnpRnaA_tr_nXNS, batch_idx, batch_size)\n",
    "                batch_rSnpRnaB_tXNS = extract_batch_size(rSnpRnaB_tr_nXNS, batch_idx, batch_size)\n",
    "                batch_rRelated_tXC = extract_batch_size(rRelated_tr_nXC, batch_idx, batch_size)\n",
    "\n",
    "                # Fit training data\n",
    "                opt, tr_loss, tr_acc = sess.run(\n",
    "                    [optimiser, cost, accuracy], \n",
    "                    feed_dict = {\n",
    "                        rSnpRnaA_pXNS: batch_rSnpRnaA_tXNS,\n",
    "                        rSnpRnaB_pXNS: batch_rSnpRnaB_tXNS,\n",
    "                        rRelated_pXC: batch_rRelated_tXC               \n",
    "                    })\n",
    "\n",
    "                tst_loss, tst_pre, _, tst_rec, _ = sess.run(\n",
    "                    [cost, pre, pre_op, rec, rec_op],\n",
    "                    feed_dict = {\n",
    "                        rSnpRnaA_pXNS: rSnpRnaA_tst_nXNS,\n",
    "                        rSnpRnaB_pXNS: rSnpRnaB_tst_nXNS,\n",
    "                        rRelated_pXC: rRelated_tst_nXC\n",
    "                    })            \n",
    "\n",
    "                if batch_idx == (n_batch - 1):\n",
    "\n",
    "                    train_losses.append(tr_loss)\n",
    "                    train_accuracies.append(tr_acc)\n",
    "\n",
    "                    tst_f1_score = 2 * ( tst_rec * tst_pre ) / (tst_rec + tst_pre) \n",
    "\n",
    "                    test_losses.append(tst_loss)\n",
    "                    test_f1_score.append(tst_f1_score)\n",
    "\n",
    "            print(\"Performance on training data\" + \n",
    "                 \": Loss = {}\".format(tr_loss) + \n",
    "                 \": Accuracy = {}\".format( tr_acc ) )\n",
    "\n",
    "            print(\"Performance on test set: \" + \n",
    "                  \": Loss = {}\".format(tst_loss) + \n",
    "                  \": Accuracy = {}\".format(tst_f1_score) )\n",
    "            print(\"\")\n",
    "            \n",
    "\n",
    "            if epoch_idx == (n_epoch-1):\n",
    "\n",
    "                for i in range(rSnpRnaA_tst_nXNS.shape[0]):\n",
    "                    rSnpRnaA_tst_nXNSA = np.expand_dims(rSnpRnaA_tst_nXNS[i], axis=0)\n",
    "                    rSnpRnaB_tst_nXNSB = np.expand_dims(rSnpRnaB_tst_nXNS[i], axis=0)\n",
    "                    rRelated_tst_nXC_ = np.expand_dims(rRelated_tst_nXC[i], axis=0)\n",
    "\n",
    "                    pred, at_weightA, at_weightB = sess.run(\n",
    "                        [prediction, attention_weightsA, attention_weightsB],\n",
    "                        feed_dict = {\n",
    "                                rSnpRnaA_pXNS: rSnpRnaA_tst_nXNSA,\n",
    "                                rSnpRnaB_pXNS: rSnpRnaB_tst_nXNSB,\n",
    "                                rRelated_pXC: rRelated_tst_nXC_\n",
    "                                }) \n",
    "\n",
    "                    at_weightA = np.reshape(at_weightA, (-1, 1))\n",
    "                    at_weightB = np.reshape(at_weightB, (-1, 1))\n",
    "\n",
    "                    attention_matrixA[dropout] = at_weightA\n",
    "                    attention_matrixB[dropout] = at_weightB                    \n",
    "                    tst_prediction[dropout] = pred\n",
    "    \n",
    "        trainLosses[dropout] = train_losses\n",
    "        testLosses[dropout] = test_losses\n",
    "        trainAccuracy[dropout] = train_accuracies\n",
    "        F1_scores[dropout] = test_f1_score\n",
    "        print(\"Optimisation finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run trainRNN_plot_utils.py\n",
    "plot_inputs(F1_scores, trainLosses, testLosses, n_epoch, \"Dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved into pickle.\n"
     ]
    }
   ],
   "source": [
    "# SAVE DATA\n",
    "# Save the created samples, such tha the NNs can load them easily\n",
    "\n",
    "# Save data into Python friendly file\n",
    "import pickle\n",
    "with open('resultsAttentionDropout_HBTRC.pickle', 'wb') as f:\n",
    "    pickle.dump( rSnpRnaA_tst_nXNS, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( rSnpRnaB_tst_nXNS, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( trainLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( testLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( F1_scores, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( trainAccuracy, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( attention_matrixA, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( attention_matrixB, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( tst_prediction, f, pickle.HIGHEST_PROTOCOL )\n",
    "    print( 'Data saved into pickle.' )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
