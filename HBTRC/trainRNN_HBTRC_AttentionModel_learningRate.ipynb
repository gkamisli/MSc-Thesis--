{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Explanation\n",
    "\n",
    "**trainRNN_HBTRC_AttentionModel_learningRate.ipynb:**\n",
    "<br> This notebook is to load HBTRC examples from 'preprocessData.pickle', create an \"Attention Network\" and train the network with respect to a range of learning rates\n",
    "\n",
    "**Processes are as follows:**\n",
    "<br> 1) Load all variables from 'preprocessData_HBTRC.pickle'\n",
    "<br> 2) Parameter and hyperparameter assignments (location: **3rd cell**)\n",
    "<br> 3) Create LSTM cells with Dropout Wrappers for gene A and gene B (function: **dropoutWrapper** in **trainRNN_network_utils.py**)\n",
    "<br> 4) Using LSTM cells, create multi-layer dynamic model from fixed length sequences (function: **dynamicLSTM_Attention** in **trainRNN_network_utils.py**)\n",
    "<br> 5) Create an attention mechanism based on a fully-connected layer of states and output, which is followed by a tanh layer to calculate scores. Then, calculate attention weights and context vector using softmax and dense layers \n",
    "<br> 6) Create a single output from a concatenation of context vectors of gene A and gene B\n",
    "<br> 7) Pass the output through a **dense** layer and make prediction\n",
    "<br> 8) Before starting the training: concatenate rSnpG_tr_nXSN and rRnaG_nXS where G represents gene A and gene B (function: **input_reshape** in **trainRNN_utils.py**)\n",
    "<br> 9) Train the network: every epoch (i.e., iteration) shuffle the data within each class (function: **shuffle_classes** in **trainRNN_utils.py**) and train in batches (function: **extract_batch_size** in **trainRNN_utils.py**)\n",
    "<br> 10) Plot results with **plot_inputs** in **trainRNN_plot_utils.py**)\n",
    "<br> 11) Save them in \"resultsAttentionLearningRate_HBTRC.pickle\" to be called when necessary\n",
    "\n",
    "**Variables created:**\n",
    "<br> 1) **trainLosses**: Train losses, dictionary, keys of ([0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "<br> 2) **testLosses**: Test losses, dictionary, keys of ([0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "<br> 3) **F1_scores**: F1_scores, dictionary, keys of ([0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "<br> 4) **trainAccuracy**: Train accuracy, dictionary, keys of ([0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "<br> 5) **attention_matrixA**: Attention weights of gene A, dictionary, keys of ([0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "<br> 6) **attention_matrixB**: Attention weights of gene B, dictionary, keys of ([0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "<br> 7) **tst_prediction**: Test predictions, dictionary, keys of ([0.1, 0.01, 0.001, 0.0001, 0.00001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.core.debugger import set_trace #set_trace()\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[ \"CUDA_VISIBLE_DEVICES\" ] = \"3\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from pickle.\n",
      "All samples loaded\n",
      "Number of training samples (transcripts) of gene A: 1500\n",
      "Number of training samples (transcripts) of gene B: 1500\n",
      "Number of test samples (transcripts) of gene A: 45\n",
      "Number of test samples (transcripts) of gene B: 45\n",
      "Number of subjects iSnum: 434\n",
      "Number of SNPs iNnum: 100\n",
      "Number of association classes iCnum: 3\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "# Load data form the pickle produced by \"preprocessData_HBTRC.ipynb\"\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('preprocessData_HBTRC.pickle', 'rb') as f:\n",
    "    rSnpA_nXSN = pickle.load( f )\n",
    "    rSnpB_nXSN = pickle.load( f )\n",
    "    rRnaA_nXS = pickle.load( f )\n",
    "    rRnaB_nXS = pickle.load( f )\n",
    "    rRelated_nXC = pickle.load( f )\n",
    "    rSnpA_tr_nXSN = pickle.load( f )\n",
    "    rSnpB_tr_nXSN = pickle.load( f )\n",
    "    rRnaA_tr_nXS = pickle.load( f )\n",
    "    rRnaB_tr_nXS = pickle.load( f )\n",
    "    rRelated_tr_nXC = pickle.load( f )\n",
    "    rSnpA_tst_nXSN = pickle.load( f )\n",
    "    rSnpB_tst_nXSN = pickle.load( f )\n",
    "    rRnaA_tst_nXS = pickle.load( f )\n",
    "    rRnaB_tst_nXS = pickle.load( f )\n",
    "    rRelated_tst_nXC = pickle.load( f )\n",
    "    sGeneNames_nX2 = pickle.load( f )\n",
    "    sGeneNames_tr_nX2 = pickle.load( f )\n",
    "    sGeneNames_tst_nX2 = pickle.load( f )\n",
    "    nRs = pickle.load( f )\n",
    "    nSs = pickle.load( f )\n",
    "    print( 'Data loaded from pickle.' )\n",
    "\n",
    "\n",
    "# Check the input dimensions\n",
    "assert( len( rSnpA_nXSN.shape ) == 3 )\n",
    "assert( len( rSnpB_nXSN.shape ) == 3 )\n",
    "assert( len( rRnaA_nXS.shape ) == 2 )\n",
    "assert( len( rRnaB_nXS.shape ) == 2)\n",
    "assert( len( rRelated_nXC.shape ) == 2 )\n",
    "assert( len( rSnpA_tr_nXSN.shape ) == 3 )\n",
    "assert( len( rSnpB_tr_nXSN.shape ) == 3 )\n",
    "assert( len( rRnaA_tr_nXS.shape ) == 2 )\n",
    "assert( len( rRnaB_tr_nXS.shape ) == 2 )\n",
    "assert( len( rRelated_tr_nXC.shape ) == 2 )\n",
    "assert( len( rSnpA_tst_nXSN.shape ) == 3 )\n",
    "assert( len( rSnpB_tst_nXSN.shape ) == 3 )\n",
    "assert( len( rRnaA_tst_nXS.shape ) == 2 )\n",
    "assert( len( rRnaB_tst_nXS.shape ) == 2 )\n",
    "assert( len( rRelated_tst_nXC.shape ) == 2)\n",
    "assert( rSnpA_nXSN.shape[ 0 ] == rRnaA_nXS.shape[0] )\n",
    "assert( rSnpA_nXSN.shape[ 0 ] == rRnaB_nXS.shape[0] )\n",
    "assert( rSnpB_nXSN.shape[ 0 ] == rRnaA_nXS.shape[0] )\n",
    "assert( rSnpB_nXSN.shape[ 0 ] == rRnaB_nXS.shape[0] )\n",
    "assert( rSnpA_nXSN.shape[ 0 ] == rRelated_nXC.shape[ 0 ] )\n",
    "assert( rSnpA_nXSN.shape[ 1 ] == rRnaA_nXS.shape[ 1 ] )\n",
    "assert( rSnpB_nXSN.shape[ 1 ] == rRnaB_nXS.shape[ 1 ] )\n",
    "assert( rRelated_nXC.shape[ 1 ] == 3 )\n",
    "\n",
    "iSnum = rSnpA_nXSN.shape[ 1 ] # Number of subjects\n",
    "iNnum = rSnpA_nXSN.shape[ 2 ] # Number of snps\n",
    "iCnum = rRelated_nXC.shape[ 1 ] # Number of classes\n",
    "\n",
    "print('All samples loaded' )\n",
    "print('Number of training samples (transcripts) of gene A: {}'.format( rSnpA_tr_nXSN.shape[ 0 ] ) )\n",
    "print('Number of training samples (transcripts) of gene B: {}'.format( rSnpB_tr_nXSN.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene A: {}'.format( rSnpA_tst_nXSN.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene B: {}'.format( rSnpB_tst_nXSN.shape[ 0 ] ) )\n",
    "print('Number of subjects iSnum: {}'.format( rSnpA_nXSN.shape[ 1 ] ) )\n",
    "print('Number of SNPs iNnum: {}'.format( rSnpA_nXSN.shape[ 2 ] ) )\n",
    "print('Number of association classes iCnum: {}'.format( rRelated_nXC.shape[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "## Input data\n",
    "time_steps = iNnum + 1                              # number of snps + number of rnas\n",
    "n_input = iSnum                                     # number of subjects\n",
    "\n",
    "## LSTM's internal structure\n",
    "n_hidden = 32                                       # number of nodes in hidden layer \n",
    "n_classes = iCnum                                   # number of classes\n",
    "n_layer = 3                                         # number of layers\n",
    "dropout = 0.4                                       # dropout percentage\n",
    "\n",
    "## Training data\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "batch_size = 150\n",
    "n_epoch = 200\n",
    "n_batch = rSnpA_tr_nXSN.shape[0] // batch_size   # number of batches\n",
    "lambda_l2_reg = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/HBTRC/trainRNN_network_utils.py:15: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/HBTRC/trainRNN_network_utils.py:70: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/HBTRC/trainRNN_network_utils.py:74: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/HBTRC/trainRNN_network_utils.py:99: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:1472: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:2176: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.9121828079223633: Accuracy = 0.35333332419395447\n",
      "Performance on test set: : Loss = 1.9455277919769287: Accuracy = 0.5867768470801786\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.9828503131866455: Accuracy = 0.47333332896232605\n",
      "Performance on test set: : Loss = 2.207718849182129: Accuracy = 0.6480144571882208\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.891689419746399: Accuracy = 0.47333332896232605\n",
      "Performance on test set: : Loss = 2.303703784942627: Accuracy = 0.6983606578313838\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.8560079336166382: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 2.1986734867095947: Accuracy = 0.7014562872347853\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.739509105682373: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 2.1420023441314697: Accuracy = 0.6754475412651074\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 1.6863903999328613: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 2.5453054904937744: Accuracy = 0.6535756180905054\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 1.6787745952606201: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 2.448699712753296: Accuracy = 0.6100079218583171\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 1.602671504020691: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 2.2804338932037354: Accuracy = 0.5827941780261545\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 1.5272889137268066: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.3009822368621826: Accuracy = 0.573650099401158\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 1.598723292350769: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 2.156789541244507: Accuracy = 0.5644365611974702\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 1.5928515195846558: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 2.375947952270508: Accuracy = 0.5664739881452033\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 1.703754186630249: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.5610907077789307: Accuracy = 0.5633849816814696\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 2.005829334259033: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 2.5349955558776855: Accuracy = 0.5646697097339678\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 2.0688109397888184: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 3.022094964981079: Accuracy = 0.562714779959925\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 2.26078724861145: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 2.748765707015991: Accuracy = 0.5551053723585496\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 2.913400173187256: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 3.326308250427246: Accuracy = 0.5470391974327458\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 2.8364086151123047: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 3.7478959560394287: Accuracy = 0.5395587432110087\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 2.731722116470337: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 3.54689884185791: Accuracy = 0.53088284505523\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 2.5166175365448: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 3.842346429824829: Accuracy = 0.5238148568444094\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 2.308396577835083: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 3.357732057571411: Accuracy = 0.5183612697420207\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 2.0637145042419434: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 3.113828420639038: Accuracy = 0.5166396159817476\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 1.992045521736145: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 3.390150308609009: Accuracy = 0.5169500081149434\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 1.879410982131958: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 3.265223264694214: Accuracy = 0.5157385202002499\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 1.8510843515396118: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 2.8970162868499756: Accuracy = 0.5115360612554205\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 1.7224109172821045: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.767322063446045: Accuracy = 0.5087947322011079\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 1.6910054683685303: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.6536190509796143: Accuracy = 0.5083472817257424\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 1.6179629564285278: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 2.443650007247925: Accuracy = 0.5028747126844\n",
      "\n",
      "Data shuffled. Epoch:  27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 1.7186532020568848: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.6994285583496094: Accuracy = 0.4955557133014684\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 1.5348312854766846: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.5223984718322754: Accuracy = 0.48942182678504936\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 1.5844789743423462: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 2.734052896499634: Accuracy = 0.48564858861973026\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 1.5665172338485718: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.366190195083618: Accuracy = 0.4798497705187726\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 1.5422395467758179: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 3.119229555130005: Accuracy = 0.4787151929943121\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 1.5868574380874634: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.6814703941345215: Accuracy = 0.47655985684930313\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 1.4016129970550537: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 3.040743589401245: Accuracy = 0.4725995338227917\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 1.3478566408157349: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.6904916763305664: Accuracy = 0.46963040887517304\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 1.2392873764038086: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.841848373413086: Accuracy = 0.467674865032597\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 1.2616970539093018: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.9760745763778687: Accuracy = 0.46464395883996573\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 1.2858468294143677: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.628469228744507: Accuracy = 0.46201884423921946\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 1.3443059921264648: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 2.479376792907715: Accuracy = 0.45673274334294806\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 1.255346417427063: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.6311635971069336: Accuracy = 0.45272799197265184\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 1.174700379371643: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 2.0759410858154297: Accuracy = 0.45329731760001635\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 1.1345186233520508: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 2.472170352935791: Accuracy = 0.45666612982883215\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 1.0627769231796265: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 2.2619900703430176: Accuracy = 0.4562439451567614\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 1.211409091949463: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 2.328838586807251: Accuracy = 0.45689115538264335\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 1.2816416025161743: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 2.350965976715088: Accuracy = 0.45612229610381033\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 1.1517196893692017: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 2.4702444076538086: Accuracy = 0.45302589585100794\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 1.137420654296875: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.1572635173797607: Accuracy = 0.4526663564438173\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 1.099116563796997: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 2.567758083343506: Accuracy = 0.45041642541650384\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 1.0290499925613403: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.3076748847961426: Accuracy = 0.44786911287176506\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.9875801801681519: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 2.9066531658172607: Accuracy = 0.44739052896047377\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.9816220998764038: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.1693928241729736: Accuracy = 0.4454224633803477\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 1.0557773113250732: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.6417686939239502: Accuracy = 0.4479124749055101\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 1.2727009057998657: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.2518961429595947: Accuracy = 0.4507524128790239\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 1.3269931077957153: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 2.006962299346924: Accuracy = 0.4554659174231373\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 1.2659014463424683: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 2.1984424591064453: Accuracy = 0.456107795124363\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 1.1263433694839478: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.8457685708999634: Accuracy = 0.4575115062803221\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 1.0984569787979126: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.986446499824524: Accuracy = 0.4592839256714688\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 1.1560306549072266: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.1498403549194336: Accuracy = 0.45951879064454626\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 1.121917486190796: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.459338426589966: Accuracy = 0.45893019816429587\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 1.0669702291488647: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.9460581541061401: Accuracy = 0.4597461851732005\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 1.0640171766281128: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.9145922660827637: Accuracy = 0.46260404713978176\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 1.0162135362625122: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.8849279880523682: Accuracy = 0.463118697028997\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.8804037570953369: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.9931291341781616: Accuracy = 0.4646775004809773\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.9227831959724426: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.9132963418960571: Accuracy = 0.4660892132578658\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.9104406833648682: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.7904554605484009: Accuracy = 0.46786562235176965\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.9191600680351257: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.286651372909546: Accuracy = 0.46809988891411913\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.943922221660614: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.8355724811553955: Accuracy = 0.4678254308421176\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.9782752394676208: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.6651976108551025: Accuracy = 0.469354032003547\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 1.0513081550598145: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.25931453704834: Accuracy = 0.4686356472962837\n",
      "\n",
      "Data shuffled. Epoch:  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.9704129099845886: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 2.055281162261963: Accuracy = 0.4680097361007157\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.8906455636024475: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.869518756866455: Accuracy = 0.46867416883225094\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.9247666597366333: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 2.6579179763793945: Accuracy = 0.46828330328530016\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.8622519969940186: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 2.175828456878662: Accuracy = 0.46756682309353254\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 1.1260111331939697: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.9055734872817993: Accuracy = 0.4679200954726632\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.9477484226226807: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.931406021118164: Accuracy = 0.4672874498447887\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 1.0077685117721558: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.1535449028015137: Accuracy = 0.4681995203157464\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 1.163793683052063: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 2.135781764984131: Accuracy = 0.46845181589639234\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 1.1477010250091553: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.118980646133423: Accuracy = 0.46891554952235287\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 1.2539582252502441: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.1943254470825195: Accuracy = 0.4680900381618352\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 1.5037951469421387: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.421109437942505: Accuracy = 0.46854452026004445\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 1.536105990409851: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 2.347973346710205: Accuracy = 0.46935478416257653\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 1.464997410774231: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.271228075027466: Accuracy = 0.4691233452344477\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 1.2805960178375244: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.179112434387207: Accuracy = 0.46829943746539254\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 1.1484451293945312: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 2.265599489212036: Accuracy = 0.4677790050610129\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 1.1734025478363037: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 2.4886255264282227: Accuracy = 0.4676770310542097\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 1.1974129676818848: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.044570207595825: Accuracy = 0.46728467890347963\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 1.4740991592407227: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.0426902770996094: Accuracy = 0.4694689776046398\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 1.4493647813796997: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 2.08172607421875: Accuracy = 0.4711941542900612\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 1.4772570133209229: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.1827096939086914: Accuracy = 0.47220224281492834\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 1.5914576053619385: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 2.6398935317993164: Accuracy = 0.4748497295359502\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 1.5090057849884033: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 2.5013372898101807: Accuracy = 0.47640054733660553\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 1.3560086488723755: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.9657965898513794: Accuracy = 0.4775720011908605\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 1.2830697298049927: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.989661693572998: Accuracy = 0.47982018674459714\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 1.2815510034561157: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 2.058527946472168: Accuracy = 0.4818666260805331\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 1.1418018341064453: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.7101974487304688: Accuracy = 0.482753694157151\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 1.1897697448730469: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 2.224152088165283: Accuracy = 0.48451709304977575\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 1.215901494026184: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.442225933074951: Accuracy = 0.4849290403119417\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 1.1466238498687744: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.6998844146728516: Accuracy = 0.4856325526727537\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 1.1191705465316772: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.628109097480774: Accuracy = 0.48745468273901005\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 1.2922521829605103: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 2.3178327083587646: Accuracy = 0.48898598219805467\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 1.2589234113693237: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.083009958267212: Accuracy = 0.4896331615599988\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 1.1280479431152344: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.9565035104751587: Accuracy = 0.49173121527789276\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 1.0139206647872925: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 2.090238332748413: Accuracy = 0.49298383062421536\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 1.0330630540847778: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.6935955286026: Accuracy = 0.493877078718903\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 1.0467705726623535: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 2.1210386753082275: Accuracy = 0.49489848062681013\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.9645366668701172: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.4328854084014893: Accuracy = 0.49567821327566414\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.9596444964408875: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.8540802001953125: Accuracy = 0.49608681042100333\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.8328053951263428: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.8483682870864868: Accuracy = 0.49676631237255586\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.8956747651100159: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.6027584075927734: Accuracy = 0.49757511649252073\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.9387114644050598: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.722014307975769: Accuracy = 0.4986319181364236\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 1.0110714435577393: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.8166422843933105: Accuracy = 0.5019711635815295\n",
      "\n",
      "Data shuffled. Epoch:  111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 1.025962471961975: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.5171947479248047: Accuracy = 0.5053280432195625\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 1.0474979877471924: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.4841759204864502: Accuracy = 0.5085301718855708\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 1.0772243738174438: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.601017951965332: Accuracy = 0.5108267179939499\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 1.0733009576797485: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.5291813611984253: Accuracy = 0.5139623866739834\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.9487298727035522: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.6396379470825195: Accuracy = 0.5156578114340349\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 1.0637612342834473: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.711209774017334: Accuracy = 0.5166163845459063\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 1.1000468730926514: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.8298215866088867: Accuracy = 0.5180206445267311\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.9577560424804688: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.9140806198120117: Accuracy = 0.5191083756453029\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.9964618682861328: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.4765616655349731: Accuracy = 0.5208511547557394\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.8853188157081604: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.5526350736618042: Accuracy = 0.5222532395744997\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.9819592237472534: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.6733919382095337: Accuracy = 0.5228048046385511\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 1.2047429084777832: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.8174736499786377: Accuracy = 0.5241405767529692\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 1.1719868183135986: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.8921501636505127: Accuracy = 0.5258275339027447\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.9965565204620361: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.4876132011413574: Accuracy = 0.5266317385696301\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 1.0222980976104736: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.8516849279403687: Accuracy = 0.5279210802219936\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 1.068805456161499: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.7685133218765259: Accuracy = 0.5293736867982357\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.9757755398750305: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.5799287557601929: Accuracy = 0.5303785412472941\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.9982452392578125: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.7579165697097778: Accuracy = 0.5309262905573153\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 1.1070739030838013: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 2.197007179260254: Accuracy = 0.5310603059686754\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 1.1689950227737427: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.952571988105774: Accuracy = 0.5313423067943532\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 1.1180553436279297: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 2.254857301712036: Accuracy = 0.5315685144066506\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 1.0553339719772339: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.7502597570419312: Accuracy = 0.5317532049874458\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 1.004233956336975: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.7099783420562744: Accuracy = 0.5327773764070781\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.9399613738059998: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.9728847742080688: Accuracy = 0.5335589758973118\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 1.041975975036621: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.7445188760757446: Accuracy = 0.5364265717063571\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 1.1645349264144897: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.8481923341751099: Accuracy = 0.5389587223520333\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 1.180356502532959: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.7156280279159546: Accuracy = 0.5414645611457951\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 1.1776326894760132: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 2.089583396911621: Accuracy = 0.5413922532437216\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 1.30110502243042: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.9942233562469482: Accuracy = 0.5414744183822454\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 1.8698707818984985: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 2.21713924407959: Accuracy = 0.5420640172678516\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 1.7559422254562378: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.1387569904327393: Accuracy = 0.5428360772801447\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 1.715939998626709: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.4321436882019043: Accuracy = 0.5429023979846025\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 1.5922077894210815: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.2199783325195312: Accuracy = 0.5435844060073447\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 1.40749990940094: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 2.3753738403320312: Accuracy = 0.5430055105099646\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 1.4248218536376953: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.2380194664001465: Accuracy = 0.5425731814488516\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 1.328834891319275: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 2.1974260807037354: Accuracy = 0.5422287110544158\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 1.3459159135818481: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 2.5918476581573486: Accuracy = 0.5419368295342952\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 1.2796435356140137: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.3694281578063965: Accuracy = 0.5417343657999154\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 1.201140284538269: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 2.0537540912628174: Accuracy = 0.5424424941603729\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 1.0919699668884277: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.8773783445358276: Accuracy = 0.5424756067752401\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 1.0765573978424072: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.1458773612976074: Accuracy = 0.5426156246303238\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 1.06961190700531: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.089783191680908: Accuracy = 0.5426778958922859\n",
      "\n",
      "Data shuffled. Epoch:  153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 1.0810670852661133: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.942222237586975: Accuracy = 0.5427742758080208\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 1.095054268836975: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.6844587326049805: Accuracy = 0.5429245191483582\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 1.0682799816131592: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 2.040057897567749: Accuracy = 0.5432863416461597\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.9613749384880066: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.8713526725769043: Accuracy = 0.5429965050182929\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.9573572874069214: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.7108383178710938: Accuracy = 0.5428462884969489\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.9138150215148926: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.6511462926864624: Accuracy = 0.543125162342038\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.9403010010719299: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.9369120597839355: Accuracy = 0.5431556837555305\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.9076201319694519: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.6942447423934937: Accuracy = 0.5441696187869149\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.8571252226829529: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.6338297128677368: Accuracy = 0.5439752999883983\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 1.0319724082946777: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.9358832836151123: Accuracy = 0.543785919619898\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.8874459862709045: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.6167056560516357: Accuracy = 0.5440651373179686\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.9483557343482971: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.4293321371078491: Accuracy = 0.5448847832402608\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 1.1516598463058472: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.8992173671722412: Accuracy = 0.5464198648385576\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 1.2786921262741089: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.106257677078247: Accuracy = 0.5479714154404568\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 6.073360919952393: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 8.252050399780273: Accuracy = 0.5497323453681867\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 14.310839653015137: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 15.761834144592285: Accuracy = 0.5518167103594199\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 17.981830596923828: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 18.940217971801758: Accuracy = 0.5537730545804008\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 19.175674438476562: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 20.343931198120117: Accuracy = 0.5557472715848173\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 19.335891723632812: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 20.13583755493164: Accuracy = 0.5576615567270256\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 19.370988845825195: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 20.10874366760254: Accuracy = 0.5597459735591983\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 19.286102294921875: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 20.33853530883789: Accuracy = 0.5619352016582634\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 19.14516830444336: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 19.86166763305664: Accuracy = 0.5639815917945771\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 18.95378875732422: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 19.6624698638916: Accuracy = 0.565866111566243\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 18.791866302490234: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 19.48318862915039: Accuracy = 0.5678850114505124\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 18.589948654174805: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 19.55111312866211: Accuracy = 0.5696973790441373\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 18.53582763671875: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 19.341493606567383: Accuracy = 0.5715241955619778\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 18.506790161132812: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 19.10773468017578: Accuracy = 0.5734528445856286\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 18.34589195251465: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 19.106319427490234: Accuracy = 0.575098224079622\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 18.580209732055664: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 20.09322738647461: Accuracy = 0.5766344674120842\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 18.468387603759766: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 19.32872772216797: Accuracy = 0.5782443001870522\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 18.412437438964844: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 19.137401580810547: Accuracy = 0.5799654265092197\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 18.452730178833008: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 18.933753967285156: Accuracy = 0.5819354494291774\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 18.289722442626953: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 18.869340896606445: Accuracy = 0.5836445825612894\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 17.96834945678711: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 18.582216262817383: Accuracy = 0.585214662909835\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 17.946882247924805: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 18.48223876953125: Accuracy = 0.586801504306421\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 17.888925552368164: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 18.26189613342285: Accuracy = 0.5885292088861905\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 17.875307083129883: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 18.31746482849121: Accuracy = 0.5902577669691362\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 17.74750328063965: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 18.440845489501953: Accuracy = 0.5918764140680743\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 17.63127899169922: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 18.347244262695312: Accuracy = 0.5934249635864336\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 17.474063873291016: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 18.20634651184082: Accuracy = 0.5948293643478987\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 17.388111114501953: Accuracy = 0.5666666626930237\n",
      "Performance on test set: : Loss = 18.00613784790039: Accuracy = 0.596195066475787\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 17.160017013549805: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 17.790842056274414: Accuracy = 0.5975510148864338\n",
      "\n",
      "Data shuffled. Epoch:  195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 17.077199935913086: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 17.9740047454834: Accuracy = 0.598987373427667\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 17.133411407470703: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 17.62476348876953: Accuracy = 0.6003365200413531\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 17.20368194580078: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 18.115564346313477: Accuracy = 0.601743534234653\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 17.197139739990234: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 17.91045379638672: Accuracy = 0.6030027179877728\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 17.042163848876953: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 17.67203140258789: Accuracy = 0.6041857645985735\n",
      "\n",
      "Optimisation finished!\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.143859624862671: Accuracy = 0.4266666769981384\n",
      "Performance on test set: : Loss = 1.1510149240493774: Accuracy = 0.633858296847484\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.118944764137268: Accuracy = 0.4333333373069763\n",
      "Performance on test set: : Loss = 1.1907862424850464: Accuracy = 0.6145038307536548\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.0590897798538208: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.2069894075393677: Accuracy = 0.5801825816172697\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 0.9353250861167908: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.3532384634017944: Accuracy = 0.5181347224248262\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 0.9938710331916809: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.58919095993042: Accuracy = 0.4707423853273383\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 0.8356963992118835: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.60874605178833: Accuracy = 0.43610161534812364\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 0.7475404143333435: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.5482228994369507: Accuracy = 0.40738251934186154\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 0.6583095192909241: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.8595051765441895: Accuracy = 0.40238094622383175\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 0.6047750115394592: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.5763046741485596: Accuracy = 0.39882383032551433\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.6455081105232239: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.7081114053726196: Accuracy = 0.39582824224542884\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.6529933214187622: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 3.0149919986724854: Accuracy = 0.384735555902914\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.6155490279197693: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.9303234815597534: Accuracy = 0.38263734743899747\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.5712531805038452: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 2.0604958534240723: Accuracy = 0.373537894000537\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.5571431517601013: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.2914483547210693: Accuracy = 0.3772913429153641\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.6043587327003479: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.5361132621765137: Accuracy = 0.3731417929142979\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 0.5487433671951294: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.607562780380249: Accuracy = 0.3757442875093263\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.5306100249290466: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.1016039848327637: Accuracy = 0.3700296773321925\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.5610509514808655: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 3.9818387031555176: Accuracy = 0.36726659549121415\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.520592451095581: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 3.603221893310547: Accuracy = 0.36185884969100507\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.5480179190635681: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.231985092163086: Accuracy = 0.3599489667020363\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.5544476509094238: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.753009557723999: Accuracy = 0.3620899134211391\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.5150387287139893: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.130829095840454: Accuracy = 0.36137576659995435\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.5399702191352844: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 3.195075511932373: Accuracy = 0.3627472534514992\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.5207287073135376: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 3.7221519947052: Accuracy = 0.36425605700246794\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.5298519134521484: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 3.4090662002563477: Accuracy = 0.366904975666797\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.5157409906387329: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 2.696911573410034: Accuracy = 0.36845723130123137\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.5075279474258423: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.5864646434783936: Accuracy = 0.3802459834416223\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.5205440521240234: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 2.234915018081665: Accuracy = 0.38983969135997176\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.5113373398780823: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.5124518871307373: Accuracy = 0.39444686371411636\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.5310969352722168: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.654118061065674: Accuracy = 0.39657920610449826\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.5221825242042542: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.5666184425354004: Accuracy = 0.403104543242953\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.5093317627906799: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 3.006553888320923: Accuracy = 0.4087112219854952\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.5120693445205688: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.815281391143799: Accuracy = 0.41361098129868057\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.536508321762085: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 3.3133044242858887: Accuracy = 0.4185876687735423\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.4749368727207184: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.2373361587524414: Accuracy = 0.4251268990138797\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.46868592500686646: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.6810429096221924: Accuracy = 0.42923495370095327\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.49136656522750854: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 3.0829579830169678: Accuracy = 0.4302418091030248\n",
      "\n",
      "Data shuffled. Epoch:  37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.4628584682941437: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.880671977996826: Accuracy = 0.4310579105764385\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.44118738174438477: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.289555549621582: Accuracy = 0.43558008753241445\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.5687913298606873: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 3.959049701690674: Accuracy = 0.43902737227835187\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.4908507168292999: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.47226619720459: Accuracy = 0.44132353849003025\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.5378652811050415: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.287203073501587: Accuracy = 0.44140899302653724\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.4769905209541321: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.4990859031677246: Accuracy = 0.4441295297676573\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.496249794960022: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 3.013293743133545: Accuracy = 0.4427921976939575\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.448476105928421: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.903501033782959: Accuracy = 0.4460813777973776\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.48054131865501404: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 3.2723379135131836: Accuracy = 0.4475398589607622\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.5516279935836792: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 4.56676721572876: Accuracy = 0.45213807383539834\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.5362597703933716: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.6289944648742676: Accuracy = 0.4517883494826155\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.5067275762557983: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.733238458633423: Accuracy = 0.4535341291743677\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.5193472504615784: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 2.304081916809082: Accuracy = 0.45227978211343045\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.4841465353965759: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.628836154937744: Accuracy = 0.4524925831338633\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.4483209252357483: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.775444269180298: Accuracy = 0.45257779362042744\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.47273311018943787: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.889765739440918: Accuracy = 0.45196298941544966\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.44068899750709534: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.559192180633545: Accuracy = 0.4501120440750719\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.4636649489402771: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.4514710903167725: Accuracy = 0.4488015567584762\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.42161858081817627: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.335577964782715: Accuracy = 0.4495246370696003\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.4082886874675751: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.0533440113067627: Accuracy = 0.4514653757272086\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.5178859233856201: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.7438955307006836: Accuracy = 0.45125859981974475\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.435867577791214: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.463942527770996: Accuracy = 0.452845574738471\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.4156132638454437: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.734513521194458: Accuracy = 0.4546182438614696\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.4360041916370392: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.0803537368774414: Accuracy = 0.45692942537584946\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.43996018171310425: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.8668010234832764: Accuracy = 0.45590801123323754\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.4082525670528412: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.1806480884552: Accuracy = 0.4557241862830557\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.3961219787597656: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.5205557346343994: Accuracy = 0.45529003573137905\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.4152508080005646: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.5672309398651123: Accuracy = 0.4550534717892398\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.43220844864845276: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.4982998371124268: Accuracy = 0.4532447866645475\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.4022394120693207: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.7001848220825195: Accuracy = 0.45310701363440814\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.40254873037338257: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.7335615158081055: Accuracy = 0.4533957076596392\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.4639599025249481: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 4.145998001098633: Accuracy = 0.45291978632230245\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.39653509855270386: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.3335750102996826: Accuracy = 0.4521864711929807\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.3991963863372803: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.9665775299072266: Accuracy = 0.4515537040302389\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.470887154340744: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.320729970932007: Accuracy = 0.4515069450464871\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.4593629837036133: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.480236530303955: Accuracy = 0.4521181930321608\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.4703340232372284: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.159686326980591: Accuracy = 0.4522606150324936\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.4245486557483673: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.666208267211914: Accuracy = 0.45094190987348454\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.44013407826423645: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.3396968841552734: Accuracy = 0.4518791385276127\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.4641701877117157: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 4.345033168792725: Accuracy = 0.45091705786786623\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.3818703591823578: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.499976634979248: Accuracy = 0.4512715695162722\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.4552212059497833: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.7443172931671143: Accuracy = 0.4508755234389319\n",
      "\n",
      "Data shuffled. Epoch:  79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.4548629820346832: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.496398687362671: Accuracy = 0.4497402573602046\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.4320252537727356: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.4958157539367676: Accuracy = 0.44863108266313756\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.45649293065071106: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.0523433685302734: Accuracy = 0.4487568653264321\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.4383958876132965: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.289369821548462: Accuracy = 0.44868583144802376\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.44069182872772217: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 4.12025785446167: Accuracy = 0.44875044056424024\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.39753079414367676: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.7018792629241943: Accuracy = 0.44904572931274067\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.37187376618385315: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 4.253632068634033: Accuracy = 0.44820799233477776\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.38632020354270935: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.192885637283325: Accuracy = 0.449598598500409\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.33691444993019104: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 4.657251834869385: Accuracy = 0.4503183448017759\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.40430405735969543: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 4.109015464782715: Accuracy = 0.44838834541674377\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.39395949244499207: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.242532730102539: Accuracy = 0.44837220099646086\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.47668397426605225: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 4.608650207519531: Accuracy = 0.44785714839706464\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.3728790581226349: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.5784363746643066: Accuracy = 0.44835462624710376\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.4495795667171478: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.7345097064971924: Accuracy = 0.4482830624255226\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.4346277415752411: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.411818742752075: Accuracy = 0.44886217240553855\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.39227715134620667: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 4.3594651222229: Accuracy = 0.4490283309028365\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.3859056532382965: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.9814486503601074: Accuracy = 0.449269898160219\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.3733835220336914: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.646303415298462: Accuracy = 0.44852044130364593\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.4846752882003784: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 6.569241523742676: Accuracy = 0.4487554816045755\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.47293204069137573: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.5564019680023193: Accuracy = 0.4477051675653363\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.5564920902252197: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.532219409942627: Accuracy = 0.44677355513330297\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.4203532636165619: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.825040817260742: Accuracy = 0.4464221518208202\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.4693930447101593: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.534334897994995: Accuracy = 0.44618228821098577\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.3973671495914459: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.433267116546631: Accuracy = 0.44556642645688005\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.34172093868255615: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.9596378803253174: Accuracy = 0.44489956656098245\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.4036722779273987: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.4691708087921143: Accuracy = 0.4452588325188297\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.4783061742782593: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 3.3079817295074463: Accuracy = 0.4446526083978311\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.428326815366745: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 4.23716402053833: Accuracy = 0.4446255408404179\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.470861554145813: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 4.176034450531006: Accuracy = 0.4429970352684178\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.4916222095489502: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 4.220451354980469: Accuracy = 0.44125514707046487\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.4341205954551697: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.3110406398773193: Accuracy = 0.44003889579684163\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.48295629024505615: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 4.857839107513428: Accuracy = 0.43997113534179455\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.3817816376686096: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 4.129683017730713: Accuracy = 0.43910920454874275\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.35310298204421997: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 4.385722637176514: Accuracy = 0.43834314817062525\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.4144713580608368: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 4.435544967651367: Accuracy = 0.4375802058289965\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.4170575439929962: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.5231974124908447: Accuracy = 0.4379858919671081\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.41545626521110535: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 4.216050624847412: Accuracy = 0.43751578294002835\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.4028187692165375: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 4.404139995574951: Accuracy = 0.438137662398361\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.4156320095062256: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 5.369637966156006: Accuracy = 0.4375258205617718\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.4454422891139984: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 4.013347625732422: Accuracy = 0.43761011700373725\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.39567816257476807: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 4.869189262390137: Accuracy = 0.43765240267279554\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.40818607807159424: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.9954543113708496: Accuracy = 0.4375050207997676\n",
      "\n",
      "Data shuffled. Epoch:  121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.36613285541534424: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 4.705186367034912: Accuracy = 0.4371987023396528\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.41508060693740845: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 5.28413200378418: Accuracy = 0.4368970642724506\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.3904159665107727: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 4.408450126647949: Accuracy = 0.4366358390936475\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.42470166087150574: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 4.797094821929932: Accuracy = 0.43682109864535057\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.4143836796283722: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 4.139372825622559: Accuracy = 0.4374043610811575\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.3950550854206085: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 4.391391754150391: Accuracy = 0.4371504742235935\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.42446473240852356: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 4.234213352203369: Accuracy = 0.43676317968150064\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.46354320645332336: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 4.565248012542725: Accuracy = 0.4367581204454586\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.4380924105644226: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.074599504470825: Accuracy = 0.43591383917335697\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.4535117447376251: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.0402655601501465: Accuracy = 0.4373380921872539\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.4476461410522461: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.7715673446655273: Accuracy = 0.4378617357328787\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.43955251574516296: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.074657917022705: Accuracy = 0.4389304285178634\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.372079074382782: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.4647231101989746: Accuracy = 0.4400399786461925\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.3879249393939972: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.668900966644287: Accuracy = 0.4408565195724015\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.4367939829826355: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 3.998903512954712: Accuracy = 0.44155655744547456\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.4227656424045563: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 4.186380863189697: Accuracy = 0.4421314327464844\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.3635406494140625: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 4.1947503089904785: Accuracy = 0.44301118876628215\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.37806349992752075: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 4.510154724121094: Accuracy = 0.4437800695208012\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.40246152877807617: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 4.475016117095947: Accuracy = 0.44426705743908473\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.4054466187953949: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 4.091655254364014: Accuracy = 0.4438738390191571\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.5104318261146545: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 5.038863658905029: Accuracy = 0.4432271650316763\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.5312033295631409: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.850370168685913: Accuracy = 0.44339459906014295\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.513339102268219: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 4.296550273895264: Accuracy = 0.4437248121303621\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.4576014280319214: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.1283860206604004: Accuracy = 0.44432538846398933\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.4519084692001343: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.581458568572998: Accuracy = 0.4454559280491584\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.4061388075351715: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.5579705238342285: Accuracy = 0.4468246890192162\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.44122084975242615: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.7193989753723145: Accuracy = 0.44793643017375845\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.39554375410079956: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 4.393893718719482: Accuracy = 0.4482478495188754\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.4127231240272522: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 5.457050800323486: Accuracy = 0.44844046299847234\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.45372435450553894: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 4.183829307556152: Accuracy = 0.44831067820003495\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.5961787700653076: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 3.488626480102539: Accuracy = 0.4491645443178016\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.5888926982879639: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.1267306804656982: Accuracy = 0.4494438900034285\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.5599263310432434: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.2810492515563965: Accuracy = 0.4506658836401696\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.47731730341911316: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.771034002304077: Accuracy = 0.4523273852245694\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.47011834383010864: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.999189615249634: Accuracy = 0.4531449419083108\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.5032059550285339: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.811234951019287: Accuracy = 0.45305740746583567\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.4967483580112457: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.9413106441497803: Accuracy = 0.4537111700452236\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.45337462425231934: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.5162110328674316: Accuracy = 0.4545605012231848\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.5375053882598877: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 3.3144986629486084: Accuracy = 0.45546007710677966\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.4931989014148712: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.1561059951782227: Accuracy = 0.45602053275194576\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.4710679054260254: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.228259563446045: Accuracy = 0.45736594050043333\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.4474742114543915: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.27640438079834: Accuracy = 0.45828151798869743\n",
      "\n",
      "Data shuffled. Epoch:  163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.4159475862979889: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.852503538131714: Accuracy = 0.45902593055162005\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.4108785390853882: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.545590877532959: Accuracy = 0.45935996101952425\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.4279060363769531: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.6212007999420166: Accuracy = 0.4593803457584627\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.4315260350704193: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.306713104248047: Accuracy = 0.45989888467451373\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.4045422673225403: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.4638092517852783: Accuracy = 0.4608548747175494\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.4558353126049042: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.8208913803100586: Accuracy = 0.4613438187519091\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.3867759108543396: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 3.468437433242798: Accuracy = 0.46136646177222185\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.38811492919921875: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 3.7405569553375244: Accuracy = 0.4620360517184603\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.4656679332256317: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.632369041442871: Accuracy = 0.46262872556698653\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.44918879866600037: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.8215372562408447: Accuracy = 0.46253784852960184\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.3916335701942444: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 4.01769495010376: Accuracy = 0.46304467233455177\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.39241647720336914: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 4.025095462799072: Accuracy = 0.4631353803698146\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.43339890241622925: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.667844533920288: Accuracy = 0.4636238725856182\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.4320906698703766: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.866483449935913: Accuracy = 0.46372468851313775\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.422428697347641: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.925206184387207: Accuracy = 0.46414435413429467\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.37683722376823425: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.9593305587768555: Accuracy = 0.46440690235394044\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.38213807344436646: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 4.430012226104736: Accuracy = 0.4645552746685123\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.44025760889053345: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.3339345455169678: Accuracy = 0.4650622769887181\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.3827757239341736: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 4.302408695220947: Accuracy = 0.46543342698350665\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.43530648946762085: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.7736294269561768: Accuracy = 0.4655172578405093\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.4779931604862213: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 4.349599361419678: Accuracy = 0.46539222726237806\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.3706403970718384: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 4.404020309448242: Accuracy = 0.46541135517595783\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.41858717799186707: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 4.059356212615967: Accuracy = 0.4655628848620417\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.3857809007167816: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 4.256966590881348: Accuracy = 0.46581934550890763\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.4829310178756714: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 4.063732147216797: Accuracy = 0.46582961337960344\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.4053702652454376: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.71835994720459: Accuracy = 0.46613581543586163\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.41027191281318665: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 4.412445545196533: Accuracy = 0.46650309697905973\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.4183327555656433: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.959214687347412: Accuracy = 0.4666075550390805\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.3717276453971863: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.902580499649048: Accuracy = 0.4665032860149446\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.40567684173583984: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.5432074069976807: Accuracy = 0.4661650321936084\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.3686387836933136: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 4.068330764770508: Accuracy = 0.46671356245528545\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.4019468128681183: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 4.656384468078613: Accuracy = 0.46681303396394963\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.4156399071216583: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.7343084812164307: Accuracy = 0.46653458980814105\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.3743561804294586: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 4.356747150421143: Accuracy = 0.4665321485287537\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.3770741820335388: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 4.136080265045166: Accuracy = 0.4664742123867715\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.3751896023750305: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 4.347809314727783: Accuracy = 0.466847796011798\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.3923557698726654: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 5.051210403442383: Accuracy = 0.46644249937987164\n",
      "\n",
      "Optimisation finished!\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.1657031774520874: Accuracy = 0.36000001430511475\n",
      "Performance on test set: : Loss = 1.1610318422317505: Accuracy = 0.6344294071879162\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.143922209739685: Accuracy = 0.3733333349227905\n",
      "Performance on test set: : Loss = 1.1585420370101929: Accuracy = 0.5671642060586848\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.1449872255325317: Accuracy = 0.4000000059604645\n",
      "Performance on test set: : Loss = 1.15218186378479: Accuracy = 0.558262022154487\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.0941476821899414: Accuracy = 0.4399999976158142\n",
      "Performance on test set: : Loss = 1.1589763164520264: Accuracy = 0.5455450476046527\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.1263073682785034: Accuracy = 0.3866666555404663\n",
      "Performance on test set: : Loss = 1.1749742031097412: Accuracy = 0.5353130519331073\n",
      "\n",
      "Data shuffled. Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 1.0630379915237427: Accuracy = 0.4399999976158142\n",
      "Performance on test set: : Loss = 1.1918379068374634: Accuracy = 0.5319006181860584\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 1.063977837562561: Accuracy = 0.4399999976158142\n",
      "Performance on test set: : Loss = 1.1890748739242554: Accuracy = 0.5262242819657069\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 1.0319613218307495: Accuracy = 0.4533333480358124\n",
      "Performance on test set: : Loss = 1.1878743171691895: Accuracy = 0.5220061299796819\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 0.8346767425537109: Accuracy = 0.5666666626930237\n",
      "Performance on test set: : Loss = 1.1698273420333862: Accuracy = 0.5103416406977874\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.8455473184585571: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.1878446340560913: Accuracy = 0.4930332233346384\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.8568633794784546: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.1752127408981323: Accuracy = 0.4900429425652736\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.7381724119186401: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.1021088361740112: Accuracy = 0.4822106435920515\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.6676225066184998: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.1790499687194824: Accuracy = 0.488822189687841\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.6661257743835449: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.2102258205413818: Accuracy = 0.49033063403477944\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.6476429104804993: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.1792328357696533: Accuracy = 0.4985440161918223\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 0.6391279697418213: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.1739728450775146: Accuracy = 0.5032152073448103\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.7195873260498047: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.2416272163391113: Accuracy = 0.5061329571909801\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.5979012846946716: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.071498155593872: Accuracy = 0.5127892892444301\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.5582971572875977: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.1866778135299683: Accuracy = 0.519474546777652\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.5471357703208923: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.5718756914138794: Accuracy = 0.524127402204462\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.6657810211181641: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.340996265411377: Accuracy = 0.527774922001504\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.6106662750244141: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.2606333494186401: Accuracy = 0.5335187084886852\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.5699308514595032: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.5555459260940552: Accuracy = 0.536905080224671\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.54290372133255: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.2466652393341064: Accuracy = 0.541204248147861\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.5519767999649048: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.1627507209777832: Accuracy = 0.5477019652692314\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.5242509245872498: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.0982805490493774: Accuracy = 0.5521739006524581\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.5502414107322693: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.1254712343215942: Accuracy = 0.5585426574944302\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.6791149377822876: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.3515732288360596: Accuracy = 0.561479565610744\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.5401668548583984: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.2123420238494873: Accuracy = 0.5653599699399522\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.5700086355209351: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.0993155241012573: Accuracy = 0.5699497027112367\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.5218440294265747: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.1321220397949219: Accuracy = 0.5748195205231763\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.58002769947052: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.274940848350525: Accuracy = 0.5779718138125542\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.496427983045578: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.2204291820526123: Accuracy = 0.5808718060351072\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.5248494744300842: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.3068472146987915: Accuracy = 0.5861613280934199\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.5228866934776306: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.4698976278305054: Accuracy = 0.5881777870753966\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.5116571187973022: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.5261199474334717: Accuracy = 0.5900392110062638\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.5027482509613037: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.4399394989013672: Accuracy = 0.5919463682976273\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.512774646282196: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.4120930433273315: Accuracy = 0.594491317927521\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.5131723284721375: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.2886548042297363: Accuracy = 0.5956817046898569\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.5039319396018982: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.6528348922729492: Accuracy = 0.5977367376953135\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.5054689645767212: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.6573370695114136: Accuracy = 0.5991560763220655\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.49276554584503174: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.548276662826538: Accuracy = 0.6006100467067009\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.5075882077217102: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.1279757022857666: Accuracy = 0.6011922811173265\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.5061173439025879: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.4624923467636108: Accuracy = 0.6017871091671917\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.4860583543777466: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.4199386835098267: Accuracy = 0.6026876842511277\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.47193223237991333: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.6464461088180542: Accuracy = 0.6037998578726846\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.44846487045288086: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.3930087089538574: Accuracy = 0.6043486093453931\n",
      "\n",
      "Data shuffled. Epoch:  47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.46441900730133057: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.6555805206298828: Accuracy = 0.6053428291790672\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.4886319041252136: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.5301778316497803: Accuracy = 0.6061478019039896\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.4913129210472107: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.6941465139389038: Accuracy = 0.6068971383832615\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.48665159940719604: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.701117753982544: Accuracy = 0.6066906931884801\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.4557923972606659: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.01033091545105: Accuracy = 0.6061479068013811\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.46703192591667175: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.679411768913269: Accuracy = 0.6053280811842877\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.49128368496894836: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.9592117071151733: Accuracy = 0.6056998167228335\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.4898054897785187: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.5680325031280518: Accuracy = 0.6064078637285314\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.4555826187133789: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.6508259773254395: Accuracy = 0.6079008865320689\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.4861065745353699: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.058397054672241: Accuracy = 0.6079506693382045\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.4309860169887543: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.014413356781006: Accuracy = 0.6062377202852353\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.42976465821266174: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.092963457107544: Accuracy = 0.6070429218976985\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.4796713888645172: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.3847525119781494: Accuracy = 0.6052056871979654\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.5014393329620361: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.6379293203353882: Accuracy = 0.6061096467493502\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.4756368398666382: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.3908123970031738: Accuracy = 0.6067027107783466\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.45174911618232727: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.490309476852417: Accuracy = 0.6087814023139063\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.44441157579421997: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.5975196361541748: Accuracy = 0.6077018489354193\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.44102606177330017: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.7412410974502563: Accuracy = 0.6082539234260772\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.45464015007019043: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.464406728744507: Accuracy = 0.6076665712922537\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.4814688563346863: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.7565046548843384: Accuracy = 0.6062102600178576\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.42217108607292175: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.6615471839904785: Accuracy = 0.6063842832266556\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.4483097791671753: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.8948817253112793: Accuracy = 0.606436338138039\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.49865952134132385: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.7982710599899292: Accuracy = 0.6069850084087524\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.3783341646194458: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.9319489002227783: Accuracy = 0.6076332397903391\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.43312203884124756: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.640542984008789: Accuracy = 0.6066973508756814\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.43505802750587463: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.9628404378890991: Accuracy = 0.607137602781644\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.47791850566864014: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.6861836910247803: Accuracy = 0.6060377273759375\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.4313605725765228: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.6488614082336426: Accuracy = 0.6064253587240991\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.40122702717781067: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.5756115913391113: Accuracy = 0.6074547138543748\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.37719231843948364: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.8592416048049927: Accuracy = 0.606853800802889\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.42839834094047546: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.8549805879592896: Accuracy = 0.6069303698994921\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.4510821998119354: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.1248998641967773: Accuracy = 0.6064267054909761\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.4304337203502655: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.2960448265075684: Accuracy = 0.6055129581518544\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.40978172421455383: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.985663652420044: Accuracy = 0.6057580177753099\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.43327900767326355: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.0280089378356934: Accuracy = 0.6058554590914115\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.3423328399658203: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.701432228088379: Accuracy = 0.6049853967772758\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.4192424416542053: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.0024781227111816: Accuracy = 0.6066467231302011\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.42554622888565063: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.384916067123413: Accuracy = 0.6085267222957836\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.38012027740478516: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.634899854660034: Accuracy = 0.60789938890577\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.3884623348712921: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.3137340545654297: Accuracy = 0.6081037548776524\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.4343803822994232: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.397348642349243: Accuracy = 0.6084667277580379\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.37111690640449524: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.5634875297546387: Accuracy = 0.6082136276213265\n",
      "\n",
      "Data shuffled. Epoch:  89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.3552074730396271: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.1985976696014404: Accuracy = 0.6088798915593012\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.40415045619010925: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.4722900390625: Accuracy = 0.6086669519071572\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.3801691234111786: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.218701124191284: Accuracy = 0.607976143986985\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.40633994340896606: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.1737799644470215: Accuracy = 0.6087056306098045\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.4210304915904999: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.9512615203857422: Accuracy = 0.6088244388302609\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.4306100904941559: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.6443896293640137: Accuracy = 0.609774192851705\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.3572797179222107: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.5516881942749023: Accuracy = 0.6100456337587267\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.34172338247299194: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.3535349369049072: Accuracy = 0.6110328602407388\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.355907142162323: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.6155433654785156: Accuracy = 0.611054241577105\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.41811060905456543: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.260277509689331: Accuracy = 0.6110787950614442\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.40163692831993103: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.6757259368896484: Accuracy = 0.610422929464068\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.3506142795085907: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.458411931991577: Accuracy = 0.6102662839012377\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.3639572262763977: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.5270259380340576: Accuracy = 0.6103852577171991\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.35472366213798523: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.547830581665039: Accuracy = 0.6115469857458443\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.38782966136932373: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.476257562637329: Accuracy = 0.6112170651683724\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.42113274335861206: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.04007625579834: Accuracy = 0.6121074396661353\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.3593187630176544: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.240793228149414: Accuracy = 0.612553976959944\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.39206376671791077: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.56716251373291: Accuracy = 0.6130957150305032\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.3653567135334015: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.0866189002990723: Accuracy = 0.6133049763184683\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.4573781192302704: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.022468328475952: Accuracy = 0.6136611679928942\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.42190396785736084: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.8187874555587769: Accuracy = 0.6137277612148261\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.35726022720336914: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.8051151037216187: Accuracy = 0.6157903909194989\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.32476046681404114: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.264385938644409: Accuracy = 0.6165956845577538\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.406659334897995: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.1486682891845703: Accuracy = 0.6163599823658431\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.38998809456825256: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.3299214839935303: Accuracy = 0.6169141260327826\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.376468688249588: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.6336560249328613: Accuracy = 0.616928805833358\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.3630349338054657: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.5632519721984863: Accuracy = 0.6162809609695339\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.3866153061389923: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.3871819972991943: Accuracy = 0.6171232098851084\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.3398875594139099: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.325500726699829: Accuracy = 0.6179350857722504\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.36793994903564453: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.272221565246582: Accuracy = 0.6177441929968334\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.41533163189888: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 3.182847023010254: Accuracy = 0.6177428012700352\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.4206084907054901: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.531874418258667: Accuracy = 0.6179338508002324\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.4476262927055359: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 2.181691884994507: Accuracy = 0.6195111753664622\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.39426326751708984: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.084010124206543: Accuracy = 0.6195447413952997\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.36911940574645996: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.607163429260254: Accuracy = 0.6194960263085285\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.3994069993495941: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.658470392227173: Accuracy = 0.6190548198868935\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.4142376482486725: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.814110040664673: Accuracy = 0.6194391927372696\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.3487498164176941: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.524214029312134: Accuracy = 0.6189262614287208\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.30867549777030945: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.62117075920105: Accuracy = 0.6186904172261963\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.38438597321510315: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.455676317214966: Accuracy = 0.6183974530988908\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.39316704869270325: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.7620394229888916: Accuracy = 0.6185430362956668\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.3917321562767029: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.640329360961914: Accuracy = 0.6186257059418715\n",
      "\n",
      "Data shuffled. Epoch:  131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.38785436749458313: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.6653223037719727: Accuracy = 0.619094553585244\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.38764074444770813: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.431248188018799: Accuracy = 0.6197906183779428\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.3620818555355072: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.4803171157836914: Accuracy = 0.6196346615612588\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.3525186777114868: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.2566425800323486: Accuracy = 0.620465353767658\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.4096352159976959: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.4311604499816895: Accuracy = 0.6214784955991637\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.36193710565567017: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.332498073577881: Accuracy = 0.6214556788022648\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.3927674889564514: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.711394786834717: Accuracy = 0.6220254596151324\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.41846704483032227: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.880290985107422: Accuracy = 0.6221662895063796\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.35265058279037476: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.809819459915161: Accuracy = 0.6219503262978762\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.3655860424041748: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.4234635829925537: Accuracy = 0.6217742054375689\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.3779655396938324: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.609930992126465: Accuracy = 0.6218492517010716\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.38182422518730164: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.766753911972046: Accuracy = 0.6222720424988152\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.36294251680374146: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.9491231441497803: Accuracy = 0.6226723295096651\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.3810325860977173: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.5837597846984863: Accuracy = 0.6224122780045249\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.374592661857605: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.530435562133789: Accuracy = 0.6228099089585325\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.29982733726501465: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.860353708267212: Accuracy = 0.6224947934529402\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.3636634349822998: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.438894033432007: Accuracy = 0.6222696035702215\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.3692830801010132: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.8407092094421387: Accuracy = 0.6225392983172446\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.35437992215156555: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.5537686347961426: Accuracy = 0.6219834720866972\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.35061734914779663: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.5985171794891357: Accuracy = 0.621985727110607\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.3810873329639435: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.0109872817993164: Accuracy = 0.6221002219230096\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.4063972234725952: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 3.029435157775879: Accuracy = 0.6219551715020508\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.3743499219417572: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.5886447429656982: Accuracy = 0.6216634824404726\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.401250422000885: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.7149288654327393: Accuracy = 0.6221960876037301\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.35133105516433716: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.5160605907440186: Accuracy = 0.6215024332958883\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.3936949670314789: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.4032483100891113: Accuracy = 0.6222128808277235\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.3969375789165497: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.72019100189209: Accuracy = 0.6225439530676475\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.32805415987968445: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.582632541656494: Accuracy = 0.6222985290695144\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.35166072845458984: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.0355749130249023: Accuracy = 0.6223072153579323\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.31657081842422485: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.697793960571289: Accuracy = 0.6224040705506962\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.3379789888858795: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.068502426147461: Accuracy = 0.6223321142430432\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.3492266535758972: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.8963091373443604: Accuracy = 0.6225163387381434\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.3133988380432129: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.794919490814209: Accuracy = 0.6219773136928605\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.3860477805137634: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.7900240421295166: Accuracy = 0.6218865656304796\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.33730843663215637: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.189826011657715: Accuracy = 0.6218372861790324\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.38230690360069275: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.0291693210601807: Accuracy = 0.6216199216979956\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.3393954038619995: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.8847618103027344: Accuracy = 0.6217090955644315\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.3462625741958618: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.9188015460968018: Accuracy = 0.6212171301775791\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.3522341549396515: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.625976800918579: Accuracy = 0.6215688631389509\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.32288315892219543: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.860496997833252: Accuracy = 0.6222013834188916\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.33396661281585693: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.693308115005493: Accuracy = 0.6224274088831395\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.320567786693573: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.178489923477173: Accuracy = 0.6220542002689937\n",
      "\n",
      "Data shuffled. Epoch:  173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.33905646204948425: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.855861186981201: Accuracy = 0.6221119646776396\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.34503376483917236: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.266380786895752: Accuracy = 0.6222076290522929\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.3351013958454132: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.074793815612793: Accuracy = 0.622680003798252\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.37348702549934387: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.4347479343414307: Accuracy = 0.6225305793464395\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.31782403588294983: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 3.237353801727295: Accuracy = 0.6220380223296823\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.34233713150024414: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.392812490463257: Accuracy = 0.6218136114504738\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.32432156801223755: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.9539055824279785: Accuracy = 0.6213769118810011\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.3757122755050659: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.0912883281707764: Accuracy = 0.6208704869767276\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.35589492321014404: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 3.6596505641937256: Accuracy = 0.6203796757170984\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.35768967866897583: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.955610513687134: Accuracy = 0.6204008445453688\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.394363671541214: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 3.1394762992858887: Accuracy = 0.6208051068359445\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.3624645471572876: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.6289329528808594: Accuracy = 0.6207241174016789\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.3517688512802124: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.2929341793060303: Accuracy = 0.6203707838954048\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.30521830916404724: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.1297030448913574: Accuracy = 0.6202929981781431\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.2770296633243561: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 3.02258563041687: Accuracy = 0.6198883898908293\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.3615657091140747: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.2048935890197754: Accuracy = 0.6199366352702043\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.3307439982891083: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.191213607788086: Accuracy = 0.61944566118925\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.3046012222766876: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.345824956893921: Accuracy = 0.61899080828515\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.3714483082294464: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 3.232124090194702: Accuracy = 0.6188547131745087\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.33426782488822937: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 3.499389410018921: Accuracy = 0.6187776562039178\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.35313892364501953: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 3.4465315341949463: Accuracy = 0.6181910110862795\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.3312304615974426: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.092258930206299: Accuracy = 0.6182790650605146\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.34123924374580383: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.051557779312134: Accuracy = 0.6181178363913828\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.31537914276123047: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 3.18477725982666: Accuracy = 0.6176497724773247\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.37295493483543396: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.3251733779907227: Accuracy = 0.6175820884448731\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.36433646082878113: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.902423858642578: Accuracy = 0.6174708226469889\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.320351779460907: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.7414519786834717: Accuracy = 0.6171812957630688\n",
      "\n",
      "Optimisation finished!\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.1149169206619263: Accuracy = 0.4333333373069763\n",
      "Performance on test set: : Loss = 1.1681140661239624: Accuracy = 0.6615385162105711\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.0842077732086182: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.1495776176452637: Accuracy = 0.677846504074191\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.114220142364502: Accuracy = 0.40666666626930237\n",
      "Performance on test set: : Loss = 1.1114612817764282: Accuracy = 0.6567871852161044\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.088496446609497: Accuracy = 0.4399999976158142\n",
      "Performance on test set: : Loss = 1.1222971677780151: Accuracy = 0.6260869676413704\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.0724595785140991: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.1484497785568237: Accuracy = 0.6206896666907806\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 1.0829917192459106: Accuracy = 0.46000000834465027\n",
      "Performance on test set: : Loss = 1.143833875656128: Accuracy = 0.6189744838999097\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 1.0374270677566528: Accuracy = 0.47999998927116394\n",
      "Performance on test set: : Loss = 1.1614196300506592: Accuracy = 0.6164817276479839\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 1.0358901023864746: Accuracy = 0.46666666865348816\n",
      "Performance on test set: : Loss = 1.1496589183807373: Accuracy = 0.621497463556646\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 1.0498530864715576: Accuracy = 0.4266666769981384\n",
      "Performance on test set: : Loss = 1.1535588502883911: Accuracy = 0.6318538010911187\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.9544711112976074: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.2460191249847412: Accuracy = 0.6371111580407907\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.9885920286178589: Accuracy = 0.4933333396911621\n",
      "Performance on test set: : Loss = 1.2382559776306152: Accuracy = 0.6434977373332528\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.9202048778533936: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.2315853834152222: Accuracy = 0.6472379422768607\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.9084720015525818: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.1710940599441528: Accuracy = 0.6523003984031727\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.8696581125259399: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.1708965301513672: Accuracy = 0.6568722472715633\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.9230523705482483: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.2530971765518188: Accuracy = 0.6624817695563963\n",
      "\n",
      "Data shuffled. Epoch:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.8302775621414185: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.2686357498168945: Accuracy = 0.667221176703468\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.8026970624923706: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.3346614837646484: Accuracy = 0.6728029903551729\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.784274697303772: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.4255610704421997: Accuracy = 0.6770068214667685\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.7237074971199036: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.2798070907592773: Accuracy = 0.6796315148095811\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.7597252726554871: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.2996472120285034: Accuracy = 0.6823889053433512\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.7198426127433777: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.3985296487808228: Accuracy = 0.6848563429354871\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.6766144037246704: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.3267604112625122: Accuracy = 0.6866946661314083\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.718944787979126: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.3540040254592896: Accuracy = 0.6869133749431213\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.6533161997795105: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.413069486618042: Accuracy = 0.6861930393705725\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.7177124619483948: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.3932030200958252: Accuracy = 0.6859164483936152\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.6863954663276672: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.4750077724456787: Accuracy = 0.6856726775178869\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.7143291234970093: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.2986581325531006: Accuracy = 0.6856376620011468\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.7024034857749939: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.4067522287368774: Accuracy = 0.6853037480527637\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.6100540161132812: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.3894003629684448: Accuracy = 0.6848084760042586\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.75323486328125: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.4317377805709839: Accuracy = 0.6842874939842681\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.6489907503128052: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.636716604232788: Accuracy = 0.6844574519903878\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.736099123954773: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.4133998155593872: Accuracy = 0.6843338111932655\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.6277502775192261: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.4229902029037476: Accuracy = 0.6841508683840857\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.6474844813346863: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.3696484565734863: Accuracy = 0.6844900860906444\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.6367390751838684: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.477481722831726: Accuracy = 0.6838479885795751\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.6457057595252991: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.460523009300232: Accuracy = 0.6840356999060528\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.5762501955032349: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.4448494911193848: Accuracy = 0.683387139293687\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.5797204375267029: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.6354292631149292: Accuracy = 0.6835815125534368\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.6223852634429932: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.6908355951309204: Accuracy = 0.6849825523505199\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.6193161010742188: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.5304838418960571: Accuracy = 0.6858289427311215\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.5760416388511658: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.5448251962661743: Accuracy = 0.685697056912865\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.5986462235450745: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.5001829862594604: Accuracy = 0.6867006495642859\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.5637128949165344: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.500815510749817: Accuracy = 0.6873547323551213\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.5977553129196167: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.5196666717529297: Accuracy = 0.6885200105911133\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.569678008556366: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.493505835533142: Accuracy = 0.6896434330965044\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.5634139180183411: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.496964693069458: Accuracy = 0.6911256034055322\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.5564062595367432: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.7384462356567383: Accuracy = 0.6921551316511529\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.606749951839447: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.4303677082061768: Accuracy = 0.6933079411326004\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.6456354260444641: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.3681727647781372: Accuracy = 0.6940770173795621\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.5803102850914001: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.9290879964828491: Accuracy = 0.6946400272198091\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.5729734301567078: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.5459067821502686: Accuracy = 0.6956625238771695\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.5561516284942627: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.553926706314087: Accuracy = 0.696566858328958\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.5506163239479065: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.512718915939331: Accuracy = 0.6971988542825485\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.5654308795928955: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.6659164428710938: Accuracy = 0.6978063964870632\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.5654865503311157: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.4674595594406128: Accuracy = 0.6980065543876667\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.6049331426620483: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.4316526651382446: Accuracy = 0.6979302187203005\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.5673016905784607: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.6391831636428833: Accuracy = 0.6985824311853803\n",
      "\n",
      "Data shuffled. Epoch:  57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.5724638104438782: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.7542665004730225: Accuracy = 0.6990595411210575\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.5404385924339294: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.8894786834716797: Accuracy = 0.6992299607556409\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.5598236322402954: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.6362208127975464: Accuracy = 0.6993843251206739\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.5414929986000061: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.541043996810913: Accuracy = 0.6997815190849506\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.5428739786148071: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.7979929447174072: Accuracy = 0.7002003678896912\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.5455577969551086: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.8602372407913208: Accuracy = 0.7002452425344953\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.5156646966934204: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.0318498611450195: Accuracy = 0.7005136430747521\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.5770698189735413: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 2.1286768913269043: Accuracy = 0.7004406304768738\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.560747504234314: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.8605022430419922: Accuracy = 0.7004156726503412\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.5549993515014648: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.6931159496307373: Accuracy = 0.700794013426174\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.5735278725624084: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.7121481895446777: Accuracy = 0.7011852345176324\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.5667837262153625: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.8731385469436646: Accuracy = 0.7009466834083065\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.5119044780731201: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.832787275314331: Accuracy = 0.7009442873180598\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.5442038774490356: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.7852308750152588: Accuracy = 0.7009930665442612\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.526390016078949: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.7710680961608887: Accuracy = 0.7009562533265604\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.5383878946304321: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.7949936389923096: Accuracy = 0.7008394582840715\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.5389389395713806: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.8697553873062134: Accuracy = 0.7008077518536372\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.5545132160186768: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.8389638662338257: Accuracy = 0.7006171448898321\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.5069561004638672: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.637557864189148: Accuracy = 0.7003176242724171\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.5262921452522278: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.8744598627090454: Accuracy = 0.7002997960667459\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.5558940172195435: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.9528917074203491: Accuracy = 0.6996298148076782\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.5615220069885254: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.7936376333236694: Accuracy = 0.6992993187936705\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.5372132658958435: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.5999218225479126: Accuracy = 0.699010675224355\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.5430973768234253: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.9992258548736572: Accuracy = 0.699063755466496\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.5370329022407532: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.7130308151245117: Accuracy = 0.6988815500920283\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.5353781580924988: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.6386682987213135: Accuracy = 0.6985176698225602\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.5391806960105896: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.8863413333892822: Accuracy = 0.6980679980736936\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.5244752764701843: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.7174627780914307: Accuracy = 0.6973920494000463\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.5121133327484131: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.7789956331253052: Accuracy = 0.6970450026457962\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.5064224004745483: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.1624457836151123: Accuracy = 0.6964081424604245\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.5186596512794495: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.9886517524719238: Accuracy = 0.6960010578582113\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.5145354866981506: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.7975391149520874: Accuracy = 0.6951559409291826\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.5521113872528076: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.735908031463623: Accuracy = 0.6945843146025127\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.5099279880523682: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.588024616241455: Accuracy = 0.6939290816109314\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.536939263343811: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.5320864915847778: Accuracy = 0.6933803930154945\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.5190497040748596: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.7759274244308472: Accuracy = 0.692681934112846\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.56368088722229: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.6819770336151123: Accuracy = 0.6920100335650308\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.5142339468002319: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.7493112087249756: Accuracy = 0.6914806147700009\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.5484786033630371: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.4631571769714355: Accuracy = 0.6909603184441556\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.5004014372825623: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.139716863632202: Accuracy = 0.6904777062740647\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.5101344585418701: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.7253373861312866: Accuracy = 0.6899888421627142\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.5220181345939636: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.8678573369979858: Accuracy = 0.6899029889816343\n",
      "\n",
      "Data shuffled. Epoch:  99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.4908914566040039: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.8376376628875732: Accuracy = 0.6895414532784551\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.5311437249183655: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.7864131927490234: Accuracy = 0.6888759645107531\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.5243549942970276: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.9027312994003296: Accuracy = 0.6881743156719773\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.5276098847389221: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.642481803894043: Accuracy = 0.6879038079854524\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.5172612071037292: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.7444978952407837: Accuracy = 0.6873291059991077\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.5321054458618164: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.6921817064285278: Accuracy = 0.6866779488894758\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.5292568802833557: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 2.022132635116577: Accuracy = 0.6863724262704455\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.4898781478404999: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.7776051759719849: Accuracy = 0.6858407722328578\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.5123315453529358: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.932413101196289: Accuracy = 0.6853954884574361\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.4969809949398041: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.674452543258667: Accuracy = 0.6848076678268054\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.5356585383415222: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.650860071182251: Accuracy = 0.6842498114777543\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.49760904908180237: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.012269973754883: Accuracy = 0.6838861234878155\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.5269814729690552: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.704957127571106: Accuracy = 0.683417622112117\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.4980197548866272: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.6286156177520752: Accuracy = 0.6830227447653481\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.508758008480072: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.7370151281356812: Accuracy = 0.6827865417600442\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.5023416876792908: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.8616943359375: Accuracy = 0.6823841154606908\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.5132507085800171: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.6690044403076172: Accuracy = 0.68181329262444\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.5133497714996338: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.0991923809051514: Accuracy = 0.6814099312433626\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.5163697600364685: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.8846876621246338: Accuracy = 0.681236911327124\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.49201735854148865: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.9095542430877686: Accuracy = 0.6804804307443652\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.5028839707374573: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.7379347085952759: Accuracy = 0.6798289918049261\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.5213122367858887: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.7661463022232056: Accuracy = 0.6793557227375087\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.5354516506195068: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.7985985279083252: Accuracy = 0.6788917908196589\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.5476781129837036: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.7182291746139526: Accuracy = 0.6786271748353292\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.4992278516292572: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.893404245376587: Accuracy = 0.6783500683308783\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.49434828758239746: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.711258053779602: Accuracy = 0.6777553898251398\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.5014614462852478: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.8800276517868042: Accuracy = 0.6774313675928902\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.5241079330444336: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.791506290435791: Accuracy = 0.677236128679757\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.5245485305786133: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.948861837387085: Accuracy = 0.6769802481718661\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.5354230999946594: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.8890275955200195: Accuracy = 0.676678719660995\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.5205885171890259: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.6978975534439087: Accuracy = 0.6763259746661695\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.5228942632675171: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.6839004755020142: Accuracy = 0.675915377777278\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.5232707858085632: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.6300241947174072: Accuracy = 0.6750698400827082\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.5154018402099609: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.011671781539917: Accuracy = 0.6743351261680609\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.5271581411361694: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.6866395473480225: Accuracy = 0.6737753212314097\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.5137116312980652: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.021718978881836: Accuracy = 0.6731378439355203\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.5192952156066895: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.749197244644165: Accuracy = 0.6727693337303955\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.5253646373748779: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.033931255340576: Accuracy = 0.6722990341747762\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.5533791184425354: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.758908748626709: Accuracy = 0.6717668843278879\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.5204353332519531: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.8095099925994873: Accuracy = 0.6714376356118904\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.5329537987709045: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 2.299346446990967: Accuracy = 0.6709561454726856\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.5476623773574829: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.8876953125: Accuracy = 0.6706444748474342\n",
      "\n",
      "Data shuffled. Epoch:  141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.5069591403007507: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.7720259428024292: Accuracy = 0.6699962155010452\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.5184611678123474: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.7887712717056274: Accuracy = 0.6690398867294076\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.5183588266372681: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.9326598644256592: Accuracy = 0.6681392059205393\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.5154111385345459: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.7258273363113403: Accuracy = 0.6675038440957326\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.5141993761062622: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.9720795154571533: Accuracy = 0.6672523883804525\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.501315176486969: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.9397094249725342: Accuracy = 0.6666163635637145\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.5140295624732971: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.9454410076141357: Accuracy = 0.6662740514031213\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.5286096334457397: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 2.041276454925537: Accuracy = 0.6657515602373344\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.5232848525047302: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.9907238483428955: Accuracy = 0.6650872309833381\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.5072903037071228: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.8052010536193848: Accuracy = 0.6648242159339438\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.5192508697509766: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.965869665145874: Accuracy = 0.664452721462463\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.48093700408935547: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 2.0241544246673584: Accuracy = 0.6639401579395876\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.5074976682662964: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 2.015368938446045: Accuracy = 0.6636616381836383\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.49958735704421997: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.0786125659942627: Accuracy = 0.6632973890321165\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.5014352798461914: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.7832341194152832: Accuracy = 0.6627202518641045\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.5427982211112976: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.7737791538238525: Accuracy = 0.6625145340277588\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.5274372100830078: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 2.1476659774780273: Accuracy = 0.6620144060962304\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.5135173797607422: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.1149797439575195: Accuracy = 0.6616143803588851\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.5004135370254517: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 2.1042723655700684: Accuracy = 0.6611723280887729\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.47765085101127625: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.9331951141357422: Accuracy = 0.6607224335764668\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.5224331021308899: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 2.010601282119751: Accuracy = 0.6605287800903148\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.5387442708015442: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.8995559215545654: Accuracy = 0.6604886089974299\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.5146211385726929: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.0003178119659424: Accuracy = 0.660135302457007\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.49437931180000305: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.9993799924850464: Accuracy = 0.6600844248886786\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.5109735131263733: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.9962042570114136: Accuracy = 0.659744342973778\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.5080952048301697: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.0120973587036133: Accuracy = 0.6591836222653265\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.48394107818603516: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.8004716634750366: Accuracy = 0.6590065440241781\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.5040891170501709: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 2.084510326385498: Accuracy = 0.658767140124995\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.5052303671836853: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.71942937374115: Accuracy = 0.6583479296434657\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.5008928179740906: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.6730937957763672: Accuracy = 0.6582154962804949\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.49512508511543274: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.117182493209839: Accuracy = 0.6578976117017679\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.5286042094230652: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.6442525386810303: Accuracy = 0.6577575637847932\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.5063978433609009: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.249706745147705: Accuracy = 0.6574329436380848\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.4714873731136322: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.8733023405075073: Accuracy = 0.6568120612760481\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.4595727026462555: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.074742078781128: Accuracy = 0.6564228524116816\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.5414444208145142: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.7385495901107788: Accuracy = 0.6557714976676964\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.5025662183761597: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.9677598476409912: Accuracy = 0.6552638246514834\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.5333892107009888: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.652969241142273: Accuracy = 0.6550512707517387\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.512761652469635: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.8175103664398193: Accuracy = 0.6545878111110404\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.5001438856124878: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.9777604341506958: Accuracy = 0.654116085494963\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.5041185021400452: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.9507193565368652: Accuracy = 0.6539067538367475\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.5038129091262817: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.7211123704910278: Accuracy = 0.6535692502535604\n",
      "\n",
      "Data shuffled. Epoch:  183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.488918662071228: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.713205099105835: Accuracy = 0.6533649437867359\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.4964251220226288: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.925333023071289: Accuracy = 0.6530049796271409\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.5032269358634949: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.8595906496047974: Accuracy = 0.6528071046848412\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.48663151264190674: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.8401520252227783: Accuracy = 0.6526680029327332\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.4821251332759857: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.93611741065979: Accuracy = 0.6524020767912827\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.48014169931411743: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.7919155359268188: Accuracy = 0.6522761811060626\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.5119612812995911: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.7221176624298096: Accuracy = 0.6521165785087925\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.48077192902565: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.9763063192367554: Accuracy = 0.651990056723128\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.48288217186927795: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.0054495334625244: Accuracy = 0.6516946341244207\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.43319040536880493: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.8300964832305908: Accuracy = 0.6513192118050123\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.508392333984375: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 2.206327199935913: Accuracy = 0.6508225596661816\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.45640838146209717: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.6968997716903687: Accuracy = 0.6505197451548529\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.48789164423942566: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.862623929977417: Accuracy = 0.6502366548629142\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.4755742847919464: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.6720075607299805: Accuracy = 0.6499167203117804\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.4719149172306061: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.8086864948272705: Accuracy = 0.649737122859124\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.49622416496276855: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 2.01916766166687: Accuracy = 0.6492307424266321\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.4975634217262268: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.9372470378875732: Accuracy = 0.648931968612034\n",
      "\n",
      "Optimisation finished!\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.2069035768508911: Accuracy = 0.2666666805744171\n",
      "Performance on test set: : Loss = 1.1586368083953857: Accuracy = 0.6679611562326321\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.2018840312957764: Accuracy = 0.25999999046325684\n",
      "Performance on test set: : Loss = 1.1583857536315918: Accuracy = 0.6844444469597777\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.177566647529602: Accuracy = 0.25333333015441895\n",
      "Performance on test set: : Loss = 1.1498596668243408: Accuracy = 0.6946175251937013\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.1589486598968506: Accuracy = 0.36666667461395264\n",
      "Performance on test set: : Loss = 1.1471335887908936: Accuracy = 0.707869845713242\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.1526145935058594: Accuracy = 0.3266666531562805\n",
      "Performance on test set: : Loss = 1.1431734561920166: Accuracy = 0.7207729354666125\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 1.1333025693893433: Accuracy = 0.3733333349227905\n",
      "Performance on test set: : Loss = 1.1525770425796509: Accuracy = 0.7277996750975106\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 1.140634536743164: Accuracy = 0.3466666638851166\n",
      "Performance on test set: : Loss = 1.144721269607544: Accuracy = 0.732186778526304\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 1.1440434455871582: Accuracy = 0.41999998688697815\n",
      "Performance on test set: : Loss = 1.1345617771148682: Accuracy = 0.7348529204128248\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 1.130914568901062: Accuracy = 0.4000000059604645\n",
      "Performance on test set: : Loss = 1.14369535446167: Accuracy = 0.7347932130690819\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 1.1284995079040527: Accuracy = 0.4266666769981384\n",
      "Performance on test set: : Loss = 1.1370049715042114: Accuracy = 0.7303990650588167\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 1.1344586610794067: Accuracy = 0.4533333480358124\n",
      "Performance on test set: : Loss = 1.14678156375885: Accuracy = 0.726509357445943\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 1.123149037361145: Accuracy = 0.41999998688697815\n",
      "Performance on test set: : Loss = 1.1515483856201172: Accuracy = 0.719870997926841\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 1.1206263303756714: Accuracy = 0.4533333480358124\n",
      "Performance on test set: : Loss = 1.14250910282135: Accuracy = 0.7098478359517436\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 1.125001072883606: Accuracy = 0.4266666769981384\n",
      "Performance on test set: : Loss = 1.138316035270691: Accuracy = 0.6987065406530417\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 1.0993691682815552: Accuracy = 0.4933333396911621\n",
      "Performance on test set: : Loss = 1.1524776220321655: Accuracy = 0.6894925585559232\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 1.124619722366333: Accuracy = 0.41333332657814026\n",
      "Performance on test set: : Loss = 1.1522692441940308: Accuracy = 0.6820698202597991\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 1.1301336288452148: Accuracy = 0.4533333480358124\n",
      "Performance on test set: : Loss = 1.153234601020813: Accuracy = 0.6738379984618182\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 1.1141102313995361: Accuracy = 0.41999998688697815\n",
      "Performance on test set: : Loss = 1.1471765041351318: Accuracy = 0.6667312848996472\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 1.1063024997711182: Accuracy = 0.4333333373069763\n",
      "Performance on test set: : Loss = 1.1395233869552612: Accuracy = 0.6605435979101858\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 1.10139000415802: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.1448895931243896: Accuracy = 0.6515570565802761\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 1.0922203063964844: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.138950228691101: Accuracy = 0.6433914938736607\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 1.103304386138916: Accuracy = 0.40666666626930237\n",
      "Performance on test set: : Loss = 1.1464478969573975: Accuracy = 0.6378467346710193\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 1.0891183614730835: Accuracy = 0.4866666793823242\n",
      "Performance on test set: : Loss = 1.1589672565460205: Accuracy = 0.6320837180946917\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 1.0983737707138062: Accuracy = 0.47333332896232605\n",
      "Performance on test set: : Loss = 1.149878978729248: Accuracy = 0.6253673530641896\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 1.1068769693374634: Accuracy = 0.47333332896232605\n",
      "Performance on test set: : Loss = 1.1394671201705933: Accuracy = 0.6200598268887364\n",
      "\n",
      "Data shuffled. Epoch:  25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 1.0853161811828613: Accuracy = 0.4533333480358124\n",
      "Performance on test set: : Loss = 1.134456992149353: Accuracy = 0.6146256089114295\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 1.0841562747955322: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.1436132192611694: Accuracy = 0.6091242132080216\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 1.0955647230148315: Accuracy = 0.4466666579246521\n",
      "Performance on test set: : Loss = 1.149748682975769: Accuracy = 0.6026422036252375\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 1.0842574834823608: Accuracy = 0.4266666769981384\n",
      "Performance on test set: : Loss = 1.1536378860473633: Accuracy = 0.5968439430435829\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 1.057424545288086: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.158258318901062: Accuracy = 0.5919927057848252\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 1.0821034908294678: Accuracy = 0.4866666793823242\n",
      "Performance on test set: : Loss = 1.1397178173065186: Accuracy = 0.5862374365087858\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 1.081709384918213: Accuracy = 0.4466666579246521\n",
      "Performance on test set: : Loss = 1.167620301246643: Accuracy = 0.5808040697804395\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 1.1004664897918701: Accuracy = 0.4266666769981384\n",
      "Performance on test set: : Loss = 1.157472848892212: Accuracy = 0.5762325397608615\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 1.0807172060012817: Accuracy = 0.41999998688697815\n",
      "Performance on test set: : Loss = 1.1565823554992676: Accuracy = 0.5697346776819431\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 1.0474094152450562: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.1687448024749756: Accuracy = 0.5638700526499765\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 1.0745435953140259: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.1616464853286743: Accuracy = 0.5587475930477341\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 1.0540637969970703: Accuracy = 0.4933333396911621\n",
      "Performance on test set: : Loss = 1.167617917060852: Accuracy = 0.5531143356324031\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 1.0598080158233643: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.175239086151123: Accuracy = 0.5476062332101757\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 1.0548474788665771: Accuracy = 0.46666666865348816\n",
      "Performance on test set: : Loss = 1.1964596509933472: Accuracy = 0.5417940110377277\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 1.015602946281433: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.1884576082229614: Accuracy = 0.5365853377264548\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 1.0272624492645264: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.1881730556488037: Accuracy = 0.5312721633895232\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 1.0157896280288696: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.1903432607650757: Accuracy = 0.526190118770353\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 1.0360714197158813: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.2013269662857056: Accuracy = 0.5213825464135913\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 1.0241931676864624: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.218031883239746: Accuracy = 0.5166794919222373\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 1.0168507099151611: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.2088627815246582: Accuracy = 0.5118884873468889\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 1.03441321849823: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.1986783742904663: Accuracy = 0.5082020332699931\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 1.0189589262008667: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.2129508256912231: Accuracy = 0.5039519983623951\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 1.0070428848266602: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.215086817741394: Accuracy = 0.4997990177809764\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 1.0090123414993286: Accuracy = 0.4933333396911621\n",
      "Performance on test set: : Loss = 1.2319703102111816: Accuracy = 0.49585039032329736\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 1.038428783416748: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.2432936429977417: Accuracy = 0.4924019726401501\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.9647623896598816: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.2270649671554565: Accuracy = 0.4889757689255476\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.9562973976135254: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.231913447380066: Accuracy = 0.4858157638649164\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 1.0195271968841553: Accuracy = 0.47333332896232605\n",
      "Performance on test set: : Loss = 1.265598177909851: Accuracy = 0.48250046821639575\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 1.0158456563949585: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.2559329271316528: Accuracy = 0.479089904449182\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.9632661938667297: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.264862060546875: Accuracy = 0.4763498527620148\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 1.0169519186019897: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.2666380405426025: Accuracy = 0.4732423269214896\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 1.0033676624298096: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.2791892290115356: Accuracy = 0.4705609631022219\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.9830028414726257: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.2644625902175903: Accuracy = 0.467623395530046\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.9615647196769714: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.2842015027999878: Accuracy = 0.4653550362386195\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.9676859378814697: Accuracy = 0.46666666865348816\n",
      "Performance on test set: : Loss = 1.2910128831863403: Accuracy = 0.46275984921025165\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 1.0150636434555054: Accuracy = 0.47999998927116394\n",
      "Performance on test set: : Loss = 1.281328797340393: Accuracy = 0.46037458802937037\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.9661298394203186: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.3123341798782349: Accuracy = 0.4576775363889638\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.948060929775238: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.3152117729187012: Accuracy = 0.4557078368456503\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.9860907793045044: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.324900507926941: Accuracy = 0.45322186763662986\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.9554718136787415: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.314283847808838: Accuracy = 0.4513404956951361\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.9796150922775269: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.319675326347351: Accuracy = 0.448913249065437\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.9428677558898926: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.3480794429779053: Accuracy = 0.4466557505403199\n",
      "\n",
      "Data shuffled. Epoch:  67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.9162856936454773: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.3249688148498535: Accuracy = 0.44446641940493753\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.922012448310852: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.3380993604660034: Accuracy = 0.4427262641798032\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.9607943892478943: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.3622205257415771: Accuracy = 0.44096912388579057\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.9609952569007874: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.3362066745758057: Accuracy = 0.4395701509631844\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.9344921708106995: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.3456848859786987: Accuracy = 0.4378820184662516\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.9535274505615234: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.3712458610534668: Accuracy = 0.4364923035382241\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.8811252117156982: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.389215111732483: Accuracy = 0.43537909072079223\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.926508903503418: Accuracy = 0.4866666793823242\n",
      "Performance on test set: : Loss = 1.3883413076400757: Accuracy = 0.43343432380025393\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.8890438675880432: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.4514127969741821: Accuracy = 0.43281461218868433\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.9480715990066528: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.3793220520019531: Accuracy = 0.431134238376681\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.896725594997406: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.3657042980194092: Accuracy = 0.4302439611885241\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.9277065992355347: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.430516004562378: Accuracy = 0.42901883497071086\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.9201693534851074: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.4505133628845215: Accuracy = 0.4279569210555216\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.9327430129051208: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.4451009035110474: Accuracy = 0.42683400991507\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.9575102925300598: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.4723656177520752: Accuracy = 0.4259543541754742\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.9094473123550415: Accuracy = 0.5133333206176758\n",
      "Performance on test set: : Loss = 1.4607231616973877: Accuracy = 0.4249255071874681\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.9608964920043945: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.4425493478775024: Accuracy = 0.42417428029863063\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.8988892436027527: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.4706717729568481: Accuracy = 0.4232325632920759\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.8479014039039612: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.48114812374115: Accuracy = 0.4223953016923364\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.9085241556167603: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.5119597911834717: Accuracy = 0.42153671315560803\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.9075363278388977: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.510396122932434: Accuracy = 0.42049605741362195\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.8823274970054626: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.4877241849899292: Accuracy = 0.4195984198404474\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.9127553105354309: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.5266320705413818: Accuracy = 0.4187603112673386\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.8388805985450745: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.490236520767212: Accuracy = 0.417979754636317\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.9086498022079468: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.460628628730774: Accuracy = 0.4171776297938297\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.8793257474899292: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.5145232677459717: Accuracy = 0.4166988902238374\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.9513359665870667: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.5141136646270752: Accuracy = 0.4161169811251784\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.8904687762260437: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.493976354598999: Accuracy = 0.415472638097352\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.8532248139381409: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.52506422996521: Accuracy = 0.41480478695624046\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.8438853621482849: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.5215818881988525: Accuracy = 0.414334347438398\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.8574682474136353: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.5599087476730347: Accuracy = 0.4138736898995313\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.8495715856552124: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.5635664463043213: Accuracy = 0.41324262200448286\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.9054407477378845: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.5342528820037842: Accuracy = 0.412802456179283\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.7785177230834961: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.5831218957901: Accuracy = 0.41233582919895373\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.8872841596603394: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.5241807699203491: Accuracy = 0.41177376176558766\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.8632853031158447: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.5575532913208008: Accuracy = 0.41125729366217884\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.8748006224632263: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.552195429801941: Accuracy = 0.410853717843722\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.8715547919273376: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.5363447666168213: Accuracy = 0.41035608542599\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.8671711087226868: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.5728261470794678: Accuracy = 0.4101706818601378\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.7802767157554626: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.545076847076416: Accuracy = 0.4098223015390171\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.8563812375068665: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.550093412399292: Accuracy = 0.4094805408539112\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.8256529569625854: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.5535931587219238: Accuracy = 0.4091451049420577\n",
      "\n",
      "Data shuffled. Epoch:  109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.8528249859809875: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.5439010858535767: Accuracy = 0.4088159038093846\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.835224986076355: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.544066071510315: Accuracy = 0.4083642969717278\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.8708615899085999: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.5623992681503296: Accuracy = 0.4081436810796644\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.8024742007255554: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.5444607734680176: Accuracy = 0.40799016917573344\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.8853675127029419: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.6154097318649292: Accuracy = 0.4078081780571568\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.8568509817123413: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.5720010995864868: Accuracy = 0.40762941996339436\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.8883481025695801: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.4926574230194092: Accuracy = 0.40726952648964715\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.8325039744377136: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.536860704421997: Accuracy = 0.4073422450295812\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.8362374305725098: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.5762208700180054: Accuracy = 0.4071420479905245\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.8062769174575806: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.52016282081604: Accuracy = 0.40685547148670975\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.8161109685897827: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.56820809841156: Accuracy = 0.4067815423826236\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.7791658043861389: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.5280144214630127: Accuracy = 0.40670890849686714\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.7575085759162903: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.5816396474838257: Accuracy = 0.4068417237473036\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.7965682744979858: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.601008653640747: Accuracy = 0.40682767567564765\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.7892614006996155: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.5810502767562866: Accuracy = 0.4068425282788993\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.8043073415756226: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.6156307458877563: Accuracy = 0.4069709175521255\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.8446040749549866: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.5524826049804688: Accuracy = 0.40695614002876185\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.7707587480545044: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.586938500404358: Accuracy = 0.40688567002032183\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.8005407452583313: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.5996495485305786: Accuracy = 0.4068718107534924\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.8711032867431641: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.5525158643722534: Accuracy = 0.40683061493427586\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.7645140290260315: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.5979310274124146: Accuracy = 0.406735471187468\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.8101903200149536: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.576107144355774: Accuracy = 0.4068315526491141\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.791350245475769: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.589199185371399: Accuracy = 0.40673789632571405\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.8008055090904236: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.6023313999176025: Accuracy = 0.4066990537375565\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.8205699920654297: Accuracy = 0.5666666626930237\n",
      "Performance on test set: : Loss = 1.5734268426895142: Accuracy = 0.4068461304797986\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.7487863898277283: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.6481266021728516: Accuracy = 0.40685286858245484\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.7758564949035645: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.6174196004867554: Accuracy = 0.4068922815643319\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.760381281375885: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.592869758605957: Accuracy = 0.40698280276368587\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.7523393630981445: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.5873793363571167: Accuracy = 0.40707192117534235\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.7785148024559021: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.5778807401657104: Accuracy = 0.40715974809239736\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.7965842485427856: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.629021167755127: Accuracy = 0.4071451306765813\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.7753339409828186: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.5619258880615234: Accuracy = 0.4073064101045419\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.8047720193862915: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.636428952217102: Accuracy = 0.4074653291880434\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.7618968486785889: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.6094775199890137: Accuracy = 0.40759724855091667\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.7170577645301819: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.669064998626709: Accuracy = 0.4076289848740734\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.747550904750824: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.521583914756775: Accuracy = 0.4077334153841507\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.7724495530128479: Accuracy = 0.5666666626930237\n",
      "Performance on test set: : Loss = 1.5122243165969849: Accuracy = 0.40783631546010074\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.7378897666931152: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.5789169073104858: Accuracy = 0.4078177247998254\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.7781328558921814: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.63491690158844: Accuracy = 0.4080140441622685\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.7883970737457275: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.5239530801773071: Accuracy = 0.40808913907477923\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.7953362464904785: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.637548804283142: Accuracy = 0.40818074357955036\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.77991783618927: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.6504238843917847: Accuracy = 0.4083471515974677\n",
      "\n",
      "Data shuffled. Epoch:  151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.772823691368103: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.6538797616958618: Accuracy = 0.40850530328002455\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.7276456952095032: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.5454540252685547: Accuracy = 0.4086902290285\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.7801164388656616: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.6238703727722168: Accuracy = 0.4088040431440515\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.7473934888839722: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.5955958366394043: Accuracy = 0.40898445700105196\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.7587274312973022: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.578084111213684: Accuracy = 0.4091173444163973\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.7279914021492004: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.6038869619369507: Accuracy = 0.40927086808680296\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.7058663964271545: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.6145689487457275: Accuracy = 0.4093333027094223\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.7334915399551392: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.60092031955719: Accuracy = 0.40943916439736044\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.7528848052024841: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.673832893371582: Accuracy = 0.40956563869337814\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.6668986678123474: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.6294463872909546: Accuracy = 0.40971232245968064\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.7004805207252502: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.6189707517623901: Accuracy = 0.4098570877444654\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.7181997895240784: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.62907075881958: Accuracy = 0.4099569123839609\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.6904498934745789: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.5767669677734375: Accuracy = 0.4100016158907897\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.7181803584098816: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.6455498933792114: Accuracy = 0.4100567278543009\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.7330583333969116: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.6078860759735107: Accuracy = 0.4102850193814168\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.6808102130889893: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.6417126655578613: Accuracy = 0.4103898561941866\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.7424951791763306: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.6262139081954956: Accuracy = 0.41054593121983807\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.7510659694671631: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.5940914154052734: Accuracy = 0.41066863748716487\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.7310287356376648: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.6504994630813599: Accuracy = 0.4107744915657185\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.7263264060020447: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.5874754190444946: Accuracy = 0.41090488771723993\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.7365131974220276: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.6231286525726318: Accuracy = 0.41103368276213237\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.671100914478302: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.656519889831543: Accuracy = 0.41118116848444003\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.6883248686790466: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.5825848579406738: Accuracy = 0.41133657027344994\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.7644451856613159: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.6791174411773682: Accuracy = 0.41145975784772015\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.6997267007827759: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.597779631614685: Accuracy = 0.4116815765598986\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.6889824271202087: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.6678322553634644: Accuracy = 0.4118217771966769\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.7210244536399841: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.6122206449508667: Accuracy = 0.41207297632371753\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.7141919732093811: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.7047772407531738: Accuracy = 0.4123602589804783\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.730303943157196: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.6447460651397705: Accuracy = 0.41251268688526954\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.6948760151863098: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.608208179473877: Accuracy = 0.4127026552168245\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.7027388215065002: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.6267069578170776: Accuracy = 0.4129862674655723\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.6844839453697205: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.6220234632492065: Accuracy = 0.41315232860067175\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.7406971454620361: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.6849931478500366: Accuracy = 0.41333046285296177\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.6666090488433838: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.632838249206543: Accuracy = 0.41346894724466543\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.6428766846656799: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.6270575523376465: Accuracy = 0.41369953284781313\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.7321950793266296: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.6016900539398193: Accuracy = 0.4140205338644045\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.6815119385719299: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.6491519212722778: Accuracy = 0.41426870214114\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.6540661454200745: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.5660405158996582: Accuracy = 0.4144445184210632\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.7626103162765503: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.5763944387435913: Accuracy = 0.41477429414160644\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.7510416507720947: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.7062482833862305: Accuracy = 0.4149137463662377\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.6922430992126465: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.5441042184829712: Accuracy = 0.4151154295638939\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.7949380278587341: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.5920847654342651: Accuracy = 0.4152875118874806\n",
      "\n",
      "Data shuffled. Epoch:  193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.6949091553688049: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.6285006999969482: Accuracy = 0.4156187300832232\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.6637300848960876: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.6906336545944214: Accuracy = 0.41583960209873855\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.6858822703361511: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.56901216506958: Accuracy = 0.41604504297154965\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.6633253693580627: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.6340404748916626: Accuracy = 0.41635753286905386\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.7628681659698486: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.7000912427902222: Accuracy = 0.41666665590348057\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.6862926483154297: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.618970274925232: Accuracy = 0.41693764360648067\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.6818009614944458: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.674464464187622: Accuracy = 0.4171111178237048\n",
      "\n",
      "Optimisation finished!\n"
     ]
    }
   ],
   "source": [
    "%run trainRNN_utils.py\n",
    "%run trainRNN_network_utils.py\n",
    "\n",
    "trainLosses = {}\n",
    "testLosses = {}\n",
    "F1_scores = {}\n",
    "trainAccuracy = {}\n",
    "attention_matrixA = {}\n",
    "attention_matrixB = {}\n",
    "tst_prediction = {}\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "\n",
    "    # Create network\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Gene A and Gene B input and output placeholders\n",
    "    ## Input placeholders\n",
    "    with tf.variable_scope('geneA'):\n",
    "\n",
    "        rSnpRnaA_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum + 1, iSnum])\n",
    "\n",
    "        hidden_output_A, current_state_A = dynamicLSTM_Attention(rSnpRnaA_pXNS, \n",
    "                                                                 n_layer, \n",
    "                                                                 n_hidden, \n",
    "                                                                 dropout)\n",
    "\n",
    "    hidden_state_A = current_state_A[-1].h\n",
    "\n",
    "    with tf.variable_scope('geneB'):\n",
    "\n",
    "        rSnpRnaB_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum + 1, iSnum])\n",
    "\n",
    "        hidden_output_B, current_state_B = dynamicLSTM_Attention(rSnpRnaB_pXNS, \n",
    "                                                                 n_layer, \n",
    "                                                                 n_hidden, \n",
    "                                                                 dropout)\n",
    "\n",
    "    hidden_state_B = current_state_B[-1].h\n",
    "\n",
    "    rRelated_pXC = tf.placeholder(tf.float32, \n",
    "                                  shape = [None, iCnum],\n",
    "                                  name = 'rRelated_pXC')\n",
    "\n",
    "    context_vectorA, attention_weightsA = attention(hidden_state_A, hidden_output_A, n_hidden)\n",
    "    context_vectorB, attention_weightsB = attention(hidden_state_B, hidden_output_B, n_hidden)\n",
    "\n",
    "    encoding = tf.concat((context_vectorA, context_vectorB), axis=1)\n",
    "\n",
    "    # Dense Layer\n",
    "    logits = tf.layers.dense(encoding,\n",
    "                            units = n_classes, \n",
    "                            activation = None,\n",
    "                            kernel_regularizer=tf.contrib.layers.l2_regularizer(0.4),\n",
    "                            kernel_initializer = tf.initializers.random_normal() )\n",
    "\n",
    "    prediction = tf.argmax(logits, 1)\n",
    "\n",
    "    l2 = lambda_l2_reg * sum(\n",
    "        tf.nn.l2_loss(tf_var)\n",
    "            for tf_var in tf.trainable_variables()\n",
    "            if not (\"bias\" in tf_var.name))\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                                         labels=tf.argmax(rRelated_pXC,1)) + l2)\n",
    "\n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Accuracy; precision, and recall for f1 score\n",
    "    correct_pred = tf.equal(prediction, tf.argmax(rRelated_pXC,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Precision and recall\n",
    "    rec, rec_op = tf.metrics.recall(labels = tf.argmax(rRelated_pXC, 1), predictions = prediction)\n",
    "    pre, pre_op = tf.metrics.precision(labels = tf.argmax(rRelated_pXC, 1), predictions = prediction)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        \n",
    "        # Train the network \n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        train_f1_score = [None] * n_epoch\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        test_f1_score = []\n",
    "\n",
    "        # Reshape and retrive the merged training and test data\n",
    "        rSnpRnaA_tr_nXNS = input_reshape(rSnpA_tr_nXSN, rRnaA_tr_nXS)\n",
    "        rSnpRnaB_tr_nXNS = input_reshape(rSnpB_tr_nXSN, rRnaB_tr_nXS)\n",
    "        rSnpRnaA_tst_nXNS = input_reshape(rSnpA_tst_nXSN, rRnaA_tst_nXS)\n",
    "        rSnpRnaB_tst_nXNS = input_reshape(rSnpB_tst_nXSN, rRnaB_tst_nXS)\n",
    "\n",
    "        for epoch_idx in range(n_epoch): \n",
    "\n",
    "            print(\"Data shuffled.\" + \\\n",
    "                  \" Epoch: \", epoch_idx)\n",
    "\n",
    "            # Shuffle classes\n",
    "            rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS = shuffle_classes(rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS)\n",
    "\n",
    "            for batch_idx in range(n_batch):\n",
    "\n",
    "                batch_rSnpRnaA_tXNS = extract_batch_size(rSnpRnaA_tr_nXNS, batch_idx, batch_size)\n",
    "                batch_rSnpRnaB_tXNS = extract_batch_size(rSnpRnaB_tr_nXNS, batch_idx, batch_size)\n",
    "                batch_rRelated_tXC = extract_batch_size(rRelated_tr_nXC, batch_idx, batch_size)\n",
    "\n",
    "                # Fit training data\n",
    "                opt, tr_loss, tr_acc = sess.run(\n",
    "                    [optimiser, cost, accuracy], \n",
    "                    feed_dict = {\n",
    "                        rSnpRnaA_pXNS: batch_rSnpRnaA_tXNS,\n",
    "                        rSnpRnaB_pXNS: batch_rSnpRnaB_tXNS,\n",
    "                        rRelated_pXC: batch_rRelated_tXC               \n",
    "                    })\n",
    "\n",
    "                tst_loss, tst_pre, _, tst_rec, _ = sess.run(\n",
    "                    [cost, pre, pre_op, rec, rec_op],\n",
    "                    feed_dict = {\n",
    "                        rSnpRnaA_pXNS: rSnpRnaA_tst_nXNS,\n",
    "                        rSnpRnaB_pXNS: rSnpRnaB_tst_nXNS,\n",
    "                        rRelated_pXC: rRelated_tst_nXC\n",
    "                    })            \n",
    "\n",
    "                if batch_idx == (n_batch - 1):\n",
    "\n",
    "                    train_losses.append(tr_loss)\n",
    "                    train_accuracies.append(tr_acc)\n",
    "\n",
    "                    tst_f1_score = 2 * ( tst_rec * tst_pre ) / (tst_rec + tst_pre) \n",
    "\n",
    "                    test_losses.append(tst_loss)\n",
    "                    test_f1_score.append(tst_f1_score)\n",
    "\n",
    "            print(\"Performance on training data\" + \n",
    "                 \": Loss = {}\".format(tr_loss) + \n",
    "                 \": Accuracy = {}\".format( tr_acc ) )\n",
    "\n",
    "            print(\"Performance on test set: \" + \n",
    "                  \": Loss = {}\".format(tst_loss) + \n",
    "                  \": Accuracy = {}\".format(tst_f1_score) )\n",
    "            print(\"\")\n",
    "            \n",
    "\n",
    "            if epoch_idx == (n_epoch-1):\n",
    "\n",
    "                for i in range(rSnpRnaA_tst_nXNS.shape[0]):\n",
    "                    rSnpRnaA_tst_nXNSA = np.expand_dims(rSnpRnaA_tst_nXNS[i], axis=0)\n",
    "                    rSnpRnaB_tst_nXNSB = np.expand_dims(rSnpRnaB_tst_nXNS[i], axis=0)\n",
    "                    rRelated_tst_nXC_ = np.expand_dims(rRelated_tst_nXC[i], axis=0)\n",
    "\n",
    "                    pred, at_weightA, at_weightB = sess.run(\n",
    "                        [prediction, attention_weightsA, attention_weightsB],\n",
    "                        feed_dict = {\n",
    "                                rSnpRnaA_pXNS: rSnpRnaA_tst_nXNSA,\n",
    "                                rSnpRnaB_pXNS: rSnpRnaB_tst_nXNSB,\n",
    "                                rRelated_pXC: rRelated_tst_nXC_\n",
    "                                }) \n",
    "\n",
    "                    at_weightA = np.reshape(at_weightA, (-1, 1))\n",
    "                    at_weightB = np.reshape(at_weightB, (-1, 1))\n",
    "\n",
    "                    attention_matrixA[dropout] = at_weightA\n",
    "                    attention_matrixB[dropout] = at_weightB                    \n",
    "                    tst_prediction[dropout] = pred\n",
    "    \n",
    "        trainLosses[learning_rate] = train_losses\n",
    "        testLosses[learning_rate] = test_losses\n",
    "        trainAccuracy[learning_rate] = train_accuracies\n",
    "        F1_scores[learning_rate] = test_f1_score\n",
    "        print(\"Optimisation finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIcAAAFNCAYAAACaOg/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd3zV9b348dc7ORkkZLKEJBAgEqYDGSIOxIHlWqyjgLaKVX+2t9rbVu+99np71dohtbXDYod1tlWwohVsBcWBlDoYTggj7AxmwggJWSfv3x+f7yEnIQnZ55C8n4/H95HznefzPUm+7+95fz9DVBVjjDHGGGOMMcYY0z1FhLoAxhhjjDHGGGOMMSZ0LDlkjDHGGGOMMcYY041ZcsgYY4wxxhhjjDGmG7PkkDHGGGOMMcYYY0w3ZskhY4wxxhhjjDHGmG7MkkPGGGOMMcYYY4wx3Zglh4wJUyJyVESGhLocxhgDICKR3nVpYCv2zRIR7YhymeYRkU0ickGoy2GMMQEiMlxEqkNdju5MRLaKyKRQl8OEB0sOdQMiskNEjnk39YFpgLfuce+GsUZEbg5xUUNORDJFREXEF+qyqGpPVd3W3scVkQdEpMr7OzgkIu+1JCiIyHIRua29y2WMaV/1rvk19eLAV1p6PFX1e9elXR1R3q5IRHxeTMkMdVlUNVtV/9nexxWR20TE7/1dHRGRj0XkCy3Y/y8i8kB7l8sY03ztHS+CjvuBiHy1PcvaFYhIrBcb0kNdFlUdqqrvt/dxReQbIlIdFBs+EpFpLdh/gYh8v73LZZpmyaHu44veTX1gKvSWfwp8E/gohGUD3E10qMvQWUQkMsRFeEFVewK9gXeAF0NcHmNMOwu+5gO7qBsHnqu/fXe6Bnc1YfC7+6f3d5YMPAH8VUQSQlwmY0wztTRemFNDGMSG5UGx4VngRRGJD3GZTBMsOdTNqepjqvoWUH6ybUVkuojkiEiJiBSIyH8GrbtKRD7xMsNbReQKb/kAEVksIsUiskVE/l/QPg+IyELvqeER4GYRiRCR73nHKBKRv4pIaiPl2SAiVwbN+0Rkv4iM9TLyf/GOcUhEVotIv7Z8Vicrm4i8KCJ7ROSwiKwQkVFB654Rkd+JyGsiUgpc7C17TET+4X2mH4rI0KB9VESygvZvatvLvRpgh0XktyLybnNq96hqNfAckCYifbxjpYjI373P8qD3Ot1b92PgAmCe9yRgnrd8uIgs837Pm0RkZls+a2NMxxORH4nICyIyX0RKgK+KyCTvSe8hEdktIo+KSJS3fZ1aMN419lERWeJdl94XkcHNfO9079pSLCK5InJL0LpzvSeMR0Rkr4j8zFseJyLPB13XV4lIb29dsog87ZU5X0QeFJEIb90w75p8WEQOiMjzjZRpmYh8o96ydSIyw7v+Pyoi+7zjfCYiI1v8oZ/4nreJyEbvWrtERDKC1s3zzuWIF8POC1rX0O/uR978X7zfxzoRGRu0T76ITAnav6ltx4mL6SXint6+KM2o3aOqNcCfgZ5AIH5FiIv1e7zf23IRGeGt+yYwC7jXiyl/85ani8jfvDi0XUTuaMvnbIxpG3HNiv9PRLZ519HnRCTZWxfvXSeKvf/xD8XdSz4CjAee8P6/H2nG+wwUd69cLCKbRWRO0LrJ4momHvGuJw819f7eulQR+ZO3fZ6I3B8UG4aLyErvmr5fRP7USJnekXr31N51e7r3uTzm7X9YRD4VkezWfs5Bx/+6uPvpYnH3/mlB634XFBtWici5QevmiouTL3ixYba37LlAvPDi11lB++wRkfOD9m9q2wneOZZ47/OyNKN2T1BsSACGeMfyichL4uL8Ie9zzvbW/QdwLfB/3t/Oi97yDBFZ5P0NbpN6Mdu0nSWHTEs8CXxdVROA0cDb4C4UwJ+A/8Jlhi8Ednj7LADygQHAdcBPRGRq0DGvAhZ6+z0HfAv4EnCRt89B4LFGyjMfuD5ofhpwQFU/AuYASUAG0Av4BnCsdad93MnKtgQ4HeiLq4lV/0nLDcCPcRfGld6y2cAPgBRgi7e+MQ1uK+7L0ULgf3Dnugk4r5Fj1CEi0cBNQJF3PuCuC08Dg4CBuM9tHoCq/i/wT+BO72nSneKeACwDnvfOfTbwW2mHL07GmA53Ne5/Nwl4AagGvo2rVTgZuAL4ehP73wD8H5CKe9r8w2a+7wvAdty1dBbwsIhc5K37DfAzVU3EJRgWesu/BsQB6bhr3TepfbDxZ9y1aihwDvBv3vbgrpX/wF0702lmTBGRM4H+wFLgC8C5uGt8Cu46V9zMc22QiFyLi5tXAX2AD3G/i4APgTNwn+1C3BPXmKD19X934GLUn3ExdQnwaBNFaHBb7z1ewdUASgVe8rZtzjn5cJ97JZAXtOrvuM/uNGCd976o6m+9sv/EiylXe1/c/g6sBtKAy4D/EpFLmlMGY0yH+E/gcuB83HW0Cvilt+42wIf7f+0N3AlUqurduP/j27z/77ub8T4v4u5j++Piyy9FZLK3bh7uWpGIu5680tT7e+ueAw7jEhITcNeyG711D3nHSMbd7/6hkTLVjw3n4GLQG8CVwFhc7EnxynywgWM0m4jMAr4DfBHoB3wM/CVok/eBMV4ZFuFiQ1TQ+mtxtXSScNdvcPHiKdy5vgX8qokiNLitiPTw3u93uHN91Stjc84pEBvKcd8LAxbhPrvTgI1euVHVR72y/9D72/myuFYXrwHv4e4drsA9WLgI035U1aYuPuESNUeBQ970SgPbrARuPslxduG+JCTWW/4H4JcNbJ8B+IGEoGUPAc94rx8AVtTbZwNwSdB8f1wA8jVw/CygBIjz5p8D7vNe34K7eJzRws8qE9BG3q8lZUv2jpPkzT8D/KneNs8ATwTNTwc2Bs0rkHWybXHJnfeD1gnupvy2Rs7xAVzQPOT9foqAKU18JmcBB4PmlwcfG/fF7p8N/E3cH+q/fZtssslNXhy4tN6yHwFvn2S//wRe9F77vOtSpjf/F+D3QdvOANY1cpwsQL3Xg71rZ3zQ+p8FrnHetfs+oFe9Y9yOi1Vj6i1PwyWGYoKW3Qgs814/j7uZTTvJuSYBZUC6N/9T4HHv9eW4G9eJQEQLPvc6n1m9dcuAOfW2rWionN51vQQY1djvzlu2NGj+DOBo0Hx+4Frf1LbAVGBXvWN/ADzQyDnehksqHvJ+r2XAtU18Jr29zyQ+6O/ogaD1k4Ft9fb5P+CPof4/ssmm7jA1Ei+2A5OD5gd7/+uCS9S/C4xu4FgfAF9t4r2GA9Xe69NxyYMeQet/iRdngFXA/zYQGxp8f9xDzlIgKmjZ14Al3uu/4hJO/U/yeaR6Maa/N/8I8Fvv9XRgPS7x1JLYEOtdB9MbWPcO8JWg+Sjv2tqvgW3F+z1ke/NzgTfqbTMX+HvQ/FjgUND8HuD8k22Li4P1r81rgO83co7f8ModiA2lwJea+ExOA2qAWG9+QfCxcQ/nc+vt8wPgd6H+n+lKk9Uc6j6+pKrJ3tSsJ4ANuBZ3EdwprtlSoBPjDGBrA9sPAIpVtSRo2U7cjXxAXt1dGAT8zateeAiXkPHjMud1qOoWb/0XRSQO98Uk8NT1z8DrwAIRKRSRh+tl1Vuj0bJ51UrnimtydoTamlO9mzhXcBfkgDJcVfzGNLbtgOBjq7taBmflG/JXVU3Gfa7rcE/ageNNN/4gIju9c1kBJEvj/SQNAiYGPhfvs/kK7iJvjAlvda5LXjX7f3jVzI8AD1L3OlZfS65hAQNwtTxLg5YFx4avASOBTV6V+ene8meAN3H92RR411wf7hoUA+wNugY9Rm3cuBt3c71GRD6XoGYKwVT1MK6W0CwREVztoOe8dW8Av8clmfaKyO+l7X3qDAIeCyrzAdyNcaAZ7397TRcO455Ex9PymNJU3w6NbTuAE2NIQ+8VbKUXU1JxT3bPD6zw4uPDXhOAI7iar9D439UgYGC9mPLfWEwxJiS862EG8FrQ/+THuJrmvXAtC94FFnrNnX7SxD1jUwYA+1U1uKZ/cGyYg0tkbxbXdCzQuXFj7z8Il4TZH1TuX1MbG76Lq436sdd8qsGOs1W1GJfMn+nVbJxFbeuAJd77/wHYI65rh+bEwaYMAn4fVOb9uAR8IDb8j3hdSeBiQyyd932jpbHhXS82BGpaBWqBBZqVPRIUGzbikl29GjnWICCzXmy4C4sN7cqSQ6bZVHW1ql6Fazr0Ci7jDu7CMLSBXQqB1Ho30AOBguDD1tsnD/hCUCIrWVVjVbWAhgWqel4F5HgJI1S1SlV/oKojcU2srsTVsGmLpsp2g1eGS3FPnzO9faSJc20vu/ECBhwP4s0a/UBVD+Cexj8gIv29xXcD2cBEdVV3LwwcOrBbvcPk4V38g6aeqvrvrTsdY0wnqv///AdcwjjL+/+/j7rXsfZQCPSWup1SHo8NqrpJVWfjYs0jwEsiEquqlar6gKqOwCUfrsYlovNwN7CpQdegRFU9wzveblW9TVX7A3cAj0vjfSMFYsr5uHukFYEVqvorVR2La1Y9EndT2hZ5wK31rp09VPVDEbnYO/61uJqoKbgawJ0VU9LqLctoaMP6vIdB/w7cKiJneItvwj1YmoqLj1ne8qZiSm69zyVBVZvVfMEY0768h44FwNQG7oEPqGqFqt6nqsNx94xfxiXXoWXXqUKgj9d8KSA4NmxQ1Vm42PAo8LKIRDfx/nm462ZKvdgw1jtegaregmsJ8B/AUyIysJGyBWLDRbhaMO8FPhtV/YWqno1LXJ2Ja5rdFnm41hz1Y8NaEbkM183F1bjYEKjV1OnfNzzNjQ1HcDWJvhHU7cTXcM2GL8bFhuHe8qZiw8YGYsPVLTwP0wRLDnVzIhItIrG4f8QocR05n/B34W33FRFJUtUq4AjuCSe4jPnXROQScR1PponIcFXNw108H/KOewZwK3Xbzdb3e+DHIjLIe98+InJVE9svwFVz/HeC+moQkYtFZIz35OAI7kJe0/AhGhTjlTk26DNpqmwJuOYARbinED9pwXu11T+AMSLyJe8p+h20IIuuqptwtaz+21uUgAs0h8R1uH1/vV324nUm5/k7MExEbhSRKG8aL16Ho8aYU0oCrn+GUu9/uKn+hlpFVbfjqqL/RERixHV2+TW82OBdS3qr68DyMO4GsUZEporIaO96fPy67sWad4Gfi0iiF4eyRORC73gzpbYzz0Pe8fyNFO9VXNOG+4AF3peiQCecE7xrbCmuaW5bYkokLqb8r9R2zpwsItd52yfgnhQfwNV6eoCmawG1p5WAT0T+3Xuyey1BtUtPRlX34/qr+D9vUf34WL9vvfox5X2gUkTuDnxWXjxvdhmMMe3u98Bc8TrNF5G+IvJF7/WlIjIy6NpcTe31sf7/d1O2AJ8DP/Jiw1hcbaFAbLhJRHqpqp/a2KCNvb8Xaz7A9WmX4MWG06W28+VZIjLAu84f8srQWGxYBIwC7qVubDhXXAf+7RUbAt83vi+1nTOneNdhcNfTKlxtomhc7d7YFrxfW6wAeojI7V5smIlLhjWLqu7F9SkUHBvKcbEhHtfcOVj9v52VACLyHe+z8onIGRI0mIJpO0sOmTdwiYDzgMe91xc2su2NwA6v6t83cE9sUdVVuBv7X+Iu1u/iqv6By7Jn4p4G/A3XD82bTZTn18Bi4A1xvex/gOvjoUGquht3I3ketR1ygkuOLMQFiQ1emf4MIK45wO+bKAO4Jw3HgqapJynbn3BVXwuAHG9dp/Bq/3wZeBh3gR2J++JV0YLD/Ay4XUT64jqe64H7UvIBrplFsF8D14kbXedR70nx5binNIW46qg/xTXzMMacWu7G3YyX4GoRvdD05q02C5eE2YO7Vt+rqsu9ddOBDd519ufALFWtxFVpfxl3XV+Pa2IWeCjwVdzNZQ6umv2L1CbJJwKrxY0U+TJwh6ruaqhQqlqOqxl7KXU7h07GPQg5hGs2vBv4BYC4EXxePcn5bqRuTLlRVV/0jvGiF1c/ww2sAK5p1ptArvd+R7z37HCqWoF7Kv0N3Gc50ytPS2LKL4EZ3hPip3GxoRD3e3uv3rZPAGd6MWWhulE0p+P68NiBi0V/ABJbe07GmDZ7GHdNetu7Nr+H648GXE3DRbi4sQ53vQjEjl8CN3n/3w839QZewuXLuPvYPd4x/ktVA4O4XIlrblyC68N0pvfAuqn3vx53/d6IG0TgBWqblU0C1orIUVzMuL2xlgqqWob7DtBQbHgGFxu24b4L/BpARH4g3giMTdhC3dhwg6rOx/WF9LIXGz7B1bAB9wBjBa47j2246+P+k7xHu/Ca+12Dq7l0ENe59+u0LDb8ArjWS3w9iSv7HlxScGW9bR8HxotrQrbA+11Px33n2+nt+zua15zdNJN4iU9jTBfhPXXIx3Vm906oy2OMMebUJiJrgV+p6p9DXRZjjDHhQUQ+BeZ6CS3TBVjNIWO6ABGZ5jVJiMFVeRU6sfaSMcaYrkNEpohIP6/a/q24viBeD3W5jDHGhI7XbUdfrwuJ23F9zi4LdblM+/GFugDGmHYxCVfNNRrXrOJLWne0B2OMMaa5RuCaX8Tjmi9cq6r7QlskY4wxITYKFxvicE3irvG6tzBdhDUrM8YYY4wxxhhjjOnGrFmZMcYYY4wxxhhjTDfWrOSQiFwhIptEZIuIfK+B9b8UkU+8abOIHApa5w9at7g9C2+MMcYYY4wxxhhj2uakzcpEJBLYjBtCLx9YDVyvqjmNbP8t4GxVvcWbP6qqzR5irnfv3pqZmdnczY0xpltZu3btAVXtE+pyBBORDOBPuOFhFXhcVX8tIqm4tumZuCGpZ6rqwQb2nwN835v9kao+29T7WZwwxpjGhWOc6GwWJ4wxpmFNxYjmdEg9AdiiqtsARGQBcBWu09uGXA/c35qCAmRmZrJmzZrW7m6MMV2aiOwMdRkaUA3craofiUgCsFZElgE3A2+p6lyv1un3gHuCd/QSSPcD43CJpbUisrihJFKAxQljjGlcmMaJTmVxwhhjGtZUjGhOs7I0IC9oPt9b1tAbDQIGA28HLY4VkTUi8oGIfKmR/W73tlmzf//+ZhTJGGNMuFDV3ar6kfe6BNiAixNXAYFaQM8CDcWAacAyVS32EkLLgCs6vtTGGGOMMcaYgPbukHo2sFBV/UHLBqnqOOAG4FciMrT+Tqr6uKqOU9Vxffp061qwxhhzShORTOBs4EOgn6ru9lbtwTU7q6/ZDyCMMcYYY4wxHaM5yaECICNoPt1b1pDZwPzgBapa4P3cBizHfWkwxhjTxYhIT+Al4DuqeiR4nboO7pru5K7pY1sNU2OMMcYYYzpIc/ocWg2cLiKDcUmh2bhaQHWIyHAgBXg/aFkKUKaqFSLSG5gMPNweBTfGGBM+RCQKlxh6TlVf9hbvFZH+qrpbRPoD+xrYtQCYEjSfjnuQUIeqPg48DjBu3LgTkkxVVVXk5+dTXl7epvPoamJjY0lPTycqKirURTHGmJCyONEwixPGmICTJodUtVpE7gReByKBp1R1vYg8CKxR1cDw9LOBBVp3+LMRwB9EpAZXS2luY6OcGWOMOTWJiABPAhtU9RdBqxYDc4C53s9FDez+OvAT72ECwOXA/7S0DPn5+SQkJJCZmYkrjlFVioqKyM/PZ/DgwaEujjHGhJTFiRNZnDDGBGtOzSFU9TXgtXrL7qs3/0AD+70HjGlD+YwxxoS/ycCNwOci8om37F5cUuivInIrsBOYCSAi44BvqOptqlosIj/E1VIFeFBVi1tagPLycrvhr0dE6NWrF9YMzxhjLE40xOKEMSZYs5JDxhhjTGNUdSXQ2N32JQ1svwa4LWj+KeCptpbDbvhPZJ+JMcbUsmviiewzMcYEtPdoZcYYY0y3tXTpUrKzs8nKymLu3LknrF+xYgVjx47F5/OxcOHCEJTQGGNMKFmcMMaEK0sOGWOMMe3A7/dzxx13sGTJEnJycpg/fz45OXW72Rs4cCDPPPMMN9xwwrgOxhhjujiLE8aYcNbtmpXVVNfw3iPvsX/9fuL6xDHl/inEJMaEuljGGGNOcatWrSIrK4shQ4YAMHv2bBYtWsTIkSOPb5OZmQlARIQ9mzGms+0/Vs3mw5UIcE6fWGIi7f/QdC6LE8aEpw0HKzhWXcPYPj0AKK+u4aMD5ZzRK5aeUd3nf7FbJYdUlaXfWcrqx1YfXyYiXP7zy0NYKmOMMV1BQUEBGRkZx+fT09P58MMPQ1giY0xAzsEKFu8oOT7/WVE51wxJpG+PbnUrbELM4oQx4UdVWeTFh6ToSIYmRfNWQSmfF1dQUlXDtIyeIS5h5+lWEfGjJz5i9WOriYyO5IL/vYDl9y9n9WOrmXTXJBIGJIS6eMYYY9rB3I8PdMhxv3d27w45rjGmYx2q8LN011EARqXEsO9YNfvL/fx1yxHmDE8iISoyxCXs+kQkA/gT0A9Q4HFV/bWIpAIvAJnADmCmqh5sYP85wPe92R+p6rNtKY/FCWNMQGWNHn+9vLCU5JgI1hVXALCrpCpUxQqJblNHqqKkgrfvfRuAL/7xi1x030WMuHYE1eXVrPjRihCXzhhjzKkuLS2NvLy84/P5+fmkpaWFsETGGIBl+UeprFGyk6O5clBP5mQnk9HTx9HqGl7eVoI/6IuB6TDVwN2qOhI4F7hDREYC3wPeUtXTgbe8+Tq8BNL9wERgAnC/iKR0WsnbkcUJY8JPWXVtDNhf7ufPmw8TWFJU4ae0quakx6iqUTYcrKDCf/Jtw1m3qTn04aMfUnagjPRJ6Zxx4xkATPnBFDb+bSNrH1/LhDsn0GdknxCX0hhjTFuF6snt+PHjyc3NZfv27aSlpbFgwQKef/75kJTFGFNrT1k1ABcPiEdE8AlcnZnIM5sPsbusmtX7j3Fuv7gQl7JrU9XdwG7vdYmIbADSgKuAKd5mzwLLgXvq7T4NWKaqxQAisgy4Apjf2vJYnDDGBJRV1yZ0fALlfiVSICUmkgPlfvKOVjE8pek+ij8rKmdZfimTT+vBBf3jO7rIHaZb1ByqKKngvZ+9B8DUH09FRADoO6ovY28fi/qVpd9eiqo9OTLGGNM6Pp+PefPmMW3aNEaMGMHMmTMZNWoU9913H4sXLwZg9erVpKen8+KLL/L1r3+dUaNGhbjUxnRtNaqUek+FE6Jrb3vjoiL4gtePxL/2lHG40h+S8nVHIpIJnA18CPTzEkcAe3DNzupLA/KC5vO9ZaccixPGhJ9AcmhoYhTfGpPK7KGJ3DQsmRFeQmjX0ZM3LSsqdzFk77FTO5Z0i5pDm/++mYrDFaRPSmfwxYPrrJv6w6msf2E9297cxtY3tpI1LStEpTTGGHOqmz59OtOnT6+z7MEHHzz+evz48eTn53d2sYzptgLNBeJ8QqT3cDBgcGI0w5Oj2XioktfzjvLlIYnHHyCajiEiPYGXgO+o6pHgz1tVVURa/aRWRG4Hbgc3HHy4sjhhTHipjRMRxERGkJkYDUCF3y3Pa0ZyKPCAobj81E4OdYuaQxte2gDAqFknZt7jescx6a5JAHz25886tVzGGGOMMabjHPX6ioj3NXzLe0laPLGRwrYjVaw9UN6ZRet2RCQKlxh6TlVf9hbvFZH+3vr+wL4Gdi0AMoLm071ldajq46o6TlXH9eljXUUYY5qnzIsTcfXixIB4Hz5x/RAFmic35kilO8ahCj/+U7g1UpdPDlWVVbFlyRYARlwzosFtRl8/GoBNizZRdax79UhujDHGGNNVBZJDPaMavuVNiI7kioGuedk7BaUcrDi1n/qGK3FVhJ4ENqjqL4JWLQbmeK/nAIsa2P114HIRSfE6or7cW2aMMW0WaFYW56tbc9QXIZzdOxaAN/OPNtkFzREv1tTgEkSnqi6fHNry+haqyqpIm5BGUkZSg9ukDk1lwPgBVB6tJPe13E4uoTHGGGOM6QilJ0kOAQxPjmFUSgx+hbcLSjuraN3NZOBGYKqIfOJN04G5wGUikgtc6s0jIuNE5AkAryPqHwKrvenBQOfUxhjTVsHNyuqb3D+OOJ+QX1rN+oMVDe5f7q853gQNoNiSQ+Fr8983AzD8muFNbjd6tqs9tG7+ug4vkzHGGGOM6XhHq0+eHAKYkhZHVATkHq5kw8GKOk+IVZXtRyrrjGhjWkZVV6qqqOoZqnqWN72mqkWqeomqnq6qlwaSPqq6RlVvC9r/KVXN8qanQ3cmxpiuprbm0IlxIjYygikD3Ohjb+WXsu9YNZ8eKK8zZH1JZd3YcCr3O9Tlk0N7P9kLwMDzm+6YbuR1IwHY+sZWavwW/I0xxhhjTnXH+xw6SXIoISqSSd5w9ot2lPD0pkO8U1BKSZWfjw+U88LWIzyz6ZA1OzPGmC7meHIoquEBCcakxjCoZxTH/MpTGw+xJO8o/9h59Pj6w/WSQ0WWHApPNf4a9ufsB6Dv6L5Nbps0MImkQUlUllQe38cYY4wxxpy6jvc51EiH1MHO7deDC/vH0SNS2HfMz4f7jvHCliO8v/cY4Doc/fPmQ3ywt4zX847y2q4SqmpO3Y5HjTHGNN2sDEBE+MLAngSeMQiw+XDl8VHMjngjlSVFuw2sWVmYOrj1INXl1SRmJBKbFHvS7TPOcwMh5L2X19FFM8YY0wUtXbqU7OxssrKymDt37gnrKyoqmDVrFllZWUycOJEdO3YAUFRUxMUXX0zPnj258847O7nUxnRdpc2sOQQQIcJ5p8XxzdGpzByaSGpMJAfK/ZRU1dA7NpJBPaMoq1aWF5bx8YFyPiuqYHmh9VFkWsbihDHhQ1WbbFYWkBwTyZxhydw0LInzTusBuD7qVPV4Z9SDE6IBKLLkUHja+7lrUtZvTL9mbR9IDuW/l99hZTLGGNM1+f1+7rjjDpYsWUJOTg7z588nJyenzjZPPvkkKSkpbNmyhe9+97vcc889AMTGxvLDH/6Qn//856EoujFdVnP7HAoWFSEMSYxmRmYCkV4rg/NPi2N2ViLXDE4gOzmac/rEEgGs3V/OtiOVHVBy0xVZnDAmvFTWKH6FqAh37W9K7x4+BsRHMbFvHPE+YXdZNVuOVB4fxj4t3kdspHCsWk/ZuNClk0P71u0DoM/oPs3aPmOy1Rwyxk9Qs2MAACAASURBVBjTOqtWrSIrK4shQ4YQHR3N7NmzWbSo7qjMixYtYs4cN2rzddddx1tvvYWqEh8fz/nnn09s7MlruRpjmkdVmzVaWWNOi/Nx9eBELh4QR3ZyNCLCsOQYrh6cyGXpPbmgv+ujaOXusnYtt+m6LE4YE15O1qSsIdGRwrn9aq//h71mZYnREUzq52oVvZlfiv8UbHbctZNDn7vkUHNrDvUb04+o+CiKtxRTus+qCRtjjGm+goICMjIyjs+np6dTUFDQ6DY+n4+kpCSKioo6tZzGdBflfvdEOCZCTvpEuDFZSdFM7BeHyIn7n9OnB1ERUFhWbR1Vm2axOGFMeGlOk7KGnNU7lnifsPeYn4LSagCSoiMZ16cHqTGRFFf4Wb3/WLuXt6P5Ql2AjhSoOXSyzqgDInwRpE9MZ/vb28l7P4/hVw3vyOIZY4zpAPKD1n0JPBm9/9R7AmRMd9bckcpaKzpSGJYUw/qDFawvruB8ryaRCX8WJ4wxUNsvXZyvZdeEqAhh8mlxvJHvKpTE+4SEqAgiI4TL0uN5YesR3ttzjFEpMSRER7Z7uTtKl605VHWsiuLcYiRS6D28d7P3S5uYBkDBqoKTbGmMMcbUSktLIy+vtllyfn4+aWlpjW5TXV3N4cOH6dWrV6eW05juoi1NypprdGoMAJ8Xl7OjpJLqU7AZgek8FieMCS/HWtGsLODs3rHcNtx1Un3biBQivRqqgxOjOT0pmsoaZVl+6SkVF7pszaEDGw+gNUrv4b3xxTb/NAeMGwDA7jW7O6poxhhjOlContyOHz+e3Nxctm/fTlpaGgsWLOD555+vs82MGTN49tlnmTRpEgsXLmTq1KkNNlcxxrRdmT9w099x/2ODEqLoGRXB4coaFmw5QkJUBGN7x9IrNpIhidH4WtmczXQsixPGGIBjfvcQoUcrkkMiQu8eDecZLkmLZ/uRSjYfruTxDQe5bkgifRvZNpyEfwlbKdDfUN8xzWtSFjBgvEsOFa4pRFXtYmyMMaZZfD4f8+bNY9q0afj9fm655RZGjRrFfffdx7hx45gxYwa33norN954I1lZWaSmprJgwYLj+2dmZnLkyBEqKyt55ZVXeOONNxg5cmQIz8iYU1vgaW1HJmgiRLhmcAKfF1ewq6SKogo/73odVPeP8zE7K5GYyC5bUd+0kMUJY8JLlRcn2ruCaXJMJDOzkliWd5T95X6WF5QyMyupfd+kAzQrOSQiVwC/BiKBJ1R1br31vwQu9mbjgL6qmuytmwN831v3I1V9tj0KfjIt7W8oIDE9kfi+8ZTuK+XQ9kOkDEnpiOIZY4zpgqZPn8706dPrLHvwwQePv46NjeXFF19scN8dO3Z0ZNGM6XaOJ4c6+EHfgPgoBsRHoapsPlzJzpIqcg9XsrusmoXbjjBzaFKrO8Q2XY/FCWPCh9cfdYdcowf2jOKG05OYt66YbSVVHKrwkxwT3v0PnTQ5JCKRwGPAZUA+sFpEFqtqTmAbVf1u0PbfAs72XqcC9wPjAAXWevsebNezaMDez/cCUDMktUX7iQgDxg0g97VcCtcUWnKoOdSrmhu4+TpwANavh5wc8PmgXz/30+eDyMgTp4QE6NULUlMhKip052GMaRUReQq4EtinqqO9ZS8A2d4mycAhVT2rgX13ACWAH6hW1XGdUmhjTJfndSVBK1oLtIqIkJ0cQ3ZyDOP7+nlu82Hyjlbzt+1HuHZw4vH+KIwxxoSHqg5+iNDDF8HwZDdwwSdF5UwZEN8h79NemlNzaAKwRVW3AYjIAuAqIKeR7a/HJYQApgHLVLXY23cZcAUwvy2Fbo68T1xyaHVCj+NVmpqr/7j+x5NDo2aOav/CnUoqK2H/figudkmfTZvgs8/g88/h0CE4ehQKCqCqqjYBVF7e+vdLTIQBA+Cyy+Dcc2HoUDf16OHWx8XVJqGMMeHiGWAe8KfAAlWdFXgtIo8Ah5vY/2JVPdBhpTPGdEv+TmhW1piUmEhmZyXy3JbDbDtSxdK8o/zboIROL4cxxpjGVWugWVnHxYmze8e65NCBckamxIR130PNKVkakBc0nw9MbGhDERkEDAbebmLftAb2ux24HWDgwIHNKFLTtuUfoXLPUYj14U9LbHHfQYFOqQtXF7a5LKcEVdiwAbZvh8OHXYJn3TpYvhw+/NAliJqjutpNPXvCyJFuEoF9+9xyv//EqboajhyBoiI4eNC9PnIENm6E3/zmxPeIiYEhQ+CMM2DMGDj/fJg82ZXZGBMSqrpCRDIbWifu4jsTmNqZZTLGmMBNf0c3K2tM7x4+Zg1N4i+bD/F5cQWDEqIYnRobkrIYY4w5UaBZWUfWME2L95GZEMWOkir+svkws7ISSYt3rWWOVddQoxDfgaNqtkR7f6OeDSxUVX9LdlLVx4HHAcaNG9fm4QNWve+GoZfBKUhkBBU1Smxk828M0iZ4w9mvLsBf5ScyKrzbBrZKZSW88gr84x/wxhuwZ0/D24lA//6uyVdKikvMnHmmS8z06+dq9KSluZ9VVW7q0QMiWvEHXlPjaiNt2gRLl7pmaVu3wrZtrryqrlbShg1ueuEFt1/PnjB8OEyY4GocjR0LGRlWw8iY8HABsFdVcxtZr8AbIqLAH7x4YIwxbdYZN/0nc1qcj8vSe7Ik7yiv5x0lQoSRKTGhK5AxxpjjqjqhhqmIcN2QRP6xs4QNhyp5Pe8oX8tOZn+5n+dzD1Ndo3xhYE9GhcHDg+YkhwqAjKD5dG9ZQ2YDd9Tbd0q9fZc3v3itc2Sja50gWb0AKKtSYluQ3+nZrye9sntRtKmI3Wt3k35uekcUMzTy8uCPf4THH4e9e2uX9+/vauMkJ7sEz8CBMGUKXHCBSww1R3S0m1orIsK916RJbmpIaWlt07aPP4bXX3fza9a46be/ddtlZcFXvwpf+IJLFlnNImNC5Xqabkp8vqoWiEhfYJmIbFTVFfU3au8apsaYri9QcygyxA+LzugVQ2FZFZ8WVbB4RwkllX4m9osLaZmMMcbUDlzQ0YMG+CKE6YMSyC89yL5jfpYXlrGuuJxyv3v/V3ce5WhVTchjQ3O+Ma8GTheRwbhkz2zghvobichwIAV4P2jx68BPRCTQq/PlwP+0qcTNcOx4csglNcqqa0ilZbV/Bl00iKJNRexYvuPUTw7t2QN/+APMn+8SKQFjxsCcOTBtGowadWrUtImPd8mesWPh5pvdsv37XS2jd96Bf/4TPvkEtmyBBx5wU1ISXHQRXHKJO9fs7CbewBjTXkTEB1wDnNPYNqpa4P3cJyJ/w/Vzd0JyqL1rmBpjuj5/GNQcAvfU+IqMnvTt4WNZfin/2nOMM3rF0iPUBTPGmG6uozukDhYVIZx/WhxL8o7y4b5jAGQmRJGVGM2bBaW8U1hGamwkpyeFrnbpSaOSqlYDd+ISPRuAv6rqehF5UERmBG06G1igqhq0bzHwQ1yCaTXwYKBz6o5U9qlrIhU7yg1jXxqoV9wCmRdlArDz3Z3tVq5Ot3Yt3HSTqwX0wAMuMRQXB1/+Mrz7Lnz6Kdx9N4wefWokhhrTp49L/jzwALz1lqsRtWQJ3H67q0F0+DAsXgzf/rZrfjZsmDvvJUtcP0fGmI5yKbBRVfMbWiki8SKSEHiNe4CwrhPL1+6WLl1KdnY2WVlZzJ0794T1FRUVzJo1i6ysLCZOnFhnWOKHHnqIrKwssrOzef31148vv+WWW+jbty+jR4/ujFMwpssIdZ9DwUSEc/r0YHBCFJU1yirviwHA4Uo/ywtKeSv/KDkHKwi6lTZdkMUJY8JHYFTLzuryZ0yvGNLjfSRERTBlQBzXDUlkXN8eXNDf1Rj6+46jlFY1nLvojNjQrI9BVV9T1WGqOlRVf+wtu09VFwdt84Cqfq+BfZ9S1Sxverr9it6wytJKKjfuhwih19n9AVdzqKUGXTQIgF0rd1HTiv1Dat06lywZNw7+/GfX8fOXvgRvvun69PnrX+HCC0/thFBTfD644gpXWyo3F3bsgKeeghtucM3WcnPhF7+A6dPd/IgR8LWvuaZ2n3/uOsT2t6jbLGO6NRGZj6s1mi0i+SJyq7dqNvWalInIABF5zZvtB6wUkU+BVcA/VHVpZ5W7vfn9fu644w6WLFlCTk4O8+fPJyen7sCeTz75JCkpKWzZsoXvfve73HPPPQDk5OSwYMEC1q9fz9KlS/nmN7+J37sO3XzzzSxdesp+LMaETHUIRytrTOALwJr9x9hwsIKVu8v4Y85BPth3jNX7y1m8o4RPitow6qsJaxYnjAkvnR0nIkT46rBk7hidyrn94o6/73n9ejAkMYqKGuWfu8tO2G/r4Up+9mkRn3ZwfOhy9VkL1xSCX5FhvUhNcZ06lVa1PMuWmJZIalYqlUcr2f3x7vYuZsfYu9fViBk7FlascM2p7r7bNbH6299cs6qoqFCXsvMNGuSSP8895z6jFSvgnnvcKGcxMW5ktGeega9/3fW7lJTklmdnu/1eeglKSkJ9FsaELVW9XlX7q2qUqqar6pPe8ptV9ff1ti1U1ene622qeqY3jQo8fDhVrVq1iqysLIYMGUJ0dDSzZ89m0aJFdbZZtGgRc+bMAeC6667jrbfeQlVZtGgRs2fPJiYmhsGDB5OVlcWqVasAuPDCC0ltbt9vxpjjAk+EWzAmSYcbEB/F6NQYqmpg0Y4SVu4po1pheHI0E/r2AODN/FL2llWHuKSmI1icMCa8VHVSn0MnIyJckhaPAJ8WlbPvWDWqyv5j1dSoknOwghqFtwtKW1Xxpbm6XC+9ee/lASBjTiM5xvUz1NoPMPPiTIq3FLP19a2kjU87+Q6qbmj2zk7AbNniask89hgc86opf/3r8NOfukSHqeXzuU62L7jAzVdWuj6K3n8fPvgAPvzQ9WFUWgqbN7vpmWdcR9sjR8LQoa6j7ssuc83TumrtK2NMixUUFJCRUTt+Q3p6Oh9++GGj2/h8PpKSkigqKqKgoIBzzz23zr4FBY2N/WCMaQ5/GNYcAvi3ga7/oX/uLmVAXBSTT4tjYIK7d6z0K58UlfParhJuzk5G7D6jS7E4YUx4Cacapr1ifZzdO5aPDpTzdkEpGT2j+OfuMqYMiCOvtAqACr+ycncZl2f07JAydLnkUP77rmuLiDNOIznaJYda0+cQwLAvDuOjP37EpsWbuPD7Fza+4caNrobJRx+55kgXXuhqpWRkuP5+kpJcXz/Dhrlh3tvC74eVK13Tp1273OhcwdVRv/hF1/fO2LFte5/uIjoaJkxw07e/Xbu8vBw2bHCjob36qkseffKJm156yW3Tv7+rXTRmDJx7rpsGD7aEkTGh9nwH/Q/eYP2AGHMqCac+h4KJCBP69mB8n9gTkj+XpMdTWaNMPq2HJYY6ksUJYwwQSBP4wuRye37/ONYfrGBHSRU7S1xCaPW+Y5RWKz4Bv8LHB8qZ0LfH8Yow7alLJYdUtU5yKCnGtZprrFOnkxlyyRB8PXwUri6kpLCEhAEJJ2705ptw7bUuWRPwzjtuqi8iwiUTzjrLJRISE10NlaQkSElxtVq2b3dJh/POc+v69nWJpepqlwj66U+hsLDucVNSXB87d93l+hkybRcbC2ef7abvfc91XL1li+uTaNky93vfvdtNy5fDb37j9uvTpzZRdO65MH48JDTwd2OM6XLS0tLIy8s7Pp+fn09aWlqD26Snp1NdXc3hw4fp1atXs/Y1xrRMdZiMVtaYhpI/URHCjEy7b+iqLE4YE17CpVlZQJwvgvP69eCdwjICqeZSr430oIQo4nwRfF5cwft7y/jCwPaPFV0qOXRoxyHKDpRBSg+iBibS07sbKKtuXRY/Ki6KoZcNZdPiTWx6dRPjvl4v8fLxx66j59JSuO46+OMfXdOypUtdbaK8PFe7p7TUdQSdm+tqo2zY4IaVb46YGJdM2rMHdnojpw0d6kbdioiAr34VrrnGJZZMx0lJcYme8ePhllugpga2bXMJo7VrXZO0Dz5wTdJefdVN4GoRZWW5JNOZZ8Lpp7v5rCxLGhnTUUL05Hb8+PHk5uayfft20tLSWLBgAc8//3ydbWbMmMGzzz7LpEmTWLhwIVOnTkVEmDFjBjfccAN33XUXhYWF5ObmMmHChJCchzFdRaC5QKTVwAk5EXkKuBLYp6qjvWUvANneJsnAIVU9q4F9dwAlgB+oVtW2Pwm1OGFMt1ejSg0gQJjkhgA4p08P1h+soKpG6dfDx8ZDlQCkx0eRnRzDuuIKPi+q4LzT4kiKbt/aQ10qo1CcWwyADEkhOjKCOG9MutY2KwPIvirbJYcW1UsO5eXBlVe6xM9XvuJGBQvcfFx/fcMHKy93TcDWrHGJhKoq6NnTDbV+8KBbn5np+rn5/HNXs6iw0PWDA66J2qOPwowZ1nQp1CIiapM8V1zhlqm6ml+BRNEHH7hmaLm5bvrrX2v3F3EJvokTXRPAfv3cz6ys0JyPMabNfD4f8+bNY9q0afj9fm655RZGjRrFfffdx7hx45gxYwa33norN954I1lZWaSmprJgwQIARo0axcyZMxk5ciQ+n4/HHnuMyEgX8K+//nqWL1/OgQMHSE9P5wc/+AG33nprU0UxxhDUrCxMaw51M88A84A/BRao6qzAaxF5BDjcxP4Xq+qBDitdJ7E4YUz4CK41FE7NeH0Rws3ZyQDsKqk6nhzK6BlFamwkI1NiWH+wgg/2HmNaO/c9JKrh1TZ23LhxumbNmlbtu/p3q3ntm68RcdUIev/4Ur4xMoWHPylCgf86sxeRrUgJHt17lEdOewRfrI//Lv5vonpEuWTO+ee7IeOnTHE1hWJiWlXmk9q/3yWUUlJcMiE6umPex3SMykr3+/vkE5fw27q1NllUVXXi9iNGwFVXuZHlxo2D5OTOL7MJayKytl2emp7CGooTGzZsYMSIESEqUXizz8Z0V79dV8yRqhr+fVRKuz9dDWfhGidEJBP4e6DmUNByAXYBU1U1t4H9dgDjWpIcsjjRMvbZmO6otKqG36wrJs4n/MeYXqEuToNqVPnjhoP4a+D2kSn4IoQD5dUsyytlcv84BvZs+UBYTcWILlVz6ODWgwBIeiLRXgYwzieUVitl1TUktOLGoGe/npx29mns+XgPu/65i6EXD4Qvf9klhoYPh5df7rjEELg+bC66qOOObzpWdLRrFnhWvVrSFRXw6aeuVtj69a7Z4PLltc0O58512w0b5hJGAwe66eyzXX9Ube3Y3BhjjOniwrVDanOCC4C9DSWGPAq8ISIK/EFVH++8ohljuqpAzaFwjhERIszJTgatHVGtd6yP60/vmBHJu1RyqHjTfgAmrFjAnm+5oR7jfBGUVvsprVYSWlnpZui0oez5eA9blm5h6As/cR0S9+0Lr73mavQY01IxMbWjpAVUVcGKFa6/okCTtM2b3RQsIgIGDKgdDW/IEDcNHep+ZmS4bYwxxphuLNw7pDbHXQ801Rnn+apaICJ9gWUislFVV9TfSERuB24HGDhwYMeU1BjTZVSHWWfUjYmN7Lwg1qWSQwdz9gAwbOt7FEe6X3J8VAT7y/2UtaHfoaxpWfxr7r/Y+tInsOspV2vj7393w5Yb016iolxzsksucfOVla5W0datrmPz7dth5UpX4yg/303vv3/iceLiXE2la66BWbMgPb1zz8MYY4wJA1ZzKPyJiA+4BjinsW1UtcD7uU9E/gZMAE5IDnk1ih4H16ysQwpsjOkyAmNW2QOEWl0mOaSqFOeXAnBaWR6xx0qBJOK93/bRVg5nD5BxXgZR8VHs31XOERJJ/NH9btQqYzpSdLRrRnb22XWXV1ZCQYHrFH3nTjdqWmDassU1UXvvPTf913/B5MmuaeLkyTBpkvVjZIwxpsurUcV7KBxWo9CYE1wKbFTV/IZWikg8EKGqJd7ry4EHO7OAxpiuKdyGsQ8HXSY5dHT3UaorlR6UEUs5ifv2AAPoGdX25FBkdCSDs3xs/rSK3NSJnHPHHe1UamNaITra1VprrOZacTG88w7Mn+9quK1c6SZwo6SNGuWas51zjpvOPBNiYzuv/MYYY0wH8weeCAthNQpNdyUi84EpQG8RyQfuV9UngdnUa1ImIgOAJ1R1OtAP+Jv3O/QBz6vq0s4suzGmawo0K/NZcui4LpMcKt7qhrFPxf3suW+3+9kOySFUGbZ/JZs5h03pl3JOR3ZAbUxbpabCtde66cgRePttV4voX/+CNWtcZ+rr1sFTT7ntIyNdwuicc9zP4cPhwgshISG052GMMca0kt30hxdVvb6R5Tc3sKwQmO693gac2aGFM8Z0S6dCh9Sdrcu0sAuMVBZIDsXvLQAgwUsOlbQlOfTeewwvfBtQtm6ooPxweZvKakynSUyEL30JHn7YJYcOH3Y/f/1ruOkmlwxShc8+g6efhv/8T7jySujVC666CpYsAb8/1GdhzClj6dKlZGdnk5WVxdzAqINBKioqmDVrFllZWUycOJEdO3YcX/fQQw+RlZVFdnY2r7/++kmPOW/ePLKyshARDhxo9gjPxnQL1t+QCVcWJ4wJD4EuiaO6TEak7brMRxGoOZSCSxLF7y0E2qnm0O9/TzylDMpQaqpqyP1HYyNtGhPmYmPhvPPgP/4Dnn3W1SA6csQljH7zG/jWt9x6vx8WL4bp0yErC+69F956y/VrZMkiYxrk9/u54447WLJkCTk5OcyfP5+cnJw62zz55JOkpKSwZcsWvvvd73LPPfcAkJOTw4IFC1i/fj1Lly7lm9/8Jn6/v8ljTp48mTfffJNBgwZ1+rkaE+783m1fJw7yYsxJWZwwJnxUqdUwra/LhMyDOXsBSPFqDsXucc3KEqLbmBzatw9efBFEGH7zRAA2vLShjaU1JozEx7uE0J13wqOPukTR7t0wd67r12jHDnjoIbj0Uhg6FPr2heuug/vvh5dfdqOmGWNYtWoVWVlZDBkyhOjoaGbPns2iRYvqbLNo0SLmzJkDwHXXXcdbb72FqrJo0SJmz55NTEwMgwcPJisri1WrVjV5zLPPPpvMzMzOPk1jTgnWrMyEI4sTxoSPU2Uo+87UZZJDYy9L5RLeJAP3RTV2j2tW1jNotLIabcWolr/6FVRUwJVXMuK2yQDkvpZrTctM19a3L9xzjxv9bNky+M533Ehn/fu7Dq9fegkefND1a5SRAWlpcPXV8JOfuBpHW7dCTRtq6xlzCiooKCAjI+P4fHp6OgUFBY1u4/P5SEpKoqioqNF9m3NMY8yJqoM6pDYmXFicMCZ82EOEE3WZDqkHpxxiMCs51q8/7IWYQtesLDJCiPMJZdVKWbXSM6oFv/xDh+Cxx9zre+8laWASgy4axM53d5KzMIext47tgDMxJoxERLgaQ5de6uZVXcLovfdg40ZYuxZWrYLCQnjlFTcF9OgBI0bAyJFwxhmuk+tRo6Bnz9Cci+k+OqqPkdY8YDDGhITd9JsmWZwwptsLNCyyhwi1ukxyiK1bATgwYTIZry4kak/h8VU9oyIoq/ZTUuU/3gdRs/z2t64/lqlT4dxzATjzpjPZ+e5OPvvTZ5YcMt2PCJx+upsCampcwujDD+Gjj2D9ejcVFrr5jz6qe4ykJDjrLBg7tnbKznajphlzCktLSyMvL+/4fH5+PmlpaQ1uk56eTnV1NYcPH6ZXr15N7nuyYxpjThTokDrSOqQ2YcTihDHhw5qVnajrJIe2bAFg39iJpP3jZXz79kJlJURHkxAVwb5jfkoqa+gf18zjVVfD737nXn/ve8cXj7xuJK/d+Ro7V+zk4PaDpAxOaecTMeYUExEBw4a56cYba5cfPAg5OS5RtGYNrFgBO3e6EdPefddNAXFxrlZR//6uSVtD0+mnuw61jTmZED25HT9+PLm5uWzfvp20tDQWLFjA888/X2ebGTNm8OyzzzJp0iQWLlzI1KlTERFmzJjBDTfcwF133UVhYSG5ublMmDABVT3pMY0xJwqMQuPrMh0omHZlccKYbs86pD5R10kOjR0L+/axb8QZHO3dj8R9u12nuoMGtW7Estdecx3tDhtW26QGiEmMYfhVw1m3YB2bFm/i3G+f295nYkzXkJICkye76fbb3TJV2LMHPv7Y1Shau9ZNeXmwenXTx4uJgbPPhvR06NfP9XM0Zoyb79XLzUfYtwATOj6fj3nz5jFt2jT8fj+33HILo0aN4r777mPcuHHMmDGDW2+9lRtvvJGsrCxSU1NZsGABAKNGjWLmzJmMHDkSn8/HY489RqRXm66hYwI8+uijPPzww+zZs4czzjiD6dOn88QTT4Ts/I0JJzaUvQlHFieMCR9Wc+hEomHWNnbcuHG6Zs2aVu//1MaDTPvyZaStWwsrV8LkyazcXcbKPWWc168HFw6Ib96Bpk+HJUvgkUfgrrvqrPr46Y9ZfMtisq/KZvYrs1tdVmOM58AB2LTJjQ4YmPburX1dWAi5uU0fIyYG+vSB3r3dqGrjx8Mll8Do0V2qxpGIrFXVcaEuRyg1FCc2bNjAiBEjQlSi8GafjemO1heX8+rOo4xMiWFGZkKoi9OpLE5YnGgp+2xMd/TqjhLWH6zgykE9GZ3adb4rnExTMaLr1BzyVPqVo31PczPeENuBmkMlza05tHkzLF3qvmx6Q0kGG3zxYAB2vruTGn8NEZFWW8GYNund201NKSqCzz93SaM9e2DHDvjsM9i/vzaZlJ/vpk8+cSOqgatNdOaZcPHFbgo0X+tCCSNjjDF12WhlxhhjmlJVYzVM62tWckhErgB+DUQCT6jq3Aa2mQk8ACjwqare4C33A597m+1S1RntUO5GVdUopal93Mz+/QAktLRZ2Y9/7Jq/3Hija65ST3JmMsmZyRzacYi9n+6l/9j+7VJ2Y0wTevWCKVMaX19a6hJIe/a4WkjLl8O//uX6I/v4Yzf94hdu24gIN4ra+PGuqdrAgZCR4Zqo9e5tzdOMMeYUW3bZZwAAIABJREFUZ6OVGWOMaYo1KzvRSZNDIhIJPAZcBuQDq0VksarmBG1zOvA/wGRVPSgifYMOcUxVz2rncjeqqgaOJXmdRBcVAS2sOZSbC3/5C/h8cO+9jW6WeXEmnzz9Cdvf2W7JIWPCQXy8mwYOhAkTajvHLiuD99+Hd96p7RS7oADWrXPT00/XPU50tEsSZWbCoEFw2mmQmuqSU6mpdV/36gVRUZ1+quFGRJ4CrgT2qepob9kDwP8D9nub3auqrzWw70kfPhhjTEsFbvoj7Z7fGGNMA2o7pA5xQcJIc2oOTQC2qOo2ABFZAFwF5ARt8/+Ax1T1IICq7mvvgjaHqlJZo5QnpboFXnIozqtTXF7djP6V5s51Q3N/7WsweHCjm2VOccmhHe/s4Ly7z2tz2Y0xHSQuzvU9dMkltcuOHXNNz1avdqOpFRS4TrHz86G4GLZtc9PJRES4JNKwYTB8uKuJNGYMDBniElXdxzPAPOBP9Zb/UlV/3thOzXn4YIwxreEPNCuzJ8LGGGMaEBjV0moO1WpOcigNyAuazwcm1ttmGICI/Av39PcBVV3qrYsVkTVANTBXVV9pW5EbF8j9VCTXrTkU7T02qqw5SXJozx5Xa0ikzvD1DRk8tbbfIX+ln8joyNYX3BjTuXr0gEmT3FRfWRns2uX6NNq50zVPLS52U1FR3ddFRbWJpKVL6x6nf3/XMXZW1ok/U1I65TQ7i6quEJHMVuzanIcPxhjTYtaszBhjTFMsTpyovTqk9gGnA1OAdGCFiIxR1UPAIFUtEJEhwNsi8rmqbg3eWURuB24HGDhwYKsLUek9JqpKrVtzKDqiNjmkqkhjnU7NmweVlXD11e4LXBMS0xPpM7IP+3P2k/d+HpkXZba63MaYMBIX52oBDR9+8m0rKmD7dteJ/WefwapVrr+j7dth9243rVx54n4TJ8IHH7R/2cPPnSJyE7AGuDtQuzRIcx4+GGNMi1mH1MYYY5piHVKfqDkt7AqAjKD5dG9ZsHxgsapWqep2YDMuWYSqFvx/9u47PK7qTPz490xXsaq7xkX2GIElNyw3iqmJjZaIJDSbhJiYFgNJIPkFkmUDibPZsCmbXWJCFjABErCJScCQNSaGkJgEXMHggo3khiU3WVZv087vjzMjq8yoN4/ez/PomZk75957JIPu6L3v+57Q4wHgb8CMlifQWj+htc7VWucOGzas099EWPgf2J/aPDiklGoWIIqoshIef9w8//a3O3S+iQsmArD/jf3tjBRCxCSn0wSR8vPh3/4NXn3VBIfq6kyA6M034Te/ge98B774RZg61ZSbdeP33FnkcWAiMB04BvyiOwdTSt2hlNqmlNpWUlLS/g79YOnSpQwfPpycnJxO77t9+3amTJmCx+PhG9/4BjpUB/+DH/yAjIwMpk+fzvTp01m3rlXbJiFEBI09h+SOsBhA5DohxMBxpqysf+cxkHTkR7EVmKSUylRKOYBFwKstxryCyRpCKTUUU2Z2QCmVqpRyNtl+Ib1YLhAODgVSQyuMhYJD0CR7KBAlOPSDH5hSkQsvhAs61kMoHBwqXF/YtQkLIWKT1Wp6EV1xBdx5J/z0p/DHP8KHH0JVFaxe3d8z7HVa6xNa64DWOgg8iSkha6kjNx/Cx+uRmwi96ZZbbmF9y/LCDlq2bBlPPvkkBQUFFBQUNDvOfffdx44dO9ixYwd5eXk9NV0hYlpAyx1hMfDIdUKIgeNMQ2q5ToS1GxzSWvuBe4A3gI+BP2itdyulliulwsvSvwGUKqX2AG8D39FalwLnAduUUh+Gtj/Sm41G/TqcORQhONRW36GdO+HRR01z2UcfNT2HOmDc/HHYXDaOf3Cc6hPV3Zu8EGJwUGpQNKtWSjVdxvELwK4Iwzpy8+GsMX/+fNLCZc0h+/fvZ+HChcycOZOLL76YvXv3ttrv2LFjVFZWMnfuXJRSfOUrX+GVV3qtPZ8Qg0L4jrCsQiMGErlOCDFwBBpXtZTgUFiHLpla63Va63O01hO11j8ObXtIa/1q6LnWWn9Laz1Zaz1Fa706tP3d0OtpoceVvfetmGXsAYIpySbQU1kJPh9wJjjUEClz6Ic/hEAAli2D88/v8PnscXbGXTIOgE9e+6R7kxdCiLOUUmoV8B6QpZQqUkrdCvxUKbVTKfURcBlwX2jsaKXUOoh+86Ffvolecscdd/CrX/2K7du38/Of/5y77rqr1Zji4mLcbnfja7fbTXHxmQSqFStWMHXqVJYuXUpZWcu2TUKISPySOSTOEnKdEKJ/hEIHWOUy0ainGlIPCOH6crvNalYDCq8sNGJE9J5DZWXw2mvmbv73vtfpc+YsymH/G/t5/8n3Of+2jgeWhBAiVmitF0fYHPFmgNb6KJDX5PU6oEcbJPxQ/bAnD9foYf1wp8ZXV1fz7rvvcv311zdua2ho6NQxli1bxve//32UUnz/+9/n29/+Nk8//XSnjiHEYHSm51A/T0QMSHKdEEKEwwJSVXZGTAWHfE2Xo0tPP7PU9IgROKNlDv3xj2aFsssvh4yMTp8z+4Zs1t+7nuItxRzfcZyR00d2+/sQQghx9gsGg6SkpLBjx45m2wOBADNnzgQgPz+fZcuWUVRU1Ph+UVERGaHr0YgRIxq333777Vx99dV9MHMhzn6NZWWSOSQGMLlOCNE/wg3dgegrmQ9CMRUcaswcCgeHoPVy9i2DQ88/bx6/9KUundMeb2faV6ax5Vdb2Pa/27j6cfmFLIQQ/amzd257S1JSEpmZmaxZs4brr78erTUfffQR06ZNa/WHQFJSEps2bWLOnDk899xzfP3rXwdMn4lRo0z7ppdffrlLK9wIMRgFpNGoaINcJ4QY3CRrKLKYSrZt1nwwHBw6fRqI0pD60CH4+9/NctTXXtvl886800T2dz6/E2+1t8vHEUIIcfZavHgx8+bNY9++fbjdblauXMnzzz/PypUrmTZtGtnZ2axduzbivr/+9a+57bbb8Hg8TJw4kauuugqA+++/nylTpjB16lTefvttfvnLX/bltyTEWetM5lD/zkOIpuQ6IcTAEO43FFPBkB4QM5lDgaLXcB7aSBKfwTb0glaZQ85ImUOPPQZaw3XXQXJyl889PHs4Yy4cw5F/HmHnqp3MvH1ml48lhBDi7LRq1aqI2zuybHFubi67drVe0O13v/tdt+clxGAUbkhtldvCA4JS6mngauCk1jontO0HwO1ASWjYv4b60LXcdyHwP4AVeEpr/UifTLoXyHVCiIEhGLpGWKSkrJmYCZa9887dnPvpz7GU/CFyWVnLzKGaGnjqKfP8m9/s9vlzv5YLwPb/3d7tYwkhhBBCiK4Lf9yTVWgGjGeAhRG2/1JrPT30FSkwZAUeA64CJgOLlVKTe3WmQoiYJ2VlkcVMcMhuTwLA5z3ZvKysRc+hxobUv/89lJfDvHkwa1a3zz/5usnEpcVxbPsxjm4/2u3jCSGEEEKIrpG7wgOL1nojcLoLu84GCrXWB7TWXmA1cE2PTk4IMehIcCiymAkOuZypAAR9pzqWOfTyy+Zx2bIeOb/NZWPqzVMB03tICCGEEEL0j3A/CfncP+Ddo5T6SCn1tFIqNcL7GcCRJq+LQtuEEKLLgoRuIMhVopmYCQ4luNIACPpOn1nKHloHhwIagkHYvNm8f9llPTaHnEVmdYA9a/agg7qd0UIIIXpS02VJhSE/EzFYabkrfDZ4HJgITAeOAb/ozsGUUncopbYppbaVlJREHCO/E1uTn4kYjCRzKLKYCQ4lxg0zT/zlETOHGhtSBzV88okpKcvIALe7x+aQMSeD5LHJVBZVcuS9I+3vIIQQoke4XC5KS0vlQ24TWmtKS0txuVz9PRUh+pyUlQ18WusTWuuA1joIPIkpIWupGBjT5LU7tC3S8Z7QWudqrXOHDRvW6n25TrQm1wkxWIV/DcglormYWa0sKWGEeeKvNMuWhoNDoTsH4cyhhoCG994z782d26NzUEox+YbJvPfz99j94m7GXji2R48vhBAiMrfbTVFREdHuFg9WLpcLdw/eBBHibCHLFA98SqlRWutjoZdfAFovxQVbgUlKqUxMUGgRcFNXzifXicjkOiEGI8kciixmgkPhzCGrriMQrIfMTIiLg48/hn37cIydCIQyhzZtMjv1cHAIIPuGbN77+XvsWr2Lz/zsM9icMfMjFkKIActut5OZmdnf0xBCDBBBuSs8oCilVgGXAkOVUkXAw8ClSqnpgAYOAXeGxo7GLFmfp7X2K6XuAd7ALGX/tNZ6d1fmINcJIUSYZJdGFjORC4stHoA4BSU1RTA0B770JbNc/a9/jeNn/wWEeg6Fg0Pz5vX4PEbnjmbE1BGc+OgEe17aw9QvTe3xcwjRIwINcHob1B2FgBecQ8E1DOzJEKiHqgIo/xAqdoPFCdY4qNpnnieMhfgx4K+BQB2kz4H4cH9IZb6sLoh3Q/V+qD8Bw+ZDzWEoecdsszjN+VCABh00OZ6+ctABSJ8N8WPB6jTHsrjOPHcOBWWBoB9Kt5rvo/44ONIhYRwEveZ7qD8Gpz8wx3eNhLSZkHSOGROXIX81CCFEjJKeQwOL1npxhM0ro4w9CuQ1eb0OaLXMvRBCdJVkl0YWM8EhrHGACQ6dqC4CcuDuu01w6Le/xfmD5WZceQXs2gU2G5x/fo9PQynFrHtm8ec7/szWx7ZKcEgMHN5yOPBbKHwCGk6BrwqCDT108BU9dJwOsiebAE/1fhOg6grXcEibbYJQ6bPAmQ7eMqjYA0EfOJJhyCRwDgNHigSThBDiLBK+K6xkJRohhBAtSFlZZDEUHDKN1FwKDld9arZNnw4XXQT/+AfOqxaQ9P3HOedv68xqZRdfbMrOesGUm6aw4TsbKHqviKPbjzJ65uheOY+Icd5y+PjnUFtkXiuLyaSJz4CqQhPcSJ8NiZngGgUWqxkXDJiMmVOb4eg6KN9p/v8o3dI6GJScYzJpLE5oKIH6k+CrMOMTxkPKVDNGB8BfDUlZJlun9lOoPQK2BMACpZvMfAGTBaRN0Kb2U4gbbQIsJe+AawSMzoOk80x2j7c0tI8y3x8K7EkmOFO6GbynTQZQoN5kOgXrzXG9ZVD+kdk10QMjLjNZSvUnTCaUxQm2OLCnQOoM87z6EJzearKXqgrN93r0z+arI+xJYBsCFgekzYC0Webn40gBW6LJgoob1dV/bSGEED2o8a6wfPAXQgjRgpSVRRZDwaFQ5pAFjlc1WSns17+Gq69Gbd7MzV/NI2gN/QF97729NhVHgoMZS2ew6Zeb2PrYVq55+ppeO5eIAWUfwZGXTPDDkWqyU7zlcOh5E4DpCGUFR1qozKs22iAYeSWc83UYOtcEgOxJPfZttCsYMAGgnvglXFtsvoZMNBk/naU1VB8wJWmlW6BsO/hrwRYPSZNN0KvhFFR9YoJl9SdD2VaVZv+ag3DkT62PmzjBlLbpgPm3TMqClCnm52yNN9lICeNMSZ7F3r2fgRBCiKikrEwIIUQ0kjkUWewFhxQcbRocmjIFPvgAPv95hrzzDgBBzyQsn/tcr05n1l2z2PTLTexaZRpTx6fH9+r5xAAU9JvMnSN/Au03205tMj11rPEw7GKo2HUmAyaS9NnguRNQJuBQVWAyYxInmseyHSY7p/6EyfwJc6RB2vkw/FIYPt9kDCWda7Jr+ks4s6knxGc06XHUBUqZwNKQiTB+Ucf2qS8xP0dfJZRuM0Glqk9MRpW/2mQkVR8ADpzZ58RbkY+VMgXy2vh3F0II0WVaa8KLlcvnfiGEEC2Fs0vlGtFcDAWHzpSVFVe2yLZIS4PXXuPUnIsYum8Xdfd+iwRrD/6hGkGaJw3PQg+F6wv54OkPuPA7F/bq+cQA4y2HjdfAyY1RBpTC4RfMU0cajL3BNHn2lplt9iQTABp7PVg68L9poMHsa0s02S9K2qv1ONewM8+TJ8OErzR/PxiAip3m3wJlSubKd4YCSLUmo6vhNNQcMhlGQgghekXTwJCSkgEhhBAtSFlZZDEUHDqTOVRU+Wnr95OTWf/7P2PftIn5t3yBhD6Y0qx7ZlG4vpBtj29j3rfmYbHKH+wxJxgwTZHLd5qvyr0mk6fmENQdMz1ozvmGeWxc1cttVtY68XfzfHQeWB3dm4fVCXEje+RbEl1ksULq9ObbRl8VeWy43kEIIUSPk3IBIYQQbZHS48hiJjikLS4U4LLA6brSiGNUcjIHL7yCucGIb/c4z0IPKZkplB8sp/D1Qs65+py+ObHoGn8daJ8p37I4TQZOUzVHTONl1wg4/qYpGavYY4I+kSSdB5etNxlBLbmGmdIiMTjJXQohhOg1EhwSQgjRFrlORBYzwaGgxYUVkzlU0VBBUAextCitcYT+9RsCfXPX3mK1MOuuWWz4zga2PrZVgkMDTaDeNCSu3Af7V5rAT5iyQPpcE8CxxpuePkdeMitstRTvhuQpZmxytikZsiVASo40HRZCCCH6WDBUWGaRbhJCCCEikOtEZDETHPKFg0MWCOogVQ1VJLuSm41xhsq6vMG+K+mYsXQGb3//bQrXF1JaUEr6pC6srNQfwrl2bWU4lO+Eoldh/E3gHBpaPWpSzzYebk/dCSjZCEMvMJk+1YdMY2CrC3QQTvzVNIOOH2tW6qo9YppC15+AI380S6WHKZvZT1lMj5hT75qvMwNgxOXgqzLLv4+/GYbONqtSCSGEEGJA6MhHGCGEEIOXZA5FFjPBIb8l3HNIAZqy+rJWwaE4m/nXr/X3XXAoLi2OnEU57HhmBx8+9yGX/+jyPjt3K8EAlG42ZVDxbhPIadm4uPj/YPu9po+OIwVm/MysmFW5F9yfP5MJc+wv8M61ZpWmnQ8D2gRj7CmQ+RWY9qMzy6TXHYfjb5mVm2qLYcwXwZlmmjaPudY8L/sI9j9lgjPpc8x+8W5InRG9H8+pzbDx86Z/T1clZ0NyDoy4FDJvNhk/YAJAJ/9ugkn+GtPoefh804hYCCGEEAOWfOgXQgjRFrlORBY7wSGcgFmtDKCsrozxKeObjYm3mUBInb+Pmg6FTL15Kjue2cGuF3Zx2fLL+nblDK1NpszhF+DTl5oHUhxpMGqB+ao5BEfXNy+t8pbB5tvOvB5xGaTlwqdrzHgwDXjLdwLKNF2uOwafPAoHfmuCOr6q1qVYx/9y5vn73wJnusn2icQaD+MWmWXYvaVmtadwgGbHd83S4okeqD9mtiVkmh4/Qa/J/hlxKTjSzSpSxzaYXj+jrjJ9g4bONYGvSP8e9iGQcXX7P18hhBBCDCjhcgH5zC+EECISWa0ssg4Fh5RSC4H/AazAU1rrRyKMuQH4AWYF0Q+11jeFti8B/i007N+11s/2wLxb8WFHo3AojQUoqy9rNSY+lDlU08fBoXGXjCNxVCJlB8oo3lKMe467909atsNk93y6Bk5vO7M9cQLEj4GqAqg7CodXma8wazxM/RFkfR0OrYJtd5nmzMoCJ942X2BKqSbdBVOXmwCQsoI9EU5/AFu/BqVbwB86pi0Bhl1kyrqcQ+Hwi4AyAZwTb5nsI1siTPgq2OLxVRykKOFa6lWqaQ4NUBueH1Adeu55BWxDzFza+x87+SpIvv/Maw2UACV7u/DD7R8ulwu3243dLn2Mzlb1/iCbT9aR7rKSk+bq7+n0GKXU08DVwEmtdU5o28+AzwFeYD/wVa11eYR9DwFVQADwa61z+2reQojYdOaOsHzoF0II0Vr4OiFXiebaDQ4ppazAY8BngCJgq1LqVa31niZjJgHfAy7UWpcppYaHtqcBDwO5mD/Ht4f2bR256SafBp+Kw6FrcSmTOdRSOHOoL8vKwDSmzlmUw6ZfbmLnCzt7LzgUDMDxDbD3F2Y1rTBnOmTeYjJw0maaQIrWpnTs8ItQ9r7JuBl2gckiCpdWTfiKKQGzOqH+JGz/pik1m7DUlH6Fews5mpTvpc2Az26C2iKznz0pFFxq8r/ehFvOPK8sAIKQOBEs5j/HooMHGTJkCOPT01HBBmgoNSVrFpsJUvkqTTPpuAxTkjYIaK0pLS2lqKiIzMzM/p6O6KRAULOtpI53T9TRENAk2S2cl+rEGjt/uDwDrACea7JtA/A9rbVfKfWfmGvEA1H2v0xrfap3pyiEGCxkiWIhhBBtCaeKyHWiuY5kDs0GCrXWBwCUUquBa4A9TcbcDjwWDvporU+Gti8ANmitT4f23QAsBJqkqvQMfxACFicEaolT0TKH+qesDGDKTVPY9MtN7Fq1i8/+7LNYHT3UtLn2qCnTOv5XOPGmKesCk1Ez7kbTQNn9ebDFNd9PKRjigZwH2z6+PdE8xmfAxS91bE5KQcKYjo1NmtRqU319PePHjzfld1aXOXdTrhEdO3YMUUqRnp5OSUlJf09FdNKhKi8bjtRQ2mCy4MYl2pk/Oj6WAkNorTcqpca32NakfpRNwHV9OSchxOAld4SFEEK0RW4iRNaR4FAGcKTJ6yJgTosx5wAopf6JKfz5gdZ6fZR9W/yl3zN8QY1PuYjDrFgWKXMoIRQcqvH1fXBo1MxRDM8ZzsldJ9n32j4mX9vNxsaBetj9H7DnEQj6zmxPyATPbeD52lmdVdOnfZnOEvIzObtUegP8tbiGveWm51aq08KVGYlMTI7SYD22LQVejPKeBv6ilNLA/2qtn+i7aQkhYpFGekkIIYSITnoORWZpf0iH2IBJwKXAYuBJpVRKR3dWSt2hlNqmlNrW1cwIv9b4lenh4YqaOWT+8ev6uKwMzB/2M26bAcAHT33QvYOd3AivT4ddPzKBoVFXwfm/hLyPIL8Qsv/1rA4MDRTr168nKysLj8fDI4+0arPFxo0bOf/887HZbLz0UgezqkTMCwQ1m07U8uTHZewt92JTMH9UPLeemzooA0NKqQcxHciejzLkIq31+cBVwN1KqflRjtPt64QQYnCQVWiEEEK0Ra4TkXUkOFQMNK0Rcoe2NVUEvKq19mmtDwKfYIJFHdkXrfUTWutcrXXusGHDOjP/Rr6gxm8xwaG4KD2HnFaFBWgIavzBvg8QTbt5GlanlcI3Cik/3Kova8cU/AbevBQq95kVvK7cCJetg3PvhZQprZemF10SCAS4++67ef3119mzZw+rVq1iz549zcaMHTuWZ555hptuuqmfZikGmoOVXlbuLedvR2vxBSErxcHtk1O5YGQ8tkF49VFK3YJpVP0lrXXEX7pa6+LQ40ngZUwpc6Rx3b5OCCEGBykrE0II0ZbGnkP9OouBpyM/j63AJKVUplLKASwCXm0x5hVM1hBKqaGYMrMDwBvAZ5VSqUqpVOCzoW09zh+kMXMoWs8hpVSTptR9X1oWlxZnysk0bFmxpXM71xyBTUth6zJAw+TvwVU7YPjFvTLXwW7Lli14PB4mTJiAw+Fg0aJFrF27ttmY8ePHM3XqVCwW+bUy2FV6A7x8sJIX91dyuiFAmtPKjROT+EJmEsk91V/sLBNa5fJ+IF9rXRtlTIJSakj4OeYasavvZimEiEXhSPQgjMkLIYToACkri6zdnkOhlWbuwQR1rMDTWuvdSqnlwDat9aucCQLtwSxH/B2tdSmAUupHmAATwPJwc+qe1jRzyGWJHBwCiLMpqv1mxbKkfqjwmPfteex8YSfbf7Odi//1YuJS49rf6dQW+OsVZsl3ZYNZj5u+QoPAIx/0zgJG350xtM33i4uLGTPmTNKb2+1m8+bNvTIXcfbSWrOjtJ63i2vxBjV2C1wwIp5Zw+MGVaaQUmoV5gbBUKVUEWaVyu8BTmBDqF/WJq3115RSo4GntNZ5wAjg5dD7NuCFUL86IYToMvnQL4QQoi1SVhZZRxpSo7VeB6xrse2hJs818K3QV8t9nwae7t402+cPavzKCZjModMRysoAEuwWSuoD/ZI5BDDq/FFM+MwEDmw4wNZfb2X+gxHba5xRuQ/+/i8mMDT6X0xvoQgrfAkh+lZZQ4B1n1ZxpNoPwKRkB59xJ5A0CDOFtNaLI2xeGWXsUSAv9PwAMK0XpyaEGITkQ78QQoi2NJYfy3WimQ4Fh84GPq3xK5OFE60hNdCvZWVhF333Ig5sOMCWX23hwu9cGH1Z+5Mb4Z0vQkOpaTo9/2Ww2Pt2sv2svQyf3pKRkcGRI2cW2isqKiIjo1cW2hNnod2n63njSA3eoCbepvisO5GsFIesKCeEEANA+BOe/EYWQggRSTC8qqVcKZqJmWYp/iDtNqSGMyuW1fbDimVh4y8bz/Cc4dScqGHv2r2RBx14Dv565ZnA0EV/GHSBof40a9YsCgoKOHjwIF6vl9WrV5Ofn9/f0xL9zBvQ/N/hKl47XI03qDk3xcHt56VybqpTAkNCCDFASFmZEEKItmjJMI0ohoJDTcrKLFBeX06kxXEGQuaQUoqZX5sJwLbHtzV/Uwfhw3+DTUvMMvVZ34RLXgN7Yj/MdPCy2WysWLGCBQsWcN5553HDDTeQnZ3NQw89xKuvmn7sW7duxe12s2bNGu68806ys7P7edaiN52o9fPMvnJ2nm7ApmDhmESuGT+EOFvM/BoVQoiYIB/6hRBCtEXKjyOLnbKy4JmysmSbg4D2UuWtIsmZ1GzcQAgOAUz98lTevP9NDr19iFN7TzH03KEmMPTul+HwKlBWyP0VTFrWr/MczPLy8sjLy2u2bfny5Y3PZ82aRVFRUV9PS/QxrTXbS+p5+2gNAQ1DXVauGT+EYXEx8+tTCCFiiixlP/AopZ4GrgZOaq1zQtt+BnwO8AL7ga9qrcsj7HsIqMIseuPXWuf21byFELFJMkwji5lb3hYFQaspK0tzmCBRpNKyxrIyX/+VlQG4kl3k3JQDwPYntpuNxf9nAkO2IXDJnyUwJEQ/q/UFeelAJW8Wm8DQ9HQXS7JSJDAkhBADmCxlPyA9AyxssW0DkKO1ngp8glnlMprLtNbTJTAkhOgJ4TSRmAmG9JCY+XlcNXYIuSNTAUjGTjOWAAAgAElEQVSxmyBRpKbUAyVzCCD3a+b6tuOZHfjqfPDJo+aNKQ/D6JbXTyFEXzpY6WXl3jL2V/pwWhWfzxzCwrGJ2OWvDSGEGNDCd4SlF9zAobXeCJxuse0vWmt/6OUmwN3nExNCDEpSVhZZzASHALCGysrsDsD0HWopwW6+5Upf/weHRs8czejc0dSX1bPn2Q1w/E2wxsPEpf09NSEGLa01G4/V8OL+Smr8GneCjaXnpnBuirO/pyaEEKIDGj/09+80ROcsBV6P8p4G/qKU2q6UuqMP5ySEiFFSVhZZbF03w8EhqwkORSorS3FYcFkV1b4g5Q2BPp1eJOHG1Fse/btpoDhhCThS+3dSQgxSvqDmtcPVvHu8DgVcPCqemyYlk+yw9vfUhBBCdJCUlZ1dlFIPAn7g+ShDLtJanw9cBdytlJof5Th3KKW2KaW2lZSU9NJshRCxoLE3nVwnmomx4JApJ0u0mT/kImUOKaVwJ5ol4Y9U+/publFMWTyF+FQLRz+OZ//ubDj32/09JSEGpdJ6P8/tK2dPWQMOi+L6iUlcODJe7igIIcRZRu4Inz2UUrdgGlV/SUdaZhjQWheHHk8CLwOzo4x7Qmudq7XOHTZsWC/NWAgRCyTDNLLY+nmEMofiQh8G6vx1EYeNDQWHPh0AwSF7wx7mLXwLgL+/cTM6cUI/z0iIwcWsRlbHb/eWU1IfIM1p5cvnJDMhydHfUxNCCNEFslrZ2UEptRC4H8jXWtdGGZOglBoSfg58FtjVd7MUQsQiyTCNLCaDQ67QP3Kdb4AHh3yV8I/rmX3le8QlByh6v55DfzvUv3MSjdavX09WVhYej4dHHnmk1fsNDQ3ceOONeDwe5syZw6FDhwAoLS3lsssuIzExkXvuuaePZy06o8ob4MX9lWwoqsGvISfNyZKsZIbLamRCCHHWalyFRj70DxhKqVXAe0CWUqpIKXUrsAIYAmxQSu1QSv0mNHa0UmpdaNcRwD+UUh8CW4D/01qv74dvQQgRQyTDNLLY+gsoVFbmUuYfO1rm0PA4K06rosIbpMIb6L9+Iju+C1UFOEZOZdbXL2bjv7/LR899ROZlmf0zH9EoEAhw9913s2HDBtxuN7NmzSI/P5/Jkyc3jlm5ciWpqakUFhayevVqHnjgAV588UVcLhc/+tGP2LVrF7t2yc2tgaqo2sfLB03T6TirYsHYRGk6LYQQMUDLKjQDjtZ6cYTNK6OMPQrkhZ4fAKb14tSEEIOQ9ByKLCYzh5yhRLFaX8QMVSxK4U4wcbF+6ztUWwT7nwIUXPACU748A4CP//Qx/np/2/uKXrdlyxY8Hg8TJkzA4XCwaNEi1q5d22zM2rVrWbJkCQDXXXcdb731FlprEhISuOiii3C5XP0xddEBH56q54XCCmr8mnGJdm49L1UCQ0IIESPkjrAQQoi2SM+hyGIscygUHFJmFbJoZWVgSsv2V/r4tMpHTlo//BH/8c8h6IOxN0BKNkNTYNTMURzbfoyCdQWc98Xz+n5OA5D6Ye98sNMPR+x52Ki4uJgxY8Y0vna73WzevDnqGJvNRnJyMqWlpQwdOrTnJyx6REBr3iqq4f1T9QDkDnNxeUaC/AEhhBAxJFxWJr/ZhRBCRBJEbiJEElvBslBZmUOb4FC0zCGAsUP6se9Q/UkofMI8z/7Xxs05i3MA2PnCzr6fkxAxrtYf5MXCSt4/VY9VQd7YRK50J8pFQQghYoyUlQkhhGhLUK4TEcVk5pCNUOZQlJ5DACPibDgtinJvkEpvgKS+7Du0978hUAcZn4PUM2XUOYtyePP+N/nktU+oLa0lPj2+7+Y0QLWX4dNbMjIyOHLkSOProqIiMjIyIo5xu934/X4qKipIT0/v66mKDjhZ5+ePByqp8AZJsCm+OCGJjAR7f09LCCFEL5CyMiGEEG2R4FBkMZY5ZIJDDm2ygdoKDlmUwp1oYmObT9bxVlE1tf5g1PE9xlsOBY+Z59kPNnsrKSOJiQsmEvAG+Oj3H/X+XERUs2bNoqCggIMHD+L1elm9ejX5+fnNxuTn5/Pss88C8NJLL3H55Zej5IPogLOvvIHffVJOhTfIyHgbS7JSJDAkhBAxTJayF0II0ZbGmwhypWgmtjKH4t1gcZDgPUmqpe2yMoAxob5D20tM/5FT9QGuyEigqMZPdpoTe2+EEvc9apawH3EFDJ3T6u0Zt86g8PVCPnjqA+Z8Y44EG/qJzWZjxYoVLFiwgEAgwNKlS8nOzuahhx4iNzeX/Px8br31Vm6++WY8Hg9paWmsXr26cf/x48dTWVmJ1+vllVde4S9/+Uuzlc5E79Na84/jtfzzuAkSZ6c6WTg2sXf+vxZCCDFghHOO5de9EEKISOQ6EVlsBYdscTB0Hurk37kkDiraaEgNpil1mFXBwSofT+0tB+DD0nqunZBEor0Hk6tqi2DPf5rnOd+POCTrc1nED4vn5K6TFG8uxj3X3XPnF52Sl5dHXl5es23Lly9vfO5yuVizZk3EfQ8dOtSbUxPtCAQ1rx2uYm+5FwVcOjqe2cPjJNgqhBCDgCxRLIQQoi1SVhZZbJWVAYy4HIDL4tsuKwMYFW/jwpFx5I1N5IuZSYBJQY63KY7V+nnlYGXPzu2D+yFQC2OuhRGXRBxidViZ/tXpAGx+dHPEMUKI6LwBzUsHKtlb7sVpUVw/MYk5I+IlMCSEEINE4yo0Ui4ghBAiAulNF1kMBocuA+DyuPbLypRSXDwqganpLiYmO1iSlczt56Vy67mp2C1QVOOn0hvomXkd+RMcXmVWVDv/F20OnX33bJRVsfsPu6k4UtEz5xdiEKj3B3lxfwUHq3zE2xSLJyUzIcnR39MSQgjRh2S1MiGEEG2R3nSRxV5wKH02QYuLHCfE+6s6teuoeDtpLisJdgvjh5g/KPdXers/p8pP4L1bzPNpP4GEcW0OTx6bTPb12eiAZsuKLd0/vxCDQIU3wO8LKiiu8ZNkt/DlSSmMjI+tylkhhBDtk3IBIYQQbQkvQyXXieZiLzhkdeJNmwXAVNX1rBtPcig4VOHr/px2PAD+Khh7PWR9s0O7zL1vLgDvP/k+vroemIMQMex4rZ/f7avgVH2AdJeVL5+TTJrL2t/TEkII0Q/C5QLymV8IIUQkZ8rK+nkiA0zsBYeAYFouAFnWtsvK2jIxVIpyqMqLL3wLqisaTsPR/wNlgZn/0+HuiBmzMxg9azT1ZfXsfnF3188vRIw7UOnlhYIKqv1BxiTauHlSMkkOCQwJIcRgdeaOsHzqF0II0dqZ8mO5TjTVoeCQUmqhUmqfUqpQKfXdCO/fopQqUUrtCH3d1uS9QJPtr/bk5KOxps0A4Fxb10vCEu0WRsbZ8Gv4tKobmTufroGgD0ZcCXGjOrVr7jIT5Nr2+Laun1+IGPZhaT1r9lfiDWompzq5cWIyLltMxrwHNKXU00qpk0qpXU22pSmlNiilCkKPqVH2XRIaU6CUWtJ3sxZCxCrpOSSEEKItUn4cWbt/RSmlrMBjwFXAZGCxUmpyhKEvaq2nh76earK9rsn2/J6Zdtvs6TMBmGwPonXXs34mJpul7rvVd+jQ8+Yx88ud3jXnxhxcKS6KtxRz7P1jXZ+D6JL169eTlZWFx+PhkUceafV+Q0MDN954Ix6Phzlz5jRbvv4nP/kJHo+HrKws3njjjcbtS5cuZfjw4eTk5PTFtxCztNa8c6yG1z+tRgPzRsTxuXGJ2OQ3fH95BljYYtt3gbe01pOAt0Kvm1FKpQEPA3OA2cDD0YJIQgjRUfKhXwghRFsaM0z7dRYDT0d+HrOBQq31Aa21F1gNXNO70+oey5BzqAvCeDvU153o8nE8odKywkpv14JMlfug5B2wxoH7853e3R5vZ9ot0wDY+vjWzp9fdFkgEODuu+/m9ddfZ8+ePaxatYo9e/Y0G7Ny5UpSU1MpLCzkvvvu44EHHgBgz549rF69mt27d7N+/XruuusuAgGz6t0tt9zC+vXr+/z7iSUBrXn902r+ebwOBSwYk8AloxNkqfp+pLXeCJxusfka4NnQ82eBSL8EFwAbtNantdZlwAZaB5mEEKJTwkvZK+k6JIQQIgJZyj6yjgSHMoAjTV4Xhba1dK1S6iOl1EtKqTFNtruUUtuUUpuUUp2PkHSFxcZev+k54i3d3uXDjIy3kWBTVHqDnKrvwpL2O5ebx8ybwT6kS3PI/ZopLdv1wi7qK+q7dAzReVu2bMHj8TBhwgQcDgeLFi1i7dq1zcasXbuWJUtMFcx1113HW2+9hdaatWvXsmjRIpxOJ5mZmXg8HrZsMavOzZ8/n7S0tD7/fmJFfSDIHw9U8tHpBmwKvjhhCDOGxvX3tERkI7TW4ZTH48CICGM6en0RQogOk7IyIYQQbZEM08h6ap3n14BVWusGpdSdmLvEl4feG6e1LlZKTQD+qpTaqbXe33RnpdQdwB0AY8eO7ZEJfeJ3MMNRR7BsB4z5ly4dQynFhCQHO083sL/Sy7C4Tvy4ynfD4VVgcUD2g106P8DQrKFkXpHJwbcO8uFzHzLn63O6fKyz0gu99H/sTW1nghUXFzNmzJkYp9vtZvPmzVHH2Gw2kpOTKS0tpbi4mLlz5zbbt7i4uAcnPzidqPXzyqFKyhqCxNkU109IYnSCvb+nJTpAa62VUt3o7N871wkhRGwKf+iXz/xCCCEiCd9EkMSh5jqSOVQMNM0Ecoe2NdJal2qtG0IvnwJmNnmvOPR4APgbMKPlCbTWT2itc7XWucOGDevUNxBNYTAeAFXRvZW+JoaWtC+s6GTfoY9/BmiYeDskdO8PmaaNqbvTQ0mIs1FQa949Xsuzn5RT1hBkeJyVr5yTIoGhge+EUmoUQOjxZIQx7V5fwnrjOiGEiE3hT0pyR1gIIUQk4fJji9xGaKYjqTBbgUlKqUzMh/ZFwE1NByilRjUpH8gHPg5tTwVqQxlFQ4ELgZ/21OTbcogkoBR7N4NDmUPsWBQU1/ip8weJ68hKSP5aOPJH8/zc+7p1foCs/CwSRyVy6uNTHP77YcZfOr7bxzxrtJPh01syMjI4cuRMtUtRUREZGRkRx7jdbvx+PxUVFaSnp3doX9E+rTXFNX7eKq7hWK0fgBlDXVyekYBdPvGfDV4FlgCPhB7XRhjzBvAfTZpQfxb4Xt9MTwgRq6SXhBBCiLZIWVlk7QaHtNZ+pdQ9mA/xVuBprfVupdRyYJvW+lXgG0qpfMCPaUp6S2j384D/VUoFMVlKj2it97Q6SS84bEkBwFW9zywlb+laloHTamFMgp3D1T4OVHrJTnO1v1Pxn8FfDemzYcjELp23Kavdyvm3n8/G5RvZ9vi2wRUc6iezZs2ioKCAgwcPkpGRwerVq3nhhReajcnPz+fZZ59l3rx5vPTSS1x++eUopcjPz+emm27iW9/6FkePHqWgoIDZs2f303fSNd6Apj4QpLwhyKEqL06rYnSCnZHxtg4HZrTWeIOahoCm1q85XR/AoiDRbiHBbqEhoKnxBWkIanaV1lNc48dpUyTYLFgVlDcEqfabtQSG2C3kjU0kM9QkXgwsSqlVwKXAUKVUEWYFskeAPyilbgUOAzeExuYCX9Na36a1Pq2U+hHmJgTAcq11y8bWQgjRKUEpFxBCCNEGCQ5F1qEmOlrrdcC6FtseavL8e0S426u1fheY0s05donXlkSBFyY5GqD8I0ib2f5OUUxMdnC42sf+Sl/HgkOHV5nHcTe1Pa4TZt4+k3d+/A4f/+ljqo9XkzgysceOLVqz2WysWLGCBQsWEAgEWLp0KdnZ2Tz00EPk5uaSn5/Prbfeys0334zH4yEtLY3Vq1cDkJ2dzQ033MDkyZOx2Ww89thjWK2mQfrixYv529/+xqlTp3C73fzwhz/k1ltv7bfvs9YXpNJnAjBBrTle66ew0suhSl/jEo9NWRSkOa2kOK2kOiwMcVjxBTUHKr3U+IL4NfiD2nx1Iemrwaup9J45c6LdQk6qk7kj43BZZbHJgUprvTjKW1dEGLsNuK3J66eBp3tpakKIQUiWKBZCCBGN1rqx/FhiQ831VEPqASfeHs97VTDJAZS8163gkCfJwV+LazhQ6SWoddtpyvUlcHQdKAuMu6HL52wpyZ1E1uey2PvKXt5f+T7zH5zfY8cWkeXl5ZGXl9ds2/Llyxufu1wu1qxZE3HfBx98kAcfbN2IfNWqVT07yW4orPDy8sFKAhGCOAqTreOyKsYPseMLQnGNj5L6AKdCXx3hsCicVoXLqkh1WtFAjc9kBDktikS7BYsCd4KdnDQnAQ01/iD+oCbJYSXZYZGyACGEEJ2ipaxMCCFEFE1vICi5TjQTs8GhOHsc79XDV5KAU+9B1j1dPlaay0qq00JZQ5DiGj9jEtsoUdvzCAS9MPpfIG5Ul88ZSe6yXBMceuJ9LvruRVgkk0J0UXGNj1dCgaE0pxWbxQSE0pxWxg9xMCnZQby99X9f3oCmrCHQ+FXtD6I1jB9iZ6jLhs0CdovCZlHYVNd+4aY4rT3wHQohhBispFxACCFENHKNiC5mg0Px9njeqwu9OPVet483McnBtpJ6DlZ5oweHao7AJ4+Z51N/1O1ztjThygmkTkylbH8ZBesKyPpcVo+fQ8S+0no/a/ZX4tcwJc1J3tjEDgdxHFbFiHgbI+Jj9leHEEKIs1zjB//+nYZoQin1NHA1cFJrnRPalga8CIwHDgE3aK3LIuy7BPi30Mt/11o/2xdzFkLEJlm0ILqYvW7G2eLY5QWfckLNQag70a3jjRtiAkKHq3zRB334PQg2wNgbIW1Gt84XibKoM8va/3pbjx9fxL4aX5AXCyupD2gmJtm5qhOBISGEEOJsEF6iWC5vA8ozwMIW274LvKW1ngS8FXrdTCiA9DAwB5gNPNxkhUshhOg0LYsWRBXTwaEAcNw5xmw49nq3jjc20Y4CjtX4aQhEaNVbtBYOPQ/WOJj2426dqy3Tb5mOzWWjcH0hp/ad6rXziNgT0JpXDlVS6QsyOt7G5zOTJGIuhBAi5ujGkgG5xg0UWuuNmBWNm7oGCGcBPQt8PsKuC4ANWuvToayiDbQOMgkhRIdJWVl0MRscirfHA7AzLsds+OB+0yy6i5xWC6MTbASBI9X+5m/6qmDLneb5tJ/0yPL10cSnxzP1K1MB2Pzo5l47j4gd3oDm/ZI6fv9JBUeq/STaLHxxQlKHl6QXQgghziaNS9n37zRE+0ZorY+Fnh8HRkQYkwEcafK6KLRNCCG6RFa0jC5mfyZx9jgANjmyYfil0FAC2+/t1jHHJYZLy7zN3zi8CupPQNosyPp6t87REXO/OReAD5/5kLqyunZGi8Gg1hfkUKWXXafr2Xyilr8W1/DaoSpeLKzgsd2n+UtRDcdq/Titii9MGEJihGbTQgghRCxo/OAv0aGzhjZLzEVYP7XjlFJ3KKW2KaW2lZR0/YawECK2Sc+h6GL2L8Q4mwkO1fjrYO7TYLHDp6tN0+guCvcdOtSy71Dhk+Yx6xtmCfteNmzyMCZ8ZgK+Wh/vP/V+r59vsFq/fj1ZWVl4PB4eeeSRVu83NDRw44034vF4mDNnDocOHWp87yc/+Qkej4esrCzeeOONdo+5YsUKPB4PSilOnepYuaDWmk/KG3h6bxmP7jrN6v2V/PlwNW8frWXLyTp2lzVwsMpHQ0CTkWDjc+MSuSs7lYyENlbbE0IIIc5yspT9WeOEUmoUQOjxZIQxxcCYJq/doW2taK2f0Frnaq1zhw0b1uOTFULEBikriy5mg0PhsrI6fx0kZoL7C6CDsH9ll4/pTrDjtCpK6s0y3gCc/gBObwN7Coy5tiem3iFz7zXZQ1t+tYWgP0IPJNEtgUCAu+++m9dff509e/awatUq9uzZ02zMypUrSU1NpbCwkPvuu48HHngAgD179rB69Wp2797N+vXrueuuuwgEAm0e88ILL+TNN99k3LhxHZpfcY2P5wsq+NPBKk7WBbApcCfYOC/FQe4wF5eMiidvbCLXT0jitvNSuPmcFLLTXDitMfu/vBBCCAFIWdlZ5FVgSej5EmBthDFvAJ9VSqWGGlF/NrRNCCG6RIJD0cXsX4rhsrI6f6jsyhPqCXRgJQT9UfZqm9Wi8CQ5ANhX3mA27vtv85j5FQhlK/UFz0IP6eekU3mkko9f/rjPzjtYbNmyBY/Hw4QJE3A4HCxatIi1a5t/Zlm7di1LlpjPNNdddx1vvfUWWmvWrl3LokWLcDqdZGZm4vF42LJlS5vHnDFjBuPHj29zTlprAkHNKwcr+d0nFRTV+ImzKa50J3Dv1HS+fE4K12QmcaU7kXkj45ma7mJisoOhLll2XgghxOARrk2SD/4Dh1JqFfAekKWUKlJK3Qo8AnxGKVUAXBl6jVIqVyn1FIDW+jTwI2Br6Gt5aJsQQnRJeEVLi9xCaCV2g0OhQE2tr9ZsGHEpJHqgtsisLNZF56SEg0NeOLkRDj4HFkef9BpqSlkUc745B4D3fvFeYwp1zFGqd77aUVxczJgxZ7KY3W43xcXFUcfYbDaSk5MpLS2Num9HjhmNL6AprQ9Q7Q+yt9yLTcG8EXHcOTmV3GFx2OQTsBBCCAHIXeGBSGu9WGs9Smtt11q7tdYrtdalWusrtNaTtNZXhoM+WuttWuvbmuz7tNbaE/r6bf99F0KIWCDXiOhiNjjUWFbmC2UOKQucG2pI/dH3u5w9NCHJgU3BiZo6Apu/ZjZm/ysM8XR3yp02bck04tLiKN5czOG/H+7z84vep7Wm2hegtMGPT2sUMHOYizsmp3LJ6ARcUiYmhBBCNCPNRoUQQkTTWHosl4hWYvYvy3BZWWPmEMDE2yFxAlR+DAef7dJx7RbFxGQHORV/wFr1sclGmvzdnphypzkSHI3ZQ+/8xzv9Modep3XvfLUjIyODI0fONC8vKioiIyMj6hi/309FRQXp6elR9+3IMcO8gSAVDQFK6gNU+UzyY7zNwhC7lc+4E0lyWDvzUxRCCCEGjXAnRvncL4QQoiVZtCC6mA0ONWtIHWZ1wNQfm+cf/7zLx56aYmPeKdNrKDjlYbA6u3ys7pr99dk4Eh0c2HCA4q0dK1ES7Zs1axYFBQUcPHgQr9fL6tWryc/PbzYmPz+fZ581QcaXXnqJyy+/HKUU+fn5rF69moaGBg4ePEhBQQGzZ8/u0DEBKr0BShsC1AaCBLTGphRpTivJDqtEuIUQQoh2aCkZEEIIEUX4BkLMBkK6IWZ/JuGeQ41lZWFjrwWLEyr3greiS8eeUPYSqb5DnLZnsj/lC92darfEpcaRe1cuAP/4j3/061xiic1mY8WKFSxYsIDzzjuPG264gezsbB566CFeffVVAG699VZKS0vxeDz813/9V+PS9NnZ2dxwww1MnjyZhQsX8thjj2G1WqMeE+DRRx/F7XZTVFTEBTNn8P/uupMEm4V0p5WhLqusMiaEEEJ0kJSVCSGEiEZ6DkUXs8sYRSwrA7DYIWUqnN4KZTtgxCWdPrba/wQAm4Z+g5MnfGQkBomzKVQ/fQiZd988Nv/PZva+speTu08yPHt4v8wj1uTl5ZGXl9ds2/Llyxufu1wu1qxZE3HfBx98kAcffLBDx/QHNV++826uv20ZADalSHFasctvLCGEEKLTpKxMCCFENHIDIbqYTUdIsCcAUOOraf1m2vnmsez9zh+45giU/BNtjeNI6hc5Xufn8T2n+dmHpfx2bxn7K7zdmHXXJI5M5PzbzPf0z0f+2efnF13jD2oqvQFO1ftpCARRYLKFXBIYEkIIIbpK7goLIYSIRq4R0cVscCjRkQhAjTdCcCh1hnk83YXg0Kd/AECN/hdumpyBO8GGL2j+IztRF2DNgUo+Lmvo6rS77ILvXIDFZmHnqp2UHSjr8/OLjguvQHaq3k+N3zSbjrNaGOaykeSwShRbCCGE6AbpOSSEECKaxuBQ/05jQIrZn0k4OFTlrWrsSN6oO5lDh180j+NuZIjDypcmJbMsO5V7p6Qxd4QpZfvb0Rr8wfZXxOpJKeNSmPKlKeiA5p8/leyhgazSF2xcgSzOamGo00aK04pVPsUKIYQQ3RYuGVBSWCaEEKIF81eYLGUfScwGh5w2J3aLHX/QjzfQotQrZQooq2lK7a+NfIBIqg+YXkW2RBht+sYopUh2WHHZLMwfFc9Ql5UKb5APTtX34HfTMRd99yJQsOO3O6gsruzz84v21fmD1PpNCVmqw2p6C1nlN5MQQgjRU8K35+SeixBCiJbOlJXJRaKlmA0OwZnsoWpvdfM3rC5IzgYdhPKPOn7AcNZQRj7Y4lu9bVGKS0ab7e8cq+Vknb9L8+6qoecOZfK1kwl4A7z5wJt9em7RPl9QU+k1bTKH2E1AUQghhBA9S/pJCCGEiEZKj6OL6b9Om5aWtZI63TyW7+z4AZuUlEXjSXKQnerEG9S8tL+SzSdqKW8IdPwc3XTlf16JzWVj5/M7OfDWgT47r2ibL6g5XR8giMZltRBvk99GQgghRE/TWjdmDsmVVgghREvScyi6mP6ZDHEOASJkDgEkesxjdQcDKBV7ofxDsCfDqAVRhymlWDg2kVHxNip9Qd4+WsvqworG+vfeljohlfnfnw/A6/e8TtAfbGcPEcnSpUsZPnw4OTk5nd53+/btTJkyBY/Hwze+8Q0CwSDlDQF++uMfcr5nPJfNmcmMGTNYt25dL8xcCCGEGLyaBoaUlAwIIYRoIdxzSMrKWovp4FDUsjKAxEzzWH2wYwc7+Kx5HPMFsDrbHGq3KBZ7krlqbCJJdgvl3iAHKn0dnXa3XfD/LiB1Yiqn9p7ig99+0GfnjSW33HIL69ev79K+y5Yt48knn6SgoICCggJe/vM6/FpjQfGt++5lx44d7Nixg7y8vB6etRADi1IqSym1o8lXpVLq3hZjLlVKVTQZ81B/zVcIcfaTkjIhhBBtketEdB0KDimlFiql9mVJWZoAACAASURBVCmlCpVS343w/i1KqZImH+5va/LeEqVUQehrSU9Ovj1tB4cmmMeOZA6d3Agf/8w8n/DVDp3bYVVMS3cxc5gLgPdL6jq0X0+wOqxc8R9XAPC3h/+Gt8bbzh6ipfnz55OWltZs2/79+1m4cCEzZ87k4osvZu/eva32O3bsGJWVlcydOxelFIu//GXWrl2LAlxWJXcxxaCitd6ntZ6utZ4OzARqgZcjDH0nPE5rvbxvZymEiCXyoV8IIURb5DoRna29AUopK/AY8BmgCNiqlHpVa72nxdAXtdb3tNg3DXgYyMVk+m4P7VvWI7NvxxCHKSuraojQcyicOVTTTnDIWw7/uBF0AM67H4bP79Qcpqa72HislgNVPsoaAqQ6rZ3av6smXzeZ0bmjObrtKJv+exPzH+zcvAeKH6of9spxH9YPd3qfO+64g9/85jdMmjSJzZs3c9ddd/HXv/612Zji4mLcbjdgltJNGZHB8aNHSbRbsFoUK1as4LnnniM3N5df/OIXpKam9sj3I8RZ4Apgv9b6cH9PRAgRuxqXKJaOQ0IIISIIt3uRsrLWOpI5NBso1Fof0Fp7gdXANR08/gJgg9b6dCggtAFY2LWpdl6bmUOukWbVsoZS8LWx7PsnK6D+OAydB9N+3Ok5xNksnJtiytD2lDV0ev+uUhbFlT+9EoB//uc/qSmp6bNzx6Lq6mreffddrr/+eqZPn86dd97JsWPH2tyn0hskqDVKQYLNwrJly9i/fz87duxg1KhRfPvb3+6j2QsxICwCVkV5b55S6kOl1OtKqey+nJQQIrbIKjRCCCHaEu7IK5eJ1trNHAIygCNNXhcBcyKMu1YpNR/4BLhPa30kyr4ZXZxrp7UZHFLKlJZV7DF9h1KntR7jq4K9vzTPp/0YLB35cbV2bqqD3WUNFFR4uXBkfJeO0RWZl2XiWeihcH0hG/99I1f9z1V9du6e0pUMn94QDAZJSUlhx44dzbYHAgFmzpwJQH5+PsuWLaOoqIg6f5C6QJBjxUWMc2eglGLEiBGN+91+++1cffXVffo9CNFflFIOIB/4XoS33wfGaa2rlVJ5wCvApAjHuAO4A2Ds2LG9OFshxNlMygWEEEK0Ra4T0fVUQ+rXgPFa66mY7KBnO7OzUuoOpdQ2pdS2kpKSHppSk7KySEvZAyS005S68H/BexqGXQjDL+3yPMYPcWC3wPFaP5XevlvWHszS9ijY9uttnNp3qk/PHUuSkpLIzMxkzZo1gFkq98MPP8RqtTY2mF6+fDkjRo4kccgQ3v7Hu2iteXn183zh858HaJZp9PLLL3dpJTQhzlJXAe9rrU+0fENrXam1rg49XwfYlVJDI4x7Qmudq7XOHTZsWO/PWAhxVjpTViaEEEK0JmVl0XUkOFQMjGny2h3a1khrXaq1DtdMPYVpPNqhfUP798qH/jYzh6D9ptSH/2Aez/1/JtOoi+wWReYQBwCFFX3bHHrE1BHMuHUGQX+Qv3z7L3167rPZ4sWLmTdvHvv27cPtdrNy5Uqef/55Vq5cybRp08jOzmbt2rVorfEHNbW+IKfr/Zys8/Pvv/wV37rrTi6cch6TJk7kqqtMxtb999/PlClT/j979x0fVZU+fvxzpqX3BNIh9I4IohQLiFJUUHFV7F91Xcu6uOq662+Lu+ru6rq2XV2xrJViWwsIUgWV3gSBBAgkIZ30Msn0Ob8/JnPTIUiSSTnv12teM3Pnzr1nJmXuPPd5nsOYMWPYuHEjL774oo9fpaJ0mgW0UlImhIgVdZ3ahRAT8XwulXbi2BRF6UHqy8rUQb+iKIrSnMocal1b6qR2AYOFECl4Ajs3Ajc1XEEIESel9KZFzAXS6m6vAf4mhPB23b2clssKOsRZBYesJVC2G3QmiLvsrMcyOMzE0Uo7RyvtnBsTcNbbOxPTn57OoY8Okb4ynSMrjjD0qqGduv/uaNmyllujeKe3d7glFqebIotLO0vpNXHCBPb9eAC/JrOTffDBBx03YEXpooQQQXgmNPhFg2X3AkgpFwHXAfcJIZyABbhRSilb2paiKMrpeA/6VWxIURRFaYkKDrXutMEhKaVTCPFLPIEePfC2lPKQEOJJYLeUcjnwKyHEXMAJlAF31D23TAjxFJ4AE8CTUsqyDngdLfIGh1qcrQwazFjWQllZ4XpAQsyFYAg667EMCjOhE3Ci2oHZ4SbY2F4VfacX3DeYaU9OY82v17Dy3pX0u7Af/uH+nbb/nsItJVaXpNbpxuGu/+6qFwKjTuCn91z06ohUUTRSyhogqsmyRQ1uvwK80tnjUhSlZ9IO+n07DEVRFKWL8paVqe9szbXps1NKuUpKOURKOVBK+de6ZX+qCwwhpXxcSjlSSjlWSjlNSnm4wXPfllIOqru80zEvo2Uhfp6eQ2ZHa5lDAz3XZbvB1iRmVbjGcx03s13GEmDQMTDUhAQOlVnbZZtnYuKDE0mclEh1fjVrHl7T6fvvzqT0BIRKrC4q7S4cbokOQaBBR7SfgT4BBiL89AQadOqfjKIoiqL4kET1klAURVFa51InEVrVo9+T05aVhY2AqIlgLYJtt4Osm9jO7YKCuv48cZe323hGR3qmtD9YZqOzqyZ0eh3z3p6H3k/Pvnf2cWz1sU7df3clpaTa4abS7sIlJUYhCDPpiQnQE2bSY9Srg09FURRF6SpUuYCiKIpyKvUNqX08kC6odweHhA6mfgymCMj/CnI+g5psWH8hWPIhIB7Cx7TbeAaGmgjQC4qtLgprne223baKHhbNtCenAbDi5yuwVnZ+BlNb+brliFtKqu0uSqwuapxuBBBm0hPl78kQ8sUZSV+/J4qiKIrS1Wk9h3w7DKWNhBBDhRD7GlyqhBAPNVnnEiFEZYN1/uSr8SqK0v15M4dUxUdzPTo4pE1l31rPIYCgfjDy/3lu534Je34FJdsgIAEmL23XjoZ6nWB0lKfXzzf5NT75sj/p4UkkTEygKreK1b9a3en7bwt/f39KS0t9FgyxuzwlZGanG6f0lJB5y8aEj/6JSCkpLS3F31/1ilIURVGU1niPHNQZ4e5BSnlESnmOlPIcPLMd1wKft7Dq9971pJRPdu4oFUXpSVSGaevaMltZt3XazCGv+Cvhh99A/kpwmj0ZRTN3QGBCu49pct8ADpZZyTE7OVRuY1Rk537Z1xl0XP3e1bx+7uvsf38/g68YzMjrR3bqGE4nMTGR3NxciouLO3W/UkrsbrC6POWFeiHw1wv0OkGndVE/BX9/fxITE309DEVRFEXpsurLBdRRfzd0KXBcSnnC1wNRFKXnUg2pW6eCQwChQyEopX7Wsr6XdkhgCMDfoOOS+CBWZZv5Lr+WERF+nX4AEz0smsufv5xV96/iq3u/ImlyEqGJoZ06hlMxGo2kpKR0yr5sLjebC2rJMTspsjm1SPLEPgFcHB+o/mkoiqIoSjeizgh3azcCy1p5bJIQYj+QDzwqpTzUecNSFKUnqesy3J4FQj1Gzy4rq5utrNp+irIy8PxmxM+pv9/vxg4clacxdbhJR5XDTVa1o0P31ZoJ905g8JzBWMutfHHHF0h37+pnI6XkRLWd945UsqvYSqHFiZSQFGzgmpQQpicEqcCQoiiKonQz2kG/T0ehnCkhhAmYC3zSwsN7gX5SyrHAv4EvWtnGPUKI3UKI3Z2dfa4oSvfh1noO+XYcXVGPDg4FGYMAT+bQafvXJFzhudYZIenaDh2XEIIxdb2H9pf6pim0EIK5b88lMCaQzA2Z7Hxlp0/G4QvlNhf/PVzBsmNVlNlcxPjrWTAolIVjIrl5cDhDw/18PURFURRFUX4CqcrKuqvZwF4p5cmmD0gpq6SU5rrbqwCjECK6hfXekFJOkFJOiImJ6fgRK4rSLbnU50SrenRwyKg34qf3wy3dWJ2nCcL0vRSSfwaj/wx+kR0+ttFRfgggvcJOiaXzZy4DCO4bzFVvXAXA+t+tp+xYV+is07GKLU4WH62gxOoixKhjSmwAtw0Np1+ICX99j/5zUBRFUZQeT81W1m0toJWSMiFErKibEUQIMRHP95fSThyboig9iCo/bl2P/zbsLS07bd8hvckzrb135rIOFmLUMzjMhBv47+EKNuSateZYnWnY1cMYfdNonBYnn9/2OU6bbwJVnaGgxsGS9EpqnJJ+wUbuHh7OhXFBGNV/BkVRFEXpEdRBf/cjhAgCLgM+a7DsXiHEvXV3rwMO1vUc+hdwo/TVlLaKonR7qiF163p8cMjblPq0fYd8YFZyMGPqMoh2FVv56oRvAkSz/jWL0MRQcrflsvK+lT6bQr6jWJ1uvs2vYUl6JVaXZFCoiZ8NDMVPZQopiqIoSo+iprLvfqSUNVLKKCllZYNli6SUi+puvyKlHCmlHCulvEBKudV3o1UUpbtzqZMIrerx347bPGOZDwQadMxJDuGGQaGYdILUchu7iiydP46oQG788kYMAQb2vbOP3a/t7vQxdJSMKjtvHa5g20kLTulpBn7NgBAM6r+BoiiKovQ43pNsQp0RVhRFUVqgMkxb1+ODQyGmNpaV+VC/EBPz+nvGubXQQo3DfZpntL+4c+OY9/Y8ANY8vIaTPzbrB9jtHKmw8fHxKswON/GBBm4bEsYV/UJUCqGiKIqi9FDeI6gef4CrKIqi/CSqrKx1Pf6zUysrs3W9srKGBoaZGBhqxOaWbMqv8ckYRt04inF3j8Nlc/Hx/I+pLan1yTjOlpSS9EobK7I8P/NJfQO4ZUgY8UFGH49MURRFUZSOJNUZYUVRFOUUVOZQ63pNcKgrZw55TU8IQi/gQJmN1HKbT8Yw++XZxJ4TS9mxMj68+kOc1u7VoLrY4uSdIxX8L6Map4QxUX5cFBeopipUFEVRlF7Apc4IK4qiKKdQP5W9jwfSBfX44JB3trIqW5WPR3J6Uf4GLk0IAuDr7GryaxydPgZjoJEFXy0gNDGUnC05fHHHF0j3mTeotjjdfFdQw3cFNeTXOJBSYndJii1OHKfYnpSSCpuLoxU2CmudSCmpdrjYVWRhRVY1G3LNHC634WxhG2nlNt47UkGRxUWwQccl8YHMTApWfQcURVEUpZfwNhrVq49+RVEUpQVa5hDqg6Ipg68H0NHC/cIBqLBW+HgkbTMu2p+8GieHym0sTa9kbv8QhoT7deoYQhNCuWnlTbw99W0OfXSI8JRwZvx9ximfc7TCxv5SK2aHG6NOUG5zUeP0/OVtLbQQYBDYXVI7aIsNMJAQbMDscBNs1BFs0JFabqPU5qJh3MdfL7C6GgeCdhVbMekE8UEGwk16/PUCnYCtJz3NvEdF+nF5YjAmdWSoKIqiKL2Kq+4gQq9OCSuK4iNSSnVyugtzq5MIrerxwaGIgAgAyq3lPh5J2wghmNMvGIMO9pfaWJ5VzW1D9fQJ6NwfVd8xfbn+0+tZMmcJW57ZQkRKBOPvGd9sPavLzfrcGg6WNS+DSwwy0CfAwPEqO5V2T4vIMJOOarubQouTQkvLJWuBBkGMv4EiqxOLU2LSCZKDjQwINWJxSdIr7BRanGRVO4DG2VUXxgUyJTbw7N8ApVepsddQbi3H4XJg0psw6U24pZtSSynFNcWU1JZQXOu5zq3K5UjpEUprS7G77ASbgkkMTcTf4M+OvB0U1RQhpSQpLIkQUwh6nR6BILsymzJLGcNjhnNxv4t5adZLvn7ZiqIoPY6aolhRFF/akbuDWUtm8crsV7h5zM2+Ho7SgvqyMvVB0VTPDw75e4JD3SVzCDx18rOSgpESfiyz8UVmNbcPDcNP37lVgAMvH8iVi65kxc9XsPL+lYQmhTJ49mDt8exqB19lV1Nld2MQnsBMUrARh1sigX7BRoQQnlIxuxs/nSDQqMPhlmRV2ym2uAg16SizuaiyuxkSZiIl1ISx7ojOJSVmh5tQo65R9H1KbCDVDhf5NU5qnW5qHJJym4uUUCOjIv079T1Sug+Hy0FmRSZHS49youIEpZZSDhUf4oeCH0gvSz+rbe8p2NNs2dHSoy2uu69wH5EBkWe1P0VRFKVl3oN+gzroVxTFB7bmbKXCWsF3J75TwaEuSjWkbl3PDw51s8whLyEElyUFU1DrpNjqYnlWNfMHhHZ6hPPcu8+lPLOczX/bzKfXf8rt392BbWAU6ZV29pZYAU+J2FX9g4nyb/nXSQhBhJ9eu2/UCQaH+TE47NT71gtBmEnf4mMhRj1Dw1t+TOl93NJNWnEaFqcFs93MrrxdlNSWkG/OZ3f+bopriqmwVuCSrhafb9QZiQmKwagz4nA7sLvsAEQHRmuXmMAYogOjiQ2OZWjUUGKDYzHqjZjtZrIqsqiyVXF+wvmkRKTglm5yKnOwOC043U6cbicJIQlEBkSSWpyKJ3yqKIqitDfVc0hRFF+qdXhme7a5fDO5kHJ6qqysdT0+OBTu7+k5VG7pXsEh8ARRrh0QyvtHKjhe5eCbvBpmJAZ3+jimPzWdiswKDi47yDszFyPevAZdcjgCmBQbwJTYQDUriNJpah217MnfQ3pZOlanlW2521h7fC1FNUWnfJ5A0C+sH0OihjAgYgCRAZEMjhzMuLhxjIgZgUlv+sljmpgwsdmykX1GtrjupKRJP3k/iqIoyqmpcgFFUXzJGxyyOq0+HonSGhfqc6I1PT445C0r626ZQ14RfnrmDwhlSXole4utnN83gBBj52TM2F2esq5Ao+Cqt+eSm11FxZZsxL1fMmH5TYwbGU1coLFTxqL0Tm7pptxSjt1lZ//J/Xya+ilLDyzF4rQ0WzchJIG+wX3RCz0T4ieQHJZMZEAk4+PGkxyWTKhfKH6Gzm3uriiKonQul6fFoTojrCiKT6jMoa5PlZW1rucHh7xlZd0wc8grMdjIkHATRyrs/FBi5aK4oA7dn90lWZtr1ppMC8BPL7A8OxPxwArk/kJy7lnOjO//r0PHofRO+dX5LD2wlI8OfcTBooMtnnk5J/YcRvcZjb/Bn+HRw5k5aCbDo4ermSEURVF6OW/mkJqtTFEUX6hx1AAqc6grc2sZpj4eSBfU84ND3bAhdUvGxwRwpMLOvhIrk/sGYqj7bS62OHFJz5TvuTUOAg06+oUYf3KZV16Ng6+zzZRYXeiAYJMOs92N1SWJjPAn6d1J7J23nMJ9hXw8/2Ou/9/1mIJ/ejmOonj9ePJHHt/wOKuPrcYt3drycP9wjDojAyMHcnG/i7lz3J0MiRriw5EqiqIoXZXqJaEoii9pmUNOlTnUVdV/TqgPiqZ6fnComzakbiopyECfAD1FFhc/llo5NyaAHLODpemVzVrbBhkEPxsYRmxg23+8B8usHCi1ccLsmRo+0k/PNSkhxAQYtPKyEvNxLnlvFva5du56+y6Orz3OE2OeIPjlYIYMGMLQ6KGM6TumHV+10tPlV+ez7MAy1meuZ+3xtbilG6POyLyh87ht7G1MT5lOqF+or4epnAUhRBZQDbgAp5RyQpPHBfAyMAeoBe6QUu7t7HEqitIzaJlD6qBfURQfUD2Huj6XKitrVZvmRhdCzBJCHBFCHBNC/O4U680XQkghxIS6+/2FEBYhxL66y6L2GnhbBRgCMOqMWJ3Wbv1HKoRgcmwgAN8X1lJtd7HyRDUSCDbo8NcLBoYaifLTU+OUfJFZhc1Vn31hd9k5XHIYKZvPkpRZZeerE2ZOmB3ogAv6BnDH0HBiAjzBJZNecLh4B9Pen0aBuYCAAQG8dddblEaW4p/pT/YvsrllyS2MXTSW+766D5vThsvtIq8qjxp7TWe8PUo3Um2r5tPUT7lq2VUkvZjEo+seZfWx1QA8OPFB8h/J57MbPuPqYVerwFDPMU1KeU7TwFCd2cDguss9wGudOjJFUXoUNVuZoii+pHoOdW3uBt+FVUPq5k6bWiKE0AOvApcBucAuIcRyKWVqk/VCgIXAjiabOC6lPKedxnvGhBBEBERQVFNEuaWcuJA4Xw3lrA0NM5EUbCDH7OT11HKcEmL89dwxNFyrrXe6Je8fraDI4uK1g7nUWPZxXp9wfrP2QX48+SPT+k9j9qDZlFvLqbRWkhyWjNs0FWEcyoQYf6bEBhJgqI8ZuqWbZzc/yx83/hGXdHFxv4v56qavKLOUkXpLKnuu20N8Tjy/+uxXvHXNWyzas4hFexahF3pc0oVO6BjdZzSzB83mqqFXcX7C+eh1erIrs9lbsJdKayUTEyYyPGY4NfYajHrjWc0apXQ9x8qO8dL2l/g09VPMdjM2lw2n2wmAQWfg6mFXM3/4fKb1n9at/z6Vn2we8L70RK63CyHChRBxUsoCXw9MUZTux+VWmUOKoviO6jnUtanS41NrS93RROCYlDIDQAjxIZ6D+dQm6z0FPAv8pl1H2A4i/OuCQ9buHRwSQnBpQjDvH6nAKSHUpOOq/iGNmi4adIJ5/UNYkl7Jm9t+ycGCFY22sTFrIxuzNjbb9iWD7uPB618iwKBDSskL217g3f3vYnPaSC9LB+DRSY/y10v/iklvItgUTPLEZM7fdD7vXPQOHIHHlzzO/+78H7vELlzSRXRgNOWWcvaf3M/+k/t5ZsszBBmD8Df4U2op1fatEzomJ01mW842wv3DmTd0HkW1RYT5hXFu3LncPvZ2ogKj2vw+VduqCTQGotd1zqxuSsuklLy7710e/PpB7YMS6n/e84fP55Yxt9AnqI8PR6l0AgmsFUJI4HUp5RtNHk8Achrcz61b1ig4JIS4B09mEcnJyR03WkVRujWtXKBNufGKoijtS/Uc6tpcqhn1KbUlONTSgfv5DVcQQpwLJEkpVwohmgaHUoQQPwBVwB+klN+fzYB/Cm/foe7elBogNtDAXcPDkRKi/PUtzs4U5W9gSlQuCwtWYNCZCPWPZ2ifSbxz5V/59NBSyixlRAREEGAM5ov03WzN+ohNx15j5gc/8ujkR/no0Ed8ePBDbXvRgdG8d/V7zBk8p9m+IgZE8POdP+ejaz4ib2ceN/73RlZ9u4rg5GD8DH7UOmrZmrOVr45+xYqjK8goz6DGUUOoXyiTkyYTYAhg+ZHlbM7ejEBQainl7X1va9tfcmAJT2x6gl+e90sWXrAQk96kZZ1IKTlZc5JaRy0T4iew8uhKXtz+It9nf8/YvmNZvmA5iaGJLb6PBdUFZFZkctJ8kuLaYgZHDubCfhdidVoJMgapWa9+IrvLzvqM9aQWp/JJ6ifszNsJwA0jb+C3U37L4KjB6ISOQGOgj0eqdKKpUso8IUQfYJ0Q4rCU8rsz3UhdUOkNgAkTJjSvj1UURaFhzyEfD0RRlF5J9Rzq2uqnsVcfEi0564bUQggd8AJwRwsPFwDJUspSIcR44AshxEgpZVWTbXToGWHvjGXdeTr7hqL8T/9j+/vmpwC4Z/y9jEv5MyVWFztLDSw45zckBRsxCPgyq5or/G/h/H4L+GDXnWzJ2cKWj7YAnl5Nb1z1BgMiBjAiZgTh/uGt7iskPoTbNtzG4lmLydmSw+JLF3PHd3fgl+RHoDGQGQNmMGPADF6c+SIV1gpsLhvRgdEYdJ7XkVacxu783cwYMIPMikx25O4gOSyZCmsFn6R+wprja3hmyzM8s+WZVscQ5hdGpa1Su/9D4Q+M+s8o4kPiSYlIoX9Yf/af3I/FaaHSWsnx8uPNtuEthesf3p8HJz7IXePuIsw/7LTvdW9UUlvCW3vfIrU4ldyqXPKq89AJHcU1xY2ywvoG9eUfl/2DW8fcqgJuvZSUMq/uukgI8TmebNSGwaE8IKnB/cS6ZYqiKGfMmzlkUJ85iqL4gOo51LW5VTPqU2pLcOh0B+4hwChgU92Xv1hguRBirpRyN2ADkFLuEUIcB4YAuxvuoKPPCPeUGcvaotJaySNrH+F/af/DT+/H7y/8LcF+oXxwtJK8GicfH68i3KQjOcTI4Qo7Jp3g8fNn8ofzj/D0d0+zKWsTU5Oncs/4exgRM6LN+zUFm7h51c18cNkH5O3M4/3p73P7ptsJTahvKOzt/9TU8JjhDI8ZDkBcSByTkyZrj9117l3szNvJk98+ybqMdQQYArSeRBJJdGA0dpedjPIMQv1C+cslf2He0HnctfwuNmZtpNJWSVpJWrN9hphCGB4znL5BfYkIiGBrzlaOlR3DoDOQVZHFI2sf4U8b/8TMQTMZ3We059J3NAMjBvbqcjWLw8Izm5/h+W3PNyoVa2hUn1FM6z+NETEjuHXMrQSZgjp5lEpXIYQIAnRSyuq625cDTzZZbTnwy7qS5fOBStVvSFGUn0qVDCiK4kveyXhU5lDX5G1IrUd9SLSkLcGhXcBgIUQKnqDQjcBN3gellJVAtPe+EGIT8KiUcrcQIgYok1K6hBAD8MxGk9GO42+TcD9P1ktPyRxqiZQSieSaj65hY9ZGTHoT/5r9L+JD4gG4eXAYe4otHK9yUGZzUVFqQwdcnRJSl4kUzj8v/+dZjcEv1I+bV9/M+5e+T+EPhbx70bvctuE2wvu3nnXUFhMTJvLVTV+1+riUksMlh4kNjtWCTxtu28Dx8uNYHBYOFh0kpyqHsX3HahlLI/uM1DKXvNuwOC346f1Ymb6Sl3e8zDeZ3/BZ2md8lvaZtl6IKYRLB1yKQWegwlrBlKQp9A/vT5+gPswaNAud6L5NDkprSwk0BhJgDGj2mNVpZcmPS3jqu6c4UXkCgDmD5zB/+HySQpNICE0APA2mB0cOVllCildf4PO63wcDsFRKuVoIcS+AlHIRsArPNPbH8Exl/38+GquiKD1AfbNR9TmkKErnUz2HfpqM8gweXvMwf7zoj4yPH99h+1HT2J/aaYNDUkqnEOKXwBpAD7wtpTwkhHgS2C2lXH6Kp18EPCmEcABu4F4pZVl7DPxM9KSeQy15fP3jvLrrVSYnTWZj1kb6BPXh2zu+ZVj0MG2dcD89lyYGc6FL8tWJao5X2bkiOYQBoe07M1hARAC3rb+NxTMXk787n7fOf4v5yE7HEAAAIABJREFUH84nZVpKu+6nISGElnnUcNmgyEEAjO47uk3b8PbBmTt0LnOHzuVo6VF25u3kwMkDHCjyXHKrcvni8Bfa89ZnrNduXz7wct6/+n36Bvdtj5fV4aSUbM/dzuIfF7MyfSUnKk+gEzqGRg1lxoAZBBmDyK3O5UTFCXbl79LOgIzpO4ZX57zK1OSpPn4FSldXN5HB2BaWL2pwWwIPdOa4FEXpuVxuz7W++56rURSlm3JLNxanBQCH24FbujvtxHFxTTFPf/c09593P0Ojh3bKPtvTsgPL+PLIlySEJHRocEiVlZ1am3oOSSlX4Tm723DZn1pZ95IGt/8H/O8sxtcutJ5DPaisTErJgaIDrEpfpfXiWXN8DQBvXfVWo8BQQya94NoBoTjdEkMH/VUERAZw6/pb+Xj+x2RuyOSDGR8w7elpTP3tVEQ3+kscEjWEIVFDGi3LrsxmfcZ6THoTgcZANmdvptRSyqr0Vaw9vpZzXj+HJdcuYXrKdB+N+tRsThsbMjewIWMDy48u51jZMe2xQGMgNqeNtJK0Fkvxzo07l0cmPcINI2/o1aV1iqIoStdV35C6+xxvKIrSMzQtJbM5bS1m5HeED378gH/t/Bcu6eKVOa80e3xj5kYqrBVcM/yaThnPmcqp8sx/VVhT2KH7cavPiFM664bU3UFP6zlkdVq55qNrWH1stbbsTxf9id0Fu5mUOImrhl512m10VGDIyz/Mn1vW3MKmJzbx/V+/55v/9w1ZG7O44rUriBwY2aH77kjJYcncOe5O7f61w68FIK8qj5s/u5lvT3zLjPdnsGD0Aq4ddi1RgVFMSZqCUW/01ZBxSzdrjq3hw0Mf8uXhLxs17o4LjuOm0TexYNQCzok9B6fbye783WzI3IBO6EgMTSQhJIGxsWPVlPOKoihKl+fSysp8Ow6l7YQQWUA14AKcUsoJTR4XwMt4SpBrgTuklHs7e5yKcjrefkNeNlfnBYcyyj2dWwrMzds2utwurvnoGsx2M4WPFhIdGN1sHV/LrcoFoNDcscEhVVZ2ar0jONSDZitzup1c+9G1rD62mjC/MEb2GcmtY27l3gn3+npozej0OqY/PZ3ESYl8cdsXZKzL4LVRr3H5C5cz4d4JPaovTUJoAhtu28DT3z3N3zb/jaUHlrL0wFIAogOjuWHkDdw8+mYuSLyg0euWUmJ1Wjvkg8PpdvLxoY/5++a/c7DooLZ8bN+xXDnkSi5NuZSL+l3UKAtIr9MzJXkKU5KntPt4FEVRFKWjqcyhbmualLKklcdm4+lbOhjPxAWv1V0rSpfi7Tfk1ZlNqb09QYtqipo9drjksHZyOL00vUsHh06aT3boftyoSQtOpVcEh7zTsPeEzKHntz7P18e+Jjowmo23b2RUn1G+HtJpDbliCA+kPcDaR9fy4wc/sur+VRz7+hhzXplDWHLPmSper9PzxCVPcPs5t/PithfJqcrhcMlh0krSeHXXq7y661WSQpMw6o0U1xQzss9IsiqyKDQXMi52HHEhcdicNuwuOyF+IcQHxxMfEk9SWBL9wvrRL7wfLreLo6VH2Zy9GYDY4Fhig2OJC4mjf3h/BkQM4PsT3/PG3jfYlLVJ+0ebEJLAvRPu5fqR1zcrlVMURVGUnkJlDvVI84D363rUbRdChAsh4tTMlkpX0zQ41JlNqU9UtB4c2p1fP1F4RnkGk5Imdfh4bE4bXx39issGXkaoX+hp1++szKH6nkPd90NiY+ZGlh1cxlVDrmpTxdCZ6BXBoZ7SkDqtOI0nNj0BwOJrFneLwJBXUJ8grnn/GoZcOYQVP1/B0RVHydyQyYT7JjDlsSkE9ek50533D+/Py7NfBjyZQfsK97H4x8V8dOgjrZ4WYHvudgAEgh8Kf+CHwh/Oet+DIweTXpau3R8YMZDfTf0dt465FT+D31lvX1EURVG6MpU51C1JYK0QQgKvSynfaPJ4ApDT4H5u3TIVHFK6lK6aObSnYI9221t+1tHe2/8ev/jqF/zhwj/w1PSnTrmuxWGh1FIKQI2jBrPdTLApuEPG1RNOIHx74lve3PsmUQFRKjj0U0QGeHrclNaW+ngkZ+ehNQ9hc9m485w7mTlopq+H85OMvH4kSVOSWPvwWg59fIhtz2/jwJIDLFixgPgJ8b4eXrsTQjAubhzj4sbx3OXP8UPBD/gZ/IgJjOFg0UH6BvdlYMRAtudup8ZRg5/eD5PeRKWtkvzqfPKq8sipyiGrIovsymyMeiMJIQlMSZpCsCmYQnMhBeYCCs2F7D+5n/SydEx6E7+Z/BuuG3Edo/uMVs2jFUVRlF7DO1uZTs1W1p1MlVLmCSH6AOuEEIellN+d6UaEEPcA9wAkJye39xgV5bRqHM17Dp0tl9uFW7pP2b+0wlpBla1Ku21z2siqyGJQ5CD0On3jzKGKzgkOHSo6BNDopHVrvFlDXifNJwmO7JjgkLchdXfOHDpU7HlvR8SMaPdt94rgkLeustRSipSyW/a62ZqzlbXH1xJiCuEfl/3D18M5K6EJoVz30XVMfmwya369huzvs3l76tsMuHQA438xnqFzu9/0i22hE7pGUzM2nPJ+Wsq0s96+1WllS/YWBkYOpH94/7PenqIoiqJ0N97MIUM3PNbrraSUeXXXRUKIz4GJQMPgUB6Q1OB+Yt2yptt5A3gDYMKECbLDBqworeiIzKGZi2eSUZ5B2gNprVYBeEvKvBbtXsRDax7i75f+nUcnP9qoOiGjPIP86nysTisDIgac9fha481kaqlBdlPNgkM1JxkYObBDxtUTprJPLU4FYGSfke2+7V5xXiXQGEiAIQCr09osotsdmO1m/vDNHwBYeP5CogKjfDyi9hE/Pp7b1t/GuLvH4bK5SF+VzofzPmTFL1ZQlVfl6+F1O/4Gfy4dcKkKDCmKoii9kpRSzUTTzQghgoQQId7bwOXAwSarLQduEx4XAJWq35DSFbV3zyEpJd+d+I7MikwOlxxudT1vIMZrxdEVAOzM20lqcSpWp5VAYyDgaUg99e2pnPv6uVTbqs9qfKeSVZEFQEH1mQeHOrLvkLubl5XZXXaOlh5FIBgWPazdt98rgkMAMUExAJTUtjYRQtdzpOQI96y4h77/7MvGrI2E+oXy8KSHfT2sdqU36Zn75lweznuYGf+Ygd6kZ+8be3kp+SU++dknnDzQsR3rFUVRFEXpGbypIoLuXTLQy/QFNgsh9gM7gZVSytVCiHuFEN6peFcBGcAx4E3gft8MVekt7C47r+167Yy/N7Z35pDZbsbhdgCQVpLW6npNM4d25O0APFlCe/I9/YZmDpyJXugpMBeQWZFJpa2SH0/+eFbjO5WzyhzqwBnLXN2krGxz9ma+yfym2fJjZcdwup2kRKRoAb/21GuCQ97Ssu4SHDpccphxr4/jzb1vUuuoZUrSFD6/4XOtuXZPExIfwpTfTOHunXcz4roRCJ0g9dNUFo1ZxCfXf0LRwebN1RRFURRFUbx6QqPR3kZKmSGlHFt3GSml/Gvd8kVSykV1t6WU8gEp5UAp5Wgp5e5Tb1VpT1kVWVqAobdYemAp96+6n99v+L227NG1jzJ32Vzc0t3q82rs7dtzyNukGTwTE7WmaeaQ2W4G4Hj5cQ4UHQBgfNx4+oX3a7Se9zGv7MpsjpQcOasxA1RaK7WJoMx282kzlLzBIe8M452ROdSVs0vtLjuzl8zmiqVXNPud8vZy6oh+Q9ALg0PFNcU+Hknb/Hb9b7E4LcweNJvDDxxm852bmZ4y3dfD6nCxY2P52Sc/Y2HWQs775XnoTXpSP0nltdGv8fF1H5P1bRZSqjJyRVEURVEac9Ud9eu78lG/onQzVy27ikn/ndTtZ30+E95MnC05W7Rli3YvYsXRFeRVNWt3pWnvzKGGSQ2pJamtrucNDvUN6ttoudlu5rsTnvZdI/uMbNZjqGHmkMPloN9L/Rj26rBmr6MtPjz4Ib9b/zs2Zm7USsq8Tpc9lFvtCQ6Nj/P0Zj1Z03GZQ+5uMKPlwaKDmO1mrE5rs/dS6zcU0/79hqAXBYdiArtPWdmmrE0sP7KcIGMQb897m6HRPbNB86mEJoQy599z+NXxX3HeA54gUdr/0njvkvd4ddirbP3nVmqKu1//KEVRFEVROobKHFKU9iWl5GjpURxuR7c5wd4eims9rzW1OJUqWxU19hqtb613VrCWtHfPoYYzbacVp+F0O/k87XMeWPkA6aX1s4B5g1nnJZzXbBveaexHxIxgQHjj4NCBogM43U6sTitrjq/RlrelT1BDxTXF3Pr5rTy75Vmmvz+d+1c1rvw83fZyKnMAmBA/AejYzCHv50R7fExUWiv586Y/t/r6cipzWg0mOt1Ovk7/GrvL3uyxvQV7tdtNg0PemcpUcOgsdaeysme3PAvAY1MeIzY41sej8a3QxFDmvDKHhZkLueiPFxESH0Lp0VLW/WYdLyS8wKc3fkrmN5lIt8omUhRFUZTezNUNzggrSndSYa3Qvrz+lGwSX/n+xPd8cuiTn/x87/dFiWRP/h4tWARQaatstO7iHxfz9+//jpSyeXCoHcvKjpYeZebimVz78bX8Z/d/+OfWfwKen9GRUk8p2MT4iS1ux6Q3MSBiAIOjBgNwUb+LAE/m0AVvXcDAfw3kpe0vtbjftlh6YClOt5M+QX0AzyzbDZ0ucyinqnFwqGMzhzzX7XES4bmtz/GXb//Ci9tfbLTcbDdz/SfX0++lfoxdNLbFgOJbe99iztI5/O37vzV7rGEZZ2ZFJu/ue5eXt78M1GcOqbKys6SVldV27ah3cU0x646vw6AzcP95qt+eV0h8CNOenMZDJx7ixi9vZMiVQ5AuyaGPDvH+pe/zytBX2PzsZswnzb4eqqIoiqIoPqAyhxSlfTX8kt6dgkML/reAGz694YwyUKSUbMnegsVhafR9cUfeDopq6nufVlorGz3ngVUP8P+++X/8UPjDWZWV2Zy2Zv1lGiY1ONyORg2Kj5cfB+Dx9Y9TZaviwuQLOSf2nBa3PSx6GAadgbvPvZtfX/Br3rv6PWICY6iyVbGnYA/51flsyNzQ4n7b4r397wHwwuUvEGIK0ZbrhCfU8E3mN5z/1vlaiVtDpbWllNSWEGQMYmzfsUBH9xxqv4bUG7M2AvV9uQa8PIB1x9fx4rYX+ST1EySSUkspy48s52DRwUZBn2252wD46uhXzbbrzfYCT8bYz1f8nIfWPMSrO18lrSQNg87QITOVQS8MDnX1zKFPUz/FJV1cNuAybcxKPZ1Bx9C5Q1mwYgELsxZy8Z8vJjQxlLJjZWz43QZeTHyRT372CcdWH8Ptar1hnKIoiqIoPYvKHFKU9tVw1qjuEhyqddSSV52HRJ5Rc+WPDn3E1Hem8uyWZxuV0DULDjXIHCqzlGlZIV8e/lIrPfPOInUmZWXT3ptGzHMx3L/yfi5850Lmfzy/xVK+28feDngySnbn72bRnkUYdUYWXbmIvsH1PYcafo/0ZpmE+4fzwswX6B/enzF9x2iP64W+0T7aWkK4O383v179a34o/IFw/3Dmj5jPrEGztMdH9xkNwJt732Rn3k4+2P9Bs20cLDoIeHoixYXEAZ7fu47qMdteDalr7DXsytsFQF51Hp+mfkpmRSZv7H1Dmy3Om6H1ys5XuOCtC5j030la5o/3de8t2Eu5pVzbrsPlaNQLasXRFTjdTgB++fUvcUs3Pz/35wSZgs7uBbSi1wSHukvPoWUHlwGwYNQCH4+k6wtLCuOSJy5hYdZCFny1gKFzhyLdktRPU1kyewkvJr3I2t+sVTOdKYqiKEov4D0npPpRK0r7aJg55A18+MI9K+5h8n8n43A5Trtuw2nRvdk1ram2VfO79b8jszyTdcfXAbCvcF+j74s783Y2CpY0LBFqOEvYl0e+1AJoEf6e2aXbmjlkd9nZlrsNi9PCa7tfY3P2Zj5L+4zdBZ6J+fwN/gAEm4L5+6V/Bzwzi31x+AsA7hl/DyNiRmhlXQAzBszQbo+Ibl6C5A3cRAdGs+aWNYyLHadlo7Tl+3J6aTpT357KSzs85Wg3jboJf4M/c4fO1daZlDip0XNaKi/zBklG9xlNsCmYIGMQFqeFcmt5s3XbQ/1JhLPbzrbcbTjcnt/H3Kpc7XdhW842dud7fm7PXPoMOqFjR94Oahw1ONwOHlj1AC63S5t9TiL59sS32nYPFR/C5rJpWVfekjuvYFMwT1z8xNkN/hR6TXCoO5SVZZRn8H329/gb/Ll62NW+Hk63odPrGHLFEG788kYeyn6IaU9NI3JQJOYCM9v+uY3XRr/G6+e+ztbnt1KaXqpmO1N8wmFxUHa8jNwduRTsPbNGf4qiKMrpaQf9KjqkKO2iYXmPLzOHlh1cxrbcbaSVtD6du1d2ZbZ2+1jZsVOu+86+d3h2y7M8tv4xLdsjpypHC44Em4LJr85vlMnRsKysYbPg/Sf3a82CIwMigbb3HGo45ocveFi77c1MmTd0HgALz19IXEgcscGxON1OrYm0NwjTMDh02YDLtNst9aeZO3QuAsETFz/BpQMuZe8v9nLL6FuA0weHpJTct/I+bC4bMwfO5M2r3uTvMzxBqzmD52iZSJOTJjd6Xn51frNtHSg6AMCoPqMAtImYvMGTptoSIDyV+syhU39OON1OVhxZwZt73mzWQwng26z6gE5+dT6ZFZmAJ4voZM1JIvwjuCDxAi7pfwkAAYYAogKi2JS1iX9s+QcWp0V7fsNyQW/p2cX9Lm60P+9Mbk9e8mSjDLH2ZuiwLXcx3aGs7MVtnmZW14+8nhC/kNOsrbQkNCGUi/5wERf+/kJyt+ey/739HProEIU/FFL4QyHrHl1HUJ8gkqcmk3xRMgMuHUDMyBiESkFXzoKUEmuFlcoTlVScqKAyu5KqnCoqsyupzK6kIrMCc2F9P6z+l/Tn9o23+3DEiqIoPY+355BBfaQrXVhBdQEL/reAx6c+zsxBM30yhhp7DS9tf4kFoxc0m968oa5QVmZ1WjHbPcdQx8qONSqHaknDQMvpMoe8ZWdrjq3R9nG45DAOt4NgUzDDo4ezK38XW3PrgwMNy8qaziS1r3AfUB8camvmkHc7F/W7iOdnPk+ZtYx3972rNYb+v3P+j79O/6v2s0oJT6HQXKhlqIzs45m5KtAYSIgphGp7NdNTpqMXelzS1WJwaFrKNKx/sGLSm7Rlbf2+/FnaZ2zI3EBUQBSLr13cqIQtMiCS1654jXJrebMeSC0Fh7yZQ97g0MiYkewt2Muh4kNMSZ7SaN1vMr9h9pLZ/POyf3Lfeffx3YnvmJQ4iQBjwCnH25C36cjpMoee2PgEf9vsaRZt0pvI/XUuMUEx2piXH12uret0O9lfuL/R8yfET0AIwf0T7uebzG94evrT+Bv8eWDVA/z1+78Cngyzcms5a46vodpWTYhfiBaknDN4Dttzt2tBpGdmPMO42HFEBUa1+bX+FL0mOOT9YXbV4FBJbQn//eG/ADw66VEfj6b7E0KQNCmJpElJzHppFumr0jn44UGyNmVRU1RD2mdppH3miUgH9Q0iZXoKKdNTSJqcRPSwaIQ666jgCfrUltRSkVVBRVYF5gIz5pNmak7WUHOypv52UQ1Oq/OU29IZdIQkhBAUE0TUsI79x64oitIbudqx0aiidJQXtr3Atye+5dsT3+L+k7vTTlDaXXb+vePf3DDqBlYeXckfNv6B7MpsXr/q9Vaf0xUaUjcs6Wo4fXtrziRz6Fi55/Fqe7W2zPs6YwJjGBAxgF35u/ih4Aft8UZlZXVTyI+PG9+oibCWOdTGnkPe4FBKeEqja6+owCgGRg7U7qdEpGgNjXVC16g58bMzniW/Op/+4f25d8K9ZFdmMyRqSIv7bRgYggbfly2n/r789r63AfjjRX9ssUfuz8f/3LOdJt+7i2qKcLqdGHSeEISUslFZGdRP0X6o6FCz7X5y6BPsLju/Wv0rVh9fzar0Vfz+wt/z9PSnWxynlJK86jwSQhK0v7O2fE6kFafx3NbnAOgf3p+siiy+OPwF58ady2PrH9MyfUx6E3HBcZyoPNEoEwjqZ16bP2I+lb+rJNQvlHJLOQ+tfkgr0VwwagHLDi7jaOlR+r3Uj1U3r9J+rpMSJ9E/vL+WLXdO7DkdHhiCXhQc8v6RltaW4nK70Ov0p3lG5/rPrv9gcVqYM3gOo/uO9vVwehSDv4Hh1w5n+LXDkVJSdqyM7O+zydqYRcaGDMwFZg4uO8jBZZ5/Tn6hfiScn0DipEQSL0gk8fxEAiLbHpFWujZvwKc6v9pzyfNc1xTXYCmxUFtSq11qimtw2Vxt2q4xyEh4v3DC+oV5LklhhCaFEpYcRkRKBCEJIej0vaaSV1EUpdO15xTFitJRGjaSfWZPKg+PG45fJxwffLD/Ax5d9yj7Tu4j2BgMQL65eSZHQ10iONSgJUh62ZkFh46XHUdK2WoA7lTBo+jAaAZGeAIy3t4y0CRzqDILgAcnPsh9K+/TAgRn2nPIGxzqH94faB4cahqAafj4wIiBWk8igPvOu0+7/cqcV9q0/6b7aRjUqbBWEOYXpr2HxTXFrDm2Br3Qc9Pom065vaiAKEx6E3aXHZ3Q4ZZuTppPkhCaAHh69VTaKokOjNZK4rxZUN4SvYa8jZkBVqWvAmD5keWtBoc+S/uM6z65jn9e9k8emfwI0Lgh9VPfPkW5tZznL39ee33eGegcbgd3j7ubSUmTuGv5Xby+53WOlB7BbDcT5hfGNcOv4faxt/Pc1uca9Z7y8gaHAEL9QgGICIjg8oGXszJ9JQDj4sZx+zm3s3D1Qrbnbue363/LoaJDGHVGxsePJyUihbSSNBJDEzttoqpeExwy6Axa6la5tbxLzQRW66jl3zv/DcBjkx/z8Wh6NiEEUYOjiBocxbg7xyGlpORwCZkbMjnx7Qlyd+RSlVNFxroMMtZlaM+LGRFD8oXJJE1OImZkDNHDojEFmU6xJ6WjSbfEbrZjrbRirbBiq7Rhray7rrBiKbdgKbNgLbNiKbNQU1xDdX415gIzLnvbAj4AfmF+hPcPJ7xfuCfzp28QwX2Dm12bgtXvQ2/lcks25dcQG2hgRISfKlNVFB9Rs5UpXd3mglp+LK3PUtmZ8zU5gwczKKzxMYTdZee1Xa/xs5E/Iz4kvl327f2yvTNvZ5sn6mlYVtZ0mvXO0ihz6AyDQ5W2ShauXojZbuaNq97QMlbA8x43LQtrKDowulG2jrZNayVLDywlpzJHe/7IPiOZN2weHx78EPAEAaDtPYeaBYcimmQOBTTOGGkYHPIGU9pD0+DQ2uNrmbl4Jq9f+Tr3jL8HgI8PfYxLupgzeI6WadQaIQRPTXuKguoCNmZtZP/J/eRX52vBoYZZQ95jJy1zqIXgUGFNfQ8so86ITug4UHSA/Or8Fv9OvEGYl3e8zEMXPIRep9eCQ8U1ufxp058AuGn0TaxKX0WhuZAJ8RPYmLWRqIAonpnxDAD3iHu0zLBZg2axbP4ywv3DAVh6YKm2v9F9Rms9lLw9gpq6YeQN2rhGxoxkYsJEPr/hc+Kfj+e7E98BnqCRv8Gf/mH9AZqV53WkXhMcAs8vfLm1nJLaki4VHHp337uU1JYwMWGiNuWd0jmEEMQMjyFmeAwTfzkRgKq8KnK355K7PZe87Xnk7cqjOLWY4tRi9rxenzIalhxG9LBoooZFETWk/hKWFKbK0lrhdrqxVlpx1Diw19i1a7u57lLd4LbZjtPqxFHrwFLqCfRYyiz1waAqG/zE3uL+Ef6ExIcQEh9CaEIowXGeIE9gdGDjS1SgCvoop5VRbWdXsefsYGq5jav6heBvUFliitLZvLOVqSRNpSuyuyTbTtaSb66fhSm18Gtyzfc1Cw69u+9dHlrzEOsz17NiwYp22f/R0qPadV5VHtCG4FAXyBxqOI38qcrKntvyHOll6Vpj4CBjEDWOGu0E/IwBMxplupyoOIFbuukb1Jdyazl2l51RfUZpAYuYoJgW+zFV2iq5+bObGy3rH96fBaMWaMGhM+055B1zS5lDRp2RYFNws/15eYMp7UGbwKkuIPd1+teAJ8hyz/h7kFLywY+e6ehvHn1zyxtp4rEpnsSHK5Zewf6T+7UZy6SUvLH3DQDG9h2rrd8vvB+BxkAKzYWU1pY2KqXyNkj/4oYvGBc3jvtX3s/K9JWsO76O289p3svT25MppyqH9RnrGRQ5CJfbk6H0bWZ9z6Anv32SFUcb/509M+MZbd/TU6azLmMd/gZ/XrviNS0wBJAQ4gl0xenh1Qgzh4Y+TLb0IzksucX3Y+7QuQQYAnBJlxbYiw2OZWryVL7P/h6obzB+QeIF/Gf3f5jef3prb2+761XBoZigGNLL0imuKW5Um+lLLreL57c9D3iyhtQZZ98LTQhlxPwRjJjvad7mtDkp2FNA9uZs8nflU5xWTOnRUq3Z8PG1jZvdGfwNRA6KJGpIFJFDPNehCaEERgcSEBVAYFQgxiBjt/pZuxwu7NV2bFU2bNU2z+1qG7aq+tvNHq97zFrhydyxlFuwV9vbdVzGICP+4f74h/njF+aHf5g//uF1tyP8CYj0vN8BkQEERAVoASFjgLFdx6H0bkWW+ky041UOlqRXcv3AUEJMXat8WVF6OpU5pHRl2WYHLglWR31Z0vGSzaRXlHNJQlCjdb1fEr9O/5pCcyGxwbFnvf+GWTfenienCg5JKbtEQ+qGZWUF5gLMdnOzYInFYeH33/y+UfnX1OSp2mxeAM9sfoYFoxZox9/ekrJRfUZxy5hbyKvKo9RSqgWHogPqy8oaatpUOdAYSFRAFLMGzdKWxQXHAc0zh1oaOzTvORQXEqeVY0UHRjf7ztAws8jbyLk9eINaZZYyz3Trdf1uvP1/VqavZEfeDsL8whpNWd8W3vdkR+4OlhxYgtPt5IvDXxDqF8rCCxZq6+mEjpHdDkWUAAAgAElEQVQxI9mVv4tDxYcaJU4UVHsCS+PixpEclqyVaK3NWNssOFTrqG2UfXTtx9dS66jlzgl/YXD8/WzM+Fx7rGlg6ILEC7hz3J3a/XvG38O6jHX85ZK/NArMASSGJgKwMBwudGdyYXANTHy+1fchzD+Mtbeuxeq0auVmANeNuK5ZcOjmMTczss/IRsGzjtargkNdcTr7lekrySjPYGDEQDV9fRdl8DOQNDmJpMlJ2jK30015ZjklaSWUHi31XI54rs2FZooOFlF0sKjVbRoDjUQNicIYaES6Jf7hnkCGf6TnOiAyAFOwCZfdhcvmwu10t7otL6ETGAONuJ1uXHYXepMevZ8enUGH0+rEaXF6rm1Obbsuu8tzv+62N3vHG+TxBnhO12y5zQT4h/ljCjZhDDJiCvJc+4X4eZYFGzEFm7SLMcCIIcCgvScBkQH1waBQP3QqO6NLE0IkAe8DffHkeb0hpXy5yTqXAF8CmXWLPpNSPtmZ4zxbxRbP38fU2EDSKmwUW118nlnNrUPCulUQWFG6O5fqOaR0YZl1J8hsDYJDLredtJJMHO4EjA2yzrfleJrSuqSLJT8u0fql/FROt5OM8oxmyyusFThcDox6I5+nfU5GeQYPT3oYIQRVtqpGwY1a59kFh6pt1dhd9hab6h4sOsgNn97A36b/jXnD5jV6rGFZGXiCOt4ym9TiVCqsFbjcrkaBoXD/8EYlT32C+nCg6ADzPpzHJf0v4eFJD2vBoUGRg7jjnDuA+pmjwZNUEB8SrwVpvI6XNT4p3D+8P0IITHoTqfenUmmr1IJuDTOH1h1fx8zFM/n37H/zwMQHAE/ZXrm1nPzqfPRCr5Vb6YSOfmH9SC9Lb/H9SgpN0nr4tGfmUNM2LN7gUEZ5BpXWSh5Z6/k9fOLiJ1oMcp2Kt+zrua3PNfpZvXHlG80CLiP71AWHiuqDQ27p1jLZ+gZ5pnK/fODlgKf8zft77LWvcB9u6SY+JJ6C6gItuLki7U3uiria/QXb8NP7EeoXqsUGVt+8mu2527lz3J3oRP13jOtGXEfpY6Va8Kwh789sgrftU2Xqad+LqclTmy27dvi1HNy6kAFGmBpV/3twbty5p91ee+pVwaHBkYMBTwOra4df6+PReCzavQiA+8+7v8s1yVZapzPotN5FTdmqbJSml2pBo7KjZZhPmqktqcVS6ml47Kh1ULivsIUtd01CLzwBnBATfiF++IXW3zaFmDy3Q/0areO99o/wJyDCE9jxC/VTJXe9ixN4REq5VwgRAuwRQqyTUjb95PxeSnmlD8bXLorrMocGhZkYH+PPW2nl5Nc6OVJhZ1iEn49Hpyi9h8ocUrqyjCpPgMFf78na8U4zXm0vJa/GQb9gIyctLnCVNZqC/d3972oBm58qqyKrUTPfhkotpcQGx/LAqgcoMBcwY8AMxsaObVRSBmefOTRn6RyOlBzh2K+ONcqYAE9QJrU4lSUHljQPDjU5qZ9emq4Fh8a9Pg67y86tY25ttE5yWDLzh89n8Y+LuX7k9UxKnMSv1/yaFUdXsOLoCmYPmt0oOOTlzQIBT1KBXqcnJTyFI6VHtCniXbJx38qGgY3hMcMBTyAIGs9Wti5jHRLJ5pzNPDDxAaSUXPTuRVq5X1JYUqOeSCkRKaSXpbfYCsWoN3LLmFvIqshq92oYbxuWrIosrX+TRPL7b37P0dKjDIkaogW3zoQ3OOQNDN097m6mJk/lhlE3NFvXO3PZjrwdWoPt0tpSnG4nEf4R+Bk8x1ZDo4YyPHo4aSVpvLrrVR664CFtG96SslkDZzE+fjwnKk7w0aGPOFF5gk9+eBCJZNagWSSEJPCf3f/hsgGXMXPQTGYOmtni+CMDImHvo2ArhvPfBks+uO2emdCACd7DvcpDICWc4d9rIrW80bfuzqaL4cIvIPGqM9pGe2hTcEgIMQt4GdADb0kpn2llvfnAp8B5UsrddcseB+4CXMCvpJRrWnpuZ/jF+F/wwrYX+ODHD3h6+tPtkqJ5NjLLM1l9bDV+ej9uH9u8TlLpnvxC/YgfH0/8+NYbCFrKLZQeLcXtcIOgvvTK21en3IrdbG+U/XO6gwK3y42j1oHeqEdn1DXKOjL4GzAEGDzXfgZtu3qT3nO/7rYpqC7I4w3+1AV8DAEGlQGhnDEpZQFQUHe7WgiRBiQApz+t0k043ZIymwsBRPnrMeoEU+MCWZNTw6b8GgaHmdCrgKiidApXg1loFKUrqbC5KLe58dMLLXNoSNQQ0krSqLEVk2N2UOuQLD9RTXHFBgAmJ03mcMlhDhYd9FQZtNAcuTUHiw4yKHKQNouVNwARFRBFqaW00boltSVEBURp/Vy+O/EdY2PHave9zqQhtcVh4cXtL3LrmFtJCkui1lHLluwtSCQHTh5gSvIUbV2b08Znhz8DaHHWJ29wKCU8hcyKTC2o43Q7tYwebx8cg86A0+0kKTSJeUPnsfPunYyLG4dAMCBiAC9tf4mNWRtZn7Fem8a+teCQt2n3wMiBHCk9wuCowewt2NtsfC1l7njf94aZV6nFnkMfb7+nE5UntJ9Lw/15eUvMmjaj9nrv6vdaXH62ogOjSS9LZ0v2lkbL39z7JgC/mfwbTPoz78fpLSsDTx+ll2e/TKAxsMV1Zw+azSNrH2H5keVaRpD39zEupH47Qgieu+w5rlx2JX/e9GduHn2zljHmDQ5NiJ+gBZj8Df48+d2THC/5DoHg1xf8mkGRg6j9/+ydd3xV9f3/n+fulZu9E5IQwp7KENkVRHEP3Ip1VVtXq3Zo9VtrrV0/bd22WltxVRHcIigiCMiUnZAEErJ3cnP3/Pz++Nx7cwMJS3C09/l48ODeMz/33Jt77nmd1/v1Drj4xZRfHPoFOPZBWbhczJAJlTIvKW/udkq0kBjxePg6wNMCxsyedfsTi4SAPX8Dvw3cjT3b9jRD2V96i0MBJ9QugbxzQWs9eFvHicOKQ4qiqIGngDlAHbBRUZR3D7zzG74rfAewPmbacOAyYASQA3yiKMpgIcSRtwo6jpSklnD+0PNZUraEJ9Y/wcOnPfxtDCPK81ueRyC4ZMQlfVoG4/z3Ykw2kjcp7/ALxonzX4KiKIXAOGLOETFMVhRlG9AA3C2EOLhFxXeUNk8QAaTo1dGSgDGpBja2eOjwBvmq3cP4dOO3O8g4cf5HCIYizqFveSBx4hzAfod0SxRYtHR5uoAeccjhbWN7uxejRgodWxrlaXLagGlYdBaW7V3G7tbdRywOvV/+Pue8dg73T7+f386SVdqRIOdzh5zLwu0LCYQC0cDmNlcbyYZkRLjLx+qa1dw26bZo3pBVb6Xb231UzqGF2xdy34r7WFm9kmVXL2NP257o9kvbSnuJQ8v2Losek766h0UCqacVTKOqqyraNSo2DynCL6b8godXP8yYzDEoisKE3AnReecOOZc2V5sUh6o+oaytDDi0cwhgYJIMpc635rOzZWdUkLp1wq3MLJzJaQNPO2gcEWdLbFlZVByyS3Fobe3aXuscaFqIhGEfKBqdaCKvO5J/EyHyus8efGxG79huYpPzJ/crDIF0YEUcQSurVzKneE5UHDrwOM0rmccZg85gaeVSbv3oVl6/6HU+2fcJn1ZJkTW2pfw1Y67ht6vk38SPJv6SGYUzAHjxvBf7H3jlP8DbDkpMhU/pn6MPk7q3M8tqARw98227esShphWw+gIY9xcYdGPvbe97Ebb8tPe0aYvh01nQshrcTWDMgpAfVp0PTZ/AsHtg3J/6H+/X5EgCOyYClUKIfUIIH/A6cF4fyz0E/BGIjWU/D3hdCOEVQlQBleHtfWvcferdgGxpF9vq8JsmJEK8vONlAG446YZvbRxx4sSJc6JRFMUCvAXcKYToPmD2FqBACDEGeAJ4u59t3KQoyiZFUTa1tn53cuMieUMZxp4fDSpFYWaO/NGzpsmFJ3j4zLA4ceJ8fSItijVx61Cc7xhNLnmuyDVreolDAKFgO3Z/iBZ3EINaoa5Tih+D0yYyPE02R+mrrXd/vLdHhutGnBPQ4xwalTGK68Zexyl5p0QvjNtcbdEOUiCdQ0KIqEsm4ow5GnFoT9seQJZSVbRXRIURgNLW0l7LvrbztejjFmcLbr+71/xI5lCkO9bSyqW4/e6DgqFzEnJ4aNZDfH7t59w77d4+xzV74GwAPiiXma+pxtRo7AhI4SGSNRMRSSLvU05CTq9yuDxrHhcNv6hX56oIUedQuKzM6XNGO5LVd9cjhIiKQz8c+0PmD5/PAzMe6LWNK0ddyVWjr+JH43/U52s5JH4HbLsfXHVHveqB4lBs2drE3InHXHkT6/g5ku5bFw27CIDFpdJVFvmMHrh/RVF44swnsOgsvLHrDUY9M4rTXz6dBnsDGeYMRmeOlgu66ije81t+PuoGTim8jp9MvK//nTd8DDVvgbcDNt4M234Fu34v5+l7i3VK86c8OCrs8InkFNl2gQj/9tv3T/B3w4aboHObnL7mCnh3EGz8sVxGHQ4sypoN6adC9lxAQO1i6S7a+BMpDAE0fHDYY/d1OBJxKBeojXleF54WRVGUk4B8IcSBoz3sut80p+afykXDLsLpd3LLB7cgxDH2wv6arKtdR42thjxrXp+hVHHixInz34CiKFqkMPSKEGLxgfOFEN1CCEf48YeAVlGUgwrshRB/F0KMF0KMT0//Zu+iHYpWjzTCpht7G3FLEnXkmTW4A4L1ze6+Vo0TJ85xJhD+TRfXhuJ812gMi0PJuiDugBuNShPNqjGpuqLLjU010OqQ4onZNCqaYRMrrvSF0x9i0d5uah3+6EV9XXePMBDpVFaSWsJz5zzHuuvXkZcgXTJtrrZeJWTNzmYqOiqipV6XjpCZMEcjDu3r6gm/fnbTs9FgY5DOoSZHExXtFdi9dt7Z8w5AVHg5sLQsUlY2Pmc8J2WfhNPvZPm+5QeJQ1MHTEVRFKYXTMes6939LcKAxAGynXm4iOXuU++OunxAZvmMzhyNVW+NuoiuHnM1v572a+6afBeJ+sTosrFOmAPRq3s7hyIuJZClZu3u9qg4tGDMAt6Y/0YvhwvIoOOFFyyM5isdFXtfgF2/g50PHfWqEXEo4ti6eNjF0Xlnlxx7PGSmORMF+eX8g6LDi0ORfOAlZUsIiVBPWVlMeVqEQSmDeOasZwAppBabk3ho1kNsv3l7z/tb+v+g6iUeCC3lkhH3olP3U0AVcEunzxcXQ+WzPSKPvwvURpi9CopvhAlPy+lNn5DpCxtOsubI/3f8Bt4wQ/Xr4IqRQtZcCjt+C/tfA8deCHmh+HqYswYGXCLdRQD54WNe/bIUpfb+QwpIaqMMvD4G0e9I+dqtfhRFUQGPAscco/9N3xF+4swnSNQn8mHFh7y49RA2shNIRCW/bMRlvdLQ48SJE+e/BUUGVb0AlAohHu1nmazwciiKMhF5Xmrva9nvGkIIasKlAumG3g0FFEVhVrg18eZWD54j6DgYJ06cr0co2q0srg7F+ebZ2rQ16toBmUm3vtlFpzdIS9hlagyHUScZkqIdl3yBdtIMarQqGJYMNk87KkVDuy+ZYWlHJg7t7PDwUeUy3qksjwoxteFsGyFE1HkUccFAjwjQ5mqLtgiP8Nym5yhvLyfVmBoN6D0acaiqsyr6+MWtL0ZLwUBevE9/cTqjnhnFw6sfxuV3MW3AtKg4sr+rRxzyBrx0e7tRK2qSDElcOLRHMIg4SS4efjF3TLqDB2c+eERjm10k3UMpxhR+MuHgYOWVC1ZS+pPSqMCUZEjioR88RHFKMYmGIxOHDswcOvD9K28vZ1vzNtSK+iBR6LhgD2cZdW496lUzzBm9np8z5By0Km308bGiVWuZVzKPMZljmJQ36dALBz2MdaznxRwj8zXN1Npq+y0rA8BVz1WOpbw48x7+ddK5VOZ08eukAJmWmNyfsOPG7KvjzMaf0m8bqPYNEAzf1NsRbp6rhIWknDMhcShM+jsMvA7UJrDthLYvAQWKwhnCvg4IemD/q9C1Q07TJUP3HtgZ/pxOfE6KQhOeg5STYOp/IDncsj7vXFDpoW0dbP+1nDb5pR7xqXHZoY/f1+BIVIl6ID/meV54WoQEYCSwUlGUauAU4F1FUcYfwbrAN39HODshm7+dIbsp3/rhrexo3nHC9xmLy+/izd1vAnD5qMu/0X3HiRMnzjfIFOBq4AeKomwN/5unKMrNiqLcHF7mYmBnOHPoceAy8W1ZOo+SXZ1emlwBTBqFggTtQfNzzVoKLFp8IcHmNk8fW4gTJ87xJN7KPs63yRVvXcF5r58XDRze0eHhswYXr1bYCAmZTef2y8rqRH1iNDi31dXCVSWJ3DgsGYdHXgAnGbPp9kOaRYo5pW2lhET/NxkWl77OP7+cz71Le/JvujwduPwudrXuosHeQKY5s1e+Ti9xKCy0RMKP/7r+r4AUAyKOHqf/yAKphRDs65TOoZKUEjo9nSytXBqdX2OroaKjAm/Qyx/X/BGQ7pmCxAKgd+5QpCV8mikNlaKKukne3fNuNB5kRPoI/nrGX4+4a9eCsQswa838/ge/J0GfcND8RENiv8LPETuHDsgcOlAcWlIq3TBjs8b263L6WjjC4lzXTggdXdTvhcMu5NT8U1FQyLZkMypjFI/NfYz7pt3HmMwxxzYeTwts/SXvn/sEW2/eevhA6/KnUDbewrVmN09kQH3jF/2WlQGw569Q/QrXsocFCeGufLsegtZ18nF3BdgrQGvFr0pgqP09kqseBWetHFssrTFZS6FwoPjU/0g3z8iY0j+1HjJkaSYiCMPuhoxpvbfVtBx8nVIYOnsPpISFwLwLYNBNsoSsr27luiSY8S6kT5NZR+P+DAPmQ/bpcn7jievvdSTdyjYCJYqiFCGFncuAKyIzhRA2IFoCoCjKSmSg6CZFUdzAq4qiPIoMpC4BNhy/4R87C8YuYOX+lfxr67/40fs/Yu31aw+/0nHA5rFx9mtn0+JsYUT6CMZljftG9hsnTpw43zRCiC+AQ16mCSGeBJ78ZkZ0/Ghw+llRL38oz8oxo1f3fa9lcpaR/ZV+NrW6GZmiJ1HX772qOHHifE3irezjfFsIIajqqkIghZFcay41dukstfulqJNt0mDzyE5lSYakqEOj1dmKQaPCAHwVLgXLssgUjjq3mUxzJs3OZmpsNb3apseyuvpDuS9v75DmPe01vF0m3UzzSub1qlaIiEOtrtZoNs7dp97Nu3veZV2dvKi+YOgF0eDgiHOoyRXg5fIuZudZGJtmwB/0c8fSO2hyNPGfi/+DzWvD7rNj1Vu585Q7+cmH0p2joFCYVBjN3olg1BiZP2J+tAwutqwsUlIWOVbD0odFu5ZFAof7KjM6FKfknYL9V/Zj6sJ7pM6hSFlZ5LjubpPiUKI+EZvXFjUJnJp/6lGP4Yhwho9x0CXLl6yDD718DAOTB7LmujW0udrQqrQYtcYja12/+0/grIERvwJTTIqMELDuWmj8CJz7YUo4Y6ptPQQckHWaFFBCATCETSL18jPrQosJP4GGpYcsK6Nphfy/8SOiPztFCNZdBaet6MnpyTmLtdp5zKi8mpTSe6H0XtCnwjmV0uETcEDLqt7bNuVJMSf/woP3m3eu3Gfe+TDmEZk5ZC6UpWRaq3xdAEmj5GubvVK6frLPOPzxzD5d/gsFewSk7Lnh17scfDbQJfa//jFyWOeQECIA3Ap8DJQCbwghdimK8ltFUc49zLq7gDeQbYuXAj/5tjqV9cXjZzyOWlGzvn79UbVn/Drc/MHNfFHzBXnWPBZdsijeHjxOnDhxvkEc/hAr653stfmOeRvrmly8VG7DFRDkWzSMTNH3u2yBRUtuOHvo+dJOtrXHHURx4pwoItnv/Wi1ceKcMOw+e9QlUtddhxCCWkeg1zJZpp4w6lhxqMXZQkiECIlQVCApTpaFF5tbPQxIko6Y/krLQiLEjqbPe01TK9LN+uqechbu7BGHYol1DjU55YX3oJRBLLt6GRcOu5DJeZM5vfj0g8ShPV1eAgLKu7z4gj4uXXQpz2x6hiVlS/h478dR19DA5IFcPvLyqEtkYPJATso+Kbr/c4fIy8j5I+Zj1VujwlesOBTJvYm4rADGZcsb6xvrNwKHFmn641ivvyLOIZPW1Cuc+kAiZWWegAchRLRKZVbRLKDnNZ4QcUgIcFb3PO/a3vdyrWvho3HQ8NHB63eXk2ZM6SWGHZKaRbD1F1DxFLw/FJpjPo/7XwuLNkD9BxD0ysDsFbPhs7ngqodlk+GD4TIA2t8NrWtAUbHeKp05iV0bo6WPBzmHvB3Q+ZV8HPJDyAepEyF5rGw///EpsOdxOT/nLGqSzmZV2i9j1m+X3cdWzIGV86BlpZxeeFV4nXl9t6EHmT00Zy1MfVMKOIoCp6+Dc6sgMyZXKXGU/F9jhvwLQHMUXWxjnUUJgyB1khSdNt4s36vjzBGdPoUQHwohBgshioUQD4enPSCEeLePZWcKITbFPH84vN4QIcRHBy7/bZKgT2BkxkhCIsRXTV+d8P3tbt3Nf3b+B51ax8oFK4/Y/hgnTpw4cb4eISHY1OLm77s7+bLFzZv7ullR78TmO7r7Fb6gYF04YHpShpGLB1oP+SNTURQuLLIyNEmHPwQf1Tj4stmFP/S9qJyLE+cgQkJ8ZzO04s6h7x+KouQrivKZoii7FUXZpSjKHX0sM1NRFFtMefIDfW3r2yS2rXpddx1dvhCOQAhtzJXWgeJQkiEJjUqDzWvjrFfPovCvhdHg4sEpAzg9T5YbabSyhf3u1t2EhKC004snEKLdIx08Syo24/C2YTVkUZw2nURjLsPCF6Z72naxv2MDKkXDnIFzeo05IrjEZg5lW7Kx6Cy8dclbrL1+LQaNAa1Ki1pREwgF+N2q3/HAJzcQDAVo9wa5/aPbWVK2JLrNV3e82kscSjYmc/7Q8wEYnj48mqFUlFTEW5e8xaL5i6JRHwVJvcvKtjdv58kN0lgc2859dIbsPiWQf+/HIg4BsuSq5YujWiUiCOUk5Bzy3B8pK/MGvWysWUVVVxWpxtSDunSdEHHI0yTzbiL0JQ65m2XgcudW2HZfb5Gh+mV4fwh8MV+6eQ6Hu0kKFQCJw6X7ZrcsF8RZC5tuk4/VJgjYoelTqHtHLieCctnuPeBtg6qX5HwRgLTJOLLOBKDIW8UpwWp+aI0Rh1z1sP6GsPAjenKBAAZcKh1DGTPl8XBWyQyf7LkEBaxNv4vm2WUyxwdk6HOkhCzkh4TBMnB6zCMw+hCh3io1pE8GVcy+jVlgzoe0mPc2adThj+ORMvklKTLtfx2q/n38thvmSMrK/quZkDOBbc3b2NSw6YR3Dfvdqt8hENww7gaKU4pP6L7ixIkTJ04PCjIjyBcS5Jo1NDgDbGhxs6HFzehUPWfkW1AdwQVlWVfPNiKB04fDrFVxfpGVza1ultc5WdngYlWji0kZRqZnm+IO0jjfKxZX2anu9nF+kZVBiYfJjfiGiWcOfS8JAHcJIbYoipIAbFYUZbkQ4kCbzGohxLG3SjrBNDt7xKF6ez214WYFRQk6rDoVre4Abm9NNEMnyZCESlGRbkqn0dEYzeSJdAjLs+ZxUroRd1CwvloKKo9veIbBmeeyuzuFPLOGettu/rHhl9Ha7RGZszhvzGMEhcLe+j+ws+ljNte+RkgEGZw+FbNOnodKEnXo1Qp1LgvQk+sDvduNR1AUBbPOTLe3mwc/f5BAKMDQnMvZ4tjL4m3PoVfrWXjBQi5ZdAnv7Hkn6gAamDQQgJ+f+nPW1q7l8pGXU5hUyMOrH+b2SbejUWm4aPhF0f1EnUNd+2lxtjD9xenYvLIMb2LuxOhyY7J6594ckzgkBKw8SwoH59eCIUM6VkofhYHXgqUwuqg7EGJ1o4sxqYaoc6jXPiv/DrYyGP1b0FpACFQtq0hQa5ioCzBxzUzuSYbQ0GspSi6KrpabkEu+NTaa9yhp+Bic+6Do2t5OFEfvsr2DxKH692H7/eAOh5B3fiVLqXztkHU6lIcr/WsXw3sl4OuC8U9C0ZV9j6P8Kem+yZojhYslOdC8Qq639nIZzpx9BqSdIrt41S0GV0+nOVHxdE/+QOWzkD5dPs4+g8ykKezfBQVaH/+K6IOd68E0D3b+TnZlizD4Nqh4Uoo7+efLnJ9ZH0PjUvC2gnU4GNIICVnqJSzFkFoIW34mhSkA6zDoLoWM6aBNgBExDqOjJX1Kz+PjKQ5ZB8P4p+DLa6WodpyJi0O5E3j+q+fZ2LDxhO6nvrue13e+jlal5RdTf3FC9xUnTpw4cXqjKApn5Fvo9gcpSdRT65A5QHttPra3ewmE4PQ8MwbNoQ2128NlYaNTDUc9hpPTjRjVKta3uGh2B1nX7EajUpicaYwKU05/CKNGOSKhKk6cb5qgEFR3+wgIWFzVzZQs03cqSyvuHPr+IYRoBBrDj+2KopQCuchIiu8UISHY3emlwKIl4YDPfKxzaHNzNWNapcM0z6IlRVPPH1bczBVVn0azaJIMSYDM0okE7UJP6VhENJiSZcJ18lWsr/43tbadXLd4DrfPXE1Zh5OnVl1Kl7unpfUp+bM4LddKmyeI0SvXb7DJcqaBaTPZ0eFheZ2T5XVOiq1adnfK81irszXa2r3PsF/AqDHR7e0mEHaSlDZ9zMaaVwB47uznmD9iPlPWT2FN7Rr+vPbPcp/JUhw6Oedkan/a087b82tPtPtVLLkJuagUFQ32Bm798FZsXhvTC6bz/07/f5ycfXJ0udGZo6OPFUV1UHetI8LTDK5w+/Gu7ZA1G7Y/AHv+JsWSGe/IeXtfoLm1ji26H1PW5UWnkQHWUXEoFISNt8h8m8YPYeZHUnzZfDu/T9MSKTz7TQo0jjwfv30/N1qhPQSavMm9bw5V/l26cEbe338ZUwRfJ6w+XzqESv8CUxdBSjjHNiIOJQ6Xbc87Y8Sh2syBa30AACAASURBVCWwOpydY8yBzFlQ/Qp8NkeKKkljoGsbaKRwGC1P23qPzNzpqxyqPnysht4lXTOpk6D9S/j8HFkeZsyRopGnWYpDNW9CwIm8bSdQIokzikqKHfa98nnOmQwyFrHEBdfHVrdtuRMypkrnTCwDLpKvJ2AHi/zsodbJXKAYIsZtlYIMlR54HZT+CfIvgpP/JlveD7n1kIf/iEgeB9pE6UhKGvn1txdL0TVymyknH37Zo+R/XhyKtA+M1K2eKFZWr0QgOL34dAYkDjih+4oTJ06cOAeTadKQGT7t5Vu05Fu01Dr8vLHXxu5OL5U2H1kmDUk6FVOyTQdd8FbbfdQ5A2hVMDTp2BwTw1P0DE/RU9rp5Z1qO6sbXWxolu4lo0bFqkYXxVbtYcvV4sT5NmhzBwkI+ZM+JGB1o4u1TS4uHmilyPrtu4iCsT/643zvUBSlEBgHrO9j9uRwV8sGZOObXd/g0ADY0eHloxoHJo3CBUVW8i09Akesc2i/rZ5mt7zgzTSEmPHP2dGMmUhr81hxqC/yrHnRx7PzM7l/9vv8ZtnptDjK2df2CWuqFtLlriPLOowuVz2BkI+ZhbMZnyEv3h2O3o6U4vQZlHX2ZO3t7fajU5vRqPS4A1LIsuqt0XwhkGXUuzu9DErUoVb1FgXWVb1AIORlePo4FoyV7buvGXMNa2rXRAWkiDgUodsXxBcUpBn7/q7QqrVMyJnAhvr1OKvfJEmt5rmznzsohqMwqRCjxoI74CBBn46iHEPImG1nzOPdbA8NYUTFP2R784YPwdMGnVtg/Q0UApmFU9G4PSS4bKgVNVPzw9UmziopDAF070GsvRpctSjApZYQofAskwqK110I3lb+Hu6u3qjeKMuuzPmyY9bGH8syqwEXS2HnUFS/KoUhRSVzdb64BOZtA42pJ4w6ay7YK+Vzb7sMXq4LCzmDboKxf5KCTfUrUhgCKQwBFF4Jw+6RAtqWn8nys6/uluVMJbeAJeyAclTJIGdNAmTOlNPyzpXiUGu4ZG/ySzKMWZ8GmadBswwSJ+csXO07MHlrCCh6GHI7mrI/y5KygssheRwpiopFHgtnmR38qRPuz80i2V4BK04Hf5c8TiqDbD2fMkGKQYeh5yZCeMKoB2TodOGVoE+Bkx897DaOCLUOfrBcZixp+8+nOiYU5YQIQ3CEmUP/zYzKGIVeraeioyJaB3wi+KJG/oFMGzDtMEvGiRMnTpxvinyLlitLkqIt52scfrZ3eHmhtIvNrW5sviDL6xy8V21n0V7ZgnhcmrHf7mRHyrBkPWcXWEjRq/GGBBtbPaxqlGGfe7v9bG71sLXNw64OD63uAIGQoNLmY0e7DLeMc3zwhwTrm13UO/3f9lC+FzS55UXf0CQd8wdaKbZqCYZdRN+FYxgKxZ1D31cURbEAbwF3CiG6D5i9BSgQQowBngDe7mcbNymKsklRlE2tra3HfYyV4UYGroDg9UobLe6ePJZY51C3p4GT0gxMyzaxtPxl9tv2MyxtWK/23UcjDimKwjlFOYwvkAG5ayofpbJ1JSatlZcv/JC7TlvPHTM/pyQlp8/1zbokchJHUXvA36hKUUgwZMUslxk9v/hDgkX7ulla62B5nQOVqrdbNhDOZ/lB8aXRadeNu45rxlwTfR4rDoWE4JUKG/8q68RTu1SWcPXBoksW8djQSXyQC++NnNBnPqtKUZGXJMWTBH0Wze7D5+K0ewK8UtHFl80uKQ509YhD7vYddO98AnVInoMRAdka/ctro8uMtr3GpbWX8sOO31O94NOe7l22sEaZMgGhz0BpW4MSdiSlq4JkasCODoEKvK0IXQqv2RXqA5Dt3Q/bf02908/n6/4phSE4uFtWX+z9p/x/0ouyZMlRCV/dI4WqiHPIWiIzdwDqwn8ybeHW7sU3yk5X1sEw+ndQfD2c8mLP9gdeBwnF0okz8v/ktIqnZXDzugXQuBzeKYS14VKznDOlCwcg95zoZkTRAt5yTeClPV34BXimfYBn4ktQcDmhMY9QaZLjqzGdypeZ98Lkl+HsMpjyqhS+gFbzELKr4LEusI16BFRaaA/rx8U3wNwNcNauIxKGINY5FD5PaMww5DYpDB1vUidIl9P3iP9555BWrWVs1ljW169n2d5lXDLikhOyn9U1qwFOeK5RnDhx4sQ5OrJMGi4vSaTTG8TmC7K1zUNZly9qv49lbKqBWTmmfrZ0dIxMMTAyxUCjy8/HtU7aPQGGJevZ3u7lk/r+O2j6QoKT04+i08V/OUIIdnV6KevyEQwJTs0y9bqj39fyiqLgC8qLnxqHHwWYnGlkWjwD6pA0ueRFWJZJQ3GijoFWLR/WONjR4eXdajs3DEtG+y3adqKZQ//ztz6/XyiKokUKQ68IIRYfOD9WLBJCfKgoytOKoqQJIdoOWO7vwN8Bxo8f/7VVdJsviCsQItukJRASVNulOFRs1bK328971Xbm5lvQqZVeziGHp5nTco2ERIgrX38EgP+b8X88vuFx1tauBXrEodig5QhqRX1QeVeeRcu1Y+bz4a4HqOyQgsRNJ13HlNwBbO7owKJPI0Xf43aNFYfGZE9HpaijF8ULBieCAp/WOZky8Cbe33kfAIrKyLpmN63uAHXOAHa/tL1U2HygHHzOUVAxLu+C6HONSsOL573IsLRhNDuaGZQyKDqvqtuPzRdiXMeLGEp/IUuQTvrLQdvMs+Zxx6BTYM96ppj6v0xNTxhORdsGrIYsah0Bsk39f+cDfFLnxNW+m1X2InZ3ermsbRuRM7mrbRvj3NUAtOReT0b9C7DrYQAChlw0nnpO7uzJtjFVPgkFsotWVBxKn0pd9vXk75LBzAFTIRqX3KY790q0ubMwuPaiDLmdlct+xYrObfyD9dC0nPUZLk7pfLNnsC2roOTm/l9M51bpatIlQ8Elsrzo44lSvGlZ2RNGbS6CAfOhaZks5co7H+zloDZCckxu08j7eh4HXLJkLXVCz7S88yDnLOm28nVB62pZmhZwyNb0kWVAZjnt80HSJPA30TTkESr2y7+bz+qd7Ony4g2eyRVjLyMgYGPS9WS5t7A+9VYa24JMGHn5QTffBqUMYnPjZlKNqRQMXgCWDLl/RYGCK3p38zoCQnGH6SGJnz6BswfLfLsFby/go4rj31Ct3dXOrtZd6NX6aBlbnDhx4sT5bpGsV1OYoOP8IisXFCVg1shfDkOSdJw5wMLFA63MzTcfd/Eg26RlweBE7hiVypn5Foqt8kduUYKWwYk6knTyVG0Nt735vMGF3X90Xdb+m9nd6eX9/Q4qbT6q7H5eqbCxrsnV57JLaxz8ZVs7L5R28tSuDmocfgxqBQGsbZYB5XH6pzEsDkUuxBRF4YwBFjKMamy+EJ/UOdjd4cXp/3a6mcUzh75/KPIL9QWgVAjRZz2HoihZ4eVQFGUi8vql/USOa0+Xl+dLO/n3Hvl9Uuvw4w9BukHNeYVWkvUqWj1BXq6w8WJZF9ta66PrBkWQZmczC7cvZL9tP0PThnLx8It7SpE42DmUm5AbdclkJ2Sj7uOCd37JUE7JOyX6/McTfoxBo2J6jolRKXrSjT3rZFmyUIWdF5PzezpkmTQK2WYt2SYt2SYNk4uuj85TFFnaXNrlw+4PYdWqyDJqCAnQqXvEIa1ayirF6dMRKilulXZ6WdPkQkHhl1N/yWNnPNbrXLm9wwNC9IgsHf3HeXjC4lewa1e0i9amVjfLah2EhMAdCJGdKPN1UsxF0fDv/qh1+Emrfpwb901hdvsfaHEH6WrpyeFJdWzEHGylU1vI6uyHekqAMk9j07jPcKuTe20vuXlxTy5OlxxrwDqcd1UXUWGZS5NhNLUj/xFd/gum8w7nwujfgD6F5855jn9cvQ4MWeBuRKl7mxzPFkKE37+Wzw9uUd69B5ZPg/1vwJa75LTCq0FtgJSTYMprYBogM4YcslscliIpCClqaPpEtpEHSBkv3Td9MfjHUiwKv3d2f5APahy0TXobzquGEWEhKeCAxJGynExrle3eAV55BU4+Gf/6M3CeUcYWuyW66S1tHpwBQUDAon3dbGpx02oYzs5JXxLM+AG+kKCsy8eBFCfLJk5TB0yVn6nceXDmV7JlvDGz79dxCEJHep5oa4Of/hRqao56H1+b4Lf3G+9/3jkE8Kupv6Kuu47nNj/HTe/fRM2dNcf1x3/kLsGkvEnR1oZx4sSJE+e7y5AkPYUJWrp9IdKNJ/5UqSgKYS2KCwda8QUFxphw7GBIoFLgrX12Krt9vFJuY3KWidEp+l7nqy5vkC5fkAKL9riLWIGQQK3wnXLWCCH4slkKOqdkGFGrYE2Tm9WNLooTdWTEvHc2X5Bt7R4E0OqRP7zSDWouKLLS6gmwpMrOygYXmSYNhQnffn7Od41ASETLaDJNPReh6nDY+0vlNra1e9nW7sWkUZiTJy8K8syag8J7TxTxbmXfS6YAVwM7FEXZGp52LzAAQAjxLHAxcIuiKAHADVwmTmB9bbXdx5Iqe/T5542u6M2C4kQdOrXCuQUJvF1tRwG6fCEa7c29trG/az8Pr5buk19P+zVqlZopA6aAvCSIikORHNJpBTJ2oqytrJfr50AuHXEpX9Z9ydziuZSklgBwSubBblaNSkNxcjGVHZWcVjSHbbLpV6/vxGyzFpWi5qez1rB01y+ZN+xOVAqMTzcyMkVPmkFNWZePd6vtaDU9+7hx/N0YVC4wXkyHN0hQCJbWOPCGBOkGNbs6vXR5g1w1OAmtSsEdCFFp85HnXk+ar1xupLus7xcoBLTLUG5NoBM8zYQMmaysdxIQkGZQk2XSMC5vPgk6M/kp06l1+KOO0KAQlHZ60akUUgxqhIAN5Rs5r/V3AIyzvYJtyP2klcn9+xUjWiHPIRUJZ1Dt1hLUPYK6aQ/Byx6ltLwbk2Uuo22vEzQWUKqdyMjuN+GjcTD41mh2UZVqMPYAvJ/0FGqfl7GmARQlj8PrqGO/eTpeu58Gp58cc1iUURQZgl39MnObpNizK/EiRrg/ReVukAJPQkxn68q/ywyfSI6PPk0GV0cYMB9yz5Ot4Ev/BNokGcqs0sqcn6ZlsOMBuWza5P4+XgA0Ov0srrLzg1wz++1+dnR4CQo4tzABBv8EKsLdyaYvkcHVQQ/o5OeZ994DwP7qf3j+glujXciyjBqa3AEsWhUpejU1Dj/lth4nXqpBTZ3Twc4OD2NSDQghqHMGyDCquWzkZby9521um3hbzyATh0kBZdkyKCmBoiKOlCPOpnviCfjrX6GlRYpe3xTvvw/nniv3efnl39x+w8TFIUCtUvPMWc+wuHQxdd11VHZURr9wjwfRkrL8eElZnDhx4nxf0KtVpBu/eYOtWlEwanr/alGHf8Wcnm+mvTJApzfERzUOGp0BxqUZaHIHqLH72d3pRQCDE3XMG2Dps/taVbePdm+QcWmGI3JYdHqDfFbvpNzmI1mvYkaOmaFJ340bHfu6/bR6gli0KqZlm1CrFNwBwZY2D0trHFw1ODGaK/BVmxSGhiTpmJBuxKpTYQ2LFikGNZMyAqxvcfN6ZTfDk/VYtCpGp+pJM/T9U8kTCLGywYVZqzAkSd/rouu/kSZXgJCAVL36INt/jlnLrBwTFTYf/pCg2R3knWp5ca1R5MXr5Exj9HN8oog7h75/CCG+AA75hgkhngSe/GZGBGubpFgwMcNIjknDBzV2nAH52SoOB69nm7XcMiIFIQSLq+zYvTLjaHDqYMrby/nz2j+zr3MfJSklXDpS5vKcmn9qdB+R4OdLRlxCi7OF+SPm88r2V3h95+vkJuT2O7YfT/gxakXdqwV8f7wx/w2aHE2Mzixhm02qQ+mGHqE2J1y2lZEwmBcuWMqkPVfC/rtRjdwBGjkv0vY+1jk0I38El4y4hKd3dtDtD7Gv24c3XKvzQY0Db/jqe2+3j6GWAJtqmwmFzEy3PdczOE8LeDt657yUl8OFF2BoaYCHATN4O3ZiS0kjfPhZ3ehiSpYJtUrLeUPn0+gKYPOFqLL7GWjVsa7JzRexzlEhuLr6djRCChGKr51Zzn+BcOHQZNKpLSTfLfNrWlLmEfJ4Ua75FXR3s1Y5meYp89iZdj2jvJ+jjH2YL9pGk+jfT757A+x+JLqbCmQJ3TW3XISxoZYVn22B2atYXN6O12cG4ItGF/OLrZR1+fAEQ4zLmgPVL2MKthNEw7rUn1Lo9JLQ/I4MxR4SI4Y0f9b7zT35b2BI63n+7LNQVwe//S0MuqH3sgMXSHEoUgJ2GHFoW7sXuz/Einpn9L2si+RVaUwwdxOEfGDK6bVeWaeHgZ+vQgekVJZhbqzHnpXLAIuWswosrGpwMSHDSLJexZfNbko7vVi0KvIsWrJCguW1UOsI0OUNUm7zsaLeiV6tMDmzmJ0370BZsQLqVsH0cKv7Z56B28LHKDNTCkSPPgqT+399QojeZWWffAJOJ5wXLovbuFEKMk8/DZs3y2kffgguF3z0EZxxBpjNhzx+X5tnn5Ui6auvxsWhbxNFUZhROINFuxexsnrlcRWHNjZI6+Tk/EP/McaJEydOnBPHuj9+TEe1B53VRHJRMlljs8gYlYHO/P1xiVh1am4clszODi/Lah1sbfewtd0Tna8AWhWU23w0lXVxTmFCNH/HFxR8UGNnT9i23eIKcOYAyyGdQEEheGOvjU6vLBPq9IZ4u8rOGfmCsWmGftc70QghsPtDfBrOZpqQbogKDzNyTJTbfDS4AnxS52RWrpkmV4Bt4eM0McNIrvlgS/2MHBMKsL7Fze5OGba6o8PDlSWJtLmD1IRLFyZmGEnSq1le52RXeLk1TW7OK0xgWPK3I5rVO/3st/sZYNGSa9Yckbsrcqf9UPOdAYHNF8QfEnxY4wCgIKHvcoRJmSYmZZoICsGaRhfVdj9qlfyx/0WTiz1dXs4tTDhhTrwah5/2sCPMoImLQ3GOjSZXgBqHH51K4dQsIwa1inyLli1tboSQTrhYFEXhnIIEPH4Zf3Ry9smUt5ezpGwJAPdOuxeNSq6TZkqjILGAGltNNI9Hq9by08k/BeDqMVezfN9ybhl/S7/j06l13Dbptn7nxzI2aywArkBPmWesiJ2oU2HWKDgDgmKzH1XDuzLQuOOraIiuVqVwSbGV1WVWdjTI9SLiVbZZg7ujE+/Wx0g0XIRNNyAqJgDs6fRStHYO07o2MFaTTUKgkaCixaVOJSHQJEul0ifT6Q3i37yZjLPmQle4OdBK4Czoat1Ji6Hn5ro7KKKZfCl6NZlGDZ83utjU6ibLqImWBhdYtNh8QZJsX5Dr2YzQp6MMvg0+eAAqHoQSMKaOQmceCPvWgy4ZQ/Y0Bry7DFW3jLg66YG7KFsyiVnjZ6BMakABLP4uXtF8wKWBf1JU8QsAvPp8ajwG9N0dpO6W3b5MKz5FjPkhjQEvINAosM/uZ0mVPeqYScudRj5AB3jeHoj2h06aBs+U4tDm26HzK5j0PCx+DZZ+BafpYMKzsjNXQYxoYLdLkSQQgFGj4NKekHB5MC4HVz1s/YUMeU4/lUMRydayx5QHZyz/EPeXfozX/5DQP16D5mZUDz0k99vcjPflV1j9xQ6GNjdF1zl952p2D72GyVmy++s5hQnReTOSVczITpYOqro61Jdfzi219aw//xq23HorZR4ViXXVTHrpKVL278XltWPevhWhVrPwg02cPGEoI14Pt7LX66G5Wf676CJ4+23pYLrmGikavfqqFIC0Wtpdfqbu2ou9YCC6nKvhrLPA74fqahgwQAoze/dKceirr+T2u7pg1izYsAHuvBMee+zgg+ZwSAEpo++A+UPidMKnn8KuXfK9++QTOX3tWikSHXiefuIJaG2Fn/8cLJaDt/c1iYtDMcwsmMmi3Yt4q/Qtntr4FGOzxvKv8//1tbYphOCrRvnhOjn7xLScixMnTpw4h2fbk4tprut9pwsFDFYVpiRIGzEAtcGIz+nD7/RjSDJgyjCh0qhQqVUoagVFpUQfq9QqUkpSSMhOoHFLI642FyIksGRbSMhJwJJlwZhsRJ+oR6VW4Wx1Ykg0YEwx4u5wR5dPH5GOKdVEwBvA2eJEZ9ZhTDGixLgshBDY6+14bB5SBqUwOtVAkk7NR7V2hIBsk4Ysk4bBSXoU4J1qO42uAK9U2MgyaZiYbqTC5mVPlw+dSiEkBNs7vDS5A6QbNJQk6Rhk1aE5wNmxrc1DpzdEil7NpYOslHV6+azBxbJaB4GQIARsb/dg0qgoSdQxOlX/tTu5xRIS0gVUaNGSZtQghOD9/Q52d3rRqIhmgIxL67mrrVerOK8wgdcrbWxp80QdQwCZRnX0bvmBqBSFmblmRqTo2e/wU97lo8bh5/nS3p1Mt7V7KEyQgbQaBQYn6cO5R3bMGhUD+hFPvg5CCLp8Iaw61UGuGG8wxKK93bjDF2WjU/TMK0joazMIIdjT5WNVowubL8iIZD2TMo2kHuCOCoQES6q62dvdO8sjx6RhZs6h75qqFYXpOWbC93apsfv5sMYezWe5eKCVvBgBSwiBJygQgKkPp9uR0OEJ8ta+boICxqUZSPyGytji/PexMSwujEnVYwh/l5m1KqZl9/+5D4TcuPwOdGpdr+5ak/Mmc+WoK3stu/2W7fiCPqz6g1tb5yTk8Mk1nxyPl9ELo1pBr1Jk2VeMOKQoCucXWbH7QmR4NvW0ZLft6NVhKdesJcvc852Sa0iHxx6jcPZ5pLc/y8i2P2OwbOLL7PuZW3Mj23N+yUbDWbS1lqHv2gBAQqARDNl8VfwUxtpXGNH9Fk1NO7BpT+LDPa1cdfU10NWFf0ge2j118DFwBvg6dtKUFkARAYYlGyjtCjDI/hGmQBspBbcwtPQmBrSU8dqARbwnZMOGYquW+cWJsGgR4rc3w+mgXHMzDLwB/vAAdDvgT6AeMwu1Pg32AbnnMCLVTOvqjwEIanWYO9u49pnfoH39tZ73yKylzhlgkepKbtI+SaK/lkbtELp8IQr3lUaXS1/1CbafLMAXEpg0CrPzLLxbbad5dwVKVh5CrWZ5RxJTEs6i8NV1mD8t58z6n7L+34soWfkmjNoEvAimCXDlneAFTh4JxT88+A1euVIKQwD33osttwCfNZH00cMibzQMvwfSp0DAgcB6sFVv50645x7cM2bhmH4ZGHvKCA1uB+f/4gY0Pi+iIB/uvBNVKIQ/JRXtU08B0HrufHL2ydLKgFaHxu9j0LoVlNxzq9xISws8/jjccANs3QoXXgj5+TB8uHTotLZiBn7wtwfZWbGbrlnzOP9XN6IK9O5EpwSDFC9ayOea6xm+di2KTgdNTbg6bPguu4ykjV/CpElyHM88iz8tHeOenvclLfwPgG2fgy+ccfT221Loiggzy5dLsSfCBvk55tVXpVB0+eXw/PPy//Z2GD9eCkwlJbBwYXQMrFolRasLLwS1Wrrjnn8ebroJBg2S+588GXbskMs/+ih45U0nOjpgzx4YGtOx74sv4Pbb5ePXXoOXX+7Z13EiLg7FMLNwJgAf75VfDNuatzGjYAaPb3icyXmTefqsp496m1VdVdi8NjLNmWQnZB/P4caJEydOnKNgYmgVAax40dNGGs1k0irS8djAY4OO/dXf9hCjaE1acsbn4Gxx0rmvExEShMJ3fxW1Qu6EXFJKUgh91YQh2UCoIIn9Lj+1WhWWbAtTzxlMqR92NzhpsOp5u8WJ6HChTTFy5ph07EFYsaGBJqOWpqwEdmZZSDJrmUQQfXkbuRNzUecksKbJhfAHGRf0Q5OKiXlWnAHB+r1dLN8bQImKCtJZ80WTizSdCosKRmWaKbYePvtor81HqyfASWlGdAeExWxv9/JJnROrVsX1w5LY0e6NunX8IXkX/6KB1oPWy7doObsggXfDpU0ZRjU5Ji0npxsOO550o4Z0o4aRKXoWltto9wTJNKoZkqSn3RNkV6c3KprMyDEzPt2AQa2wpc3Dm/tsnFOQgFpR6PQF0aoURibr+y2nEkLQ7Q/R4QnS7gnS6ApQ5/QTCmdrnFWQQHmXly+b3XT7QxQlaJlfbO1pwQtsbPHgDgqSdCoc/hDbO7wUJ+qwaFVsb/fgCghm55mxalV8Wu9kU2uP02x7h5cdHV5Gp+qZlGEixaAmGBK8XWVnb7cfrQpS9RrUKkjSqZmdZz7oWB+OAQlarhuazHv77VTYfLxSYUOlgEWjQqWAwx+Klowk6VRMyTIxKvXQrjRPMITTH4qKWp/Wy1KWkkQdc/JOsOU/zn8t3mCICpsPBQ7bEbLb281vVv6GH479IRadvHufac5keLpssa5T63jv8vfQqnuLxX2JQicaRZEuqHZPkAxjb+E02tmxbFPPxK4dB20jUgYHkPfmx/CznzHkgjX4L5cXzUWOFWR1BLB4y5hle4a6lPPIqfsUgLqkeeQMvRXVdb9ndO09bPzLuQBU1+9gTXcjs/98H+n79tBeOIh9f5zNhJufhSZgE2gSS2l2eLn5d+Ox7mvh1HmzSR30EYoBOluS0exfSO42uPpPZ1KfPwnfmRcx7dK5sGAuvLRMiiAVyOdb90E4e4my8+GuX8LqVXCrBR4cSfYpGrLXLANA/fJCuPZatP95HW68AU47DYDhyXp2d3gxaU3UDvod1tJrqTTPBKC4piJ6jArXrKD7/x7kgo1bcEyeyvCfLCD1+T+S+fTf2HHzXXxw0y9pcQd5O+t5frZedg7LKtvBjIvmQl01wemjUP9oB/z7V+ANCxirNBBpYiYEvPCCFBBiA5P37SNx2mQCOj3uL9djHNfTlcybcgplzy5k1B0Wmu//LWk/mI7vlh/DxRdjemUhVFZiXLqU6/KfZfV7n9Out+AOCGZsXIPGJ8+7gWuvRRuSv0U099wd3bb+mafIy5BZWc3XXE/uC8+gLF8OVVWQnS0zdNavh88/l2MWQo47MvZZs+Dmmwles4CRH77JkBXvS2Hoiiv4G966mQAAIABJREFU6oyL2NvuItmg4bRbLmf0O69iz8hGEQJx2myUpCRWdWuo/vXjXH/5LLQuJ6HCQjTV1Wja2wgMGYrmrHm02d3st3lJ6mylePl7MtsnwuLFMG9ez3giwlBqqhR/IrS0wJVXyvl//CNcdhnceKMUhgAqKqQAtm2bnDZ7tnQmjRoFc+fCP/4BNhssWiRL2N5/XwpDOTlSKGoLN2BUq2Wm0sKF0NAgXUJDh8Jd4TByqxUqK+Gpp467OKScwDy3Y2L8+PFi06ZNh1/wBCCEIPMvmbS6Wvucv+/2fRQlH3ngFcCi3YuY/+Z8zhh0Bh9defw7ocWJE+d/C0VRNgsh/qfbHh7recL22B/wvLuIxI3baTb7sadCSb2KYLceBwm0he8n6fChxY8LIy7MiIJCQvkFCLcHMXMWoewcRFAQ8AZo2dGCs8VJ9knZWPPlj35HowN7gx1HkwOvzYvH5iHkD2FKN+Hp8uDp8mBMMWJKMyGCgpZdLfgcPlQaFeYMM36nH0+X56DxG1ONGJIMdFV1IUIn9tyt6NVorxpLMNEAr28n2CBFlpRBKaQNT6P8vXIQoMlOIHVwCglD0uhKNdHZ5CT4UTm0uVCdVkz2nIGMS9RRtXwflhwLyUXJtO5uJWFgMubTBlKVZGJvtx/R5cGwsZZRehUZaUZyxufgsXl4p9aJfWAqIF0rTe4AQYePOYkaSoakYtWqejlQuqq7aNnRQuboTMwZZko/2UfW8HQyBqX0+1r7QghB45ZGzEVJBEw6UvTq6H7aPQH226U4NC5Nik0hIfhgvyMqXMWSaVQzOtVAmkFNQUzQdZMrwMe1jmgHsL6IlHzEUpigxR0IMSLFwLAkHc+XduENCa4oSaTZFYiW2sVi1ChYtSqa3UFUCpyWa6YgQcvGFjfb271RZ9XQJB2eoKDaLru4XVmSeNzKwEJC8Em4FC+29ARAr5bHMFLFMCHdQKZJQ75Fi1WrwhUQGDUKKkXBGwzxYlkXXb4QFxQloFMp/GdvNzqVwo+GJ2PWxhvxxs8Tx36ecPpD1Dj8hy0R/c3K3/Dg5w9ySt4pPDb3MSa/MJnxOeNZd/06lpQuYVbRLNJMaYfcxneKtVdD9cvycfpUmLO6Z14wyIOf/YbfrPkd6aZ0WrbPhZdfRpiNKE+54SCzpMLmqXtJ+uoGip0r8J38ArpfvQ9LZKmd8+dXYB7zKk3dU7HcX46lrQWhVrN44YeMNj9KyZKP4V9AKrj+nMyesvMY96d/9WxeD4wCkaJBqQ1AjzEEoVKhPP4nuPVuOa4BwF5g3Dgp8PzlL3LBpCSor4czz5TuDq1WzrvjDilm1NXBH/4A990HhYXwz39KASPCsmWwfz8rZ81ha60PdcDPRa/8jZx/93Qp64VKBWFRRSQk8Nf3t6JzOUiv2MUlt1/R9zrPjoQXd8L68GtLtqI0tsgyqkcegXvvDR8PPXi9lP/0VxQ89zhBnQFTVzueUWMw/OxOWLGC0O5Stpwym5EvPYPBbiOo1RJISUUfUwbG8OHY3T4SqippufHHpDz7JALwXnUNltde7nuMQECnR+Pz4rEkYHDYpcvmvvuk+yYvTzqE1q3rvVJ+Prz1lhRbUlNhwgRQqwk+8gjq8OsKnXc+qiWL8YYET+/sxBsMceOFk0ndvxd3UgrGrg7K/vgERXf9mCd3duAPQeq+cs5PFewbOBzNPXejd9jp+tOjTB2RxztV3ZR2+Tg9ReGkKWPk+5+fD01NUoh58EG4//7e47ztNvjsM+jslLlETx9gFPnJT6RAY7VK8WvOHPnZ+c9/5Ot74w2Z3xXrgLJYZBna1KlSeCothRdfhMRE6TACuOUWmakUYcwYuPlmOT0zU5agPfWUdBElJfX73vTHoc4RcXHoAK546wpe2/kad066k0Wli6jrrovOu3fqvTx82sNHtb37Pr2P33/x+2NaN06cOHEOJP6j//icJ/Z27GX6v6bTYG/A6oEUN1w4eBx/9sxCtX4TtG4Ekxu2pUJdzF0jRYHRo6UdeM4c+eOnslKexA8Rgni0OJodNGxqwJxhJn14OiqNCo1eXqT7HD72fboPe72d7JOy8XZ7sTfY0Zq1hAIhmrc3U/F+BYpaQWvS4mxxYsq0YMxOIGTz4Gx1EvKHSB6YjM/pw1Zjo7u2m1AwBFY9DEhCbGvqNR5LtoWgL4i7XZZcqMLlP6GYLItjIsWIYtAgWpzQz7Y00woIOf2EmuyoRmaifFlLsNtL7qRc/E4/nVWd6BP0uDvdBL3h9q8K6BP0eLu9qDQqTrrxJMbfPJ497+2hZlUNikohZXAKhkQDjVsaKZxVSOGMQjY8uQFDkoH28nYqP6rEkGRg8l2TGXXFKJIHynbGfpcflVZFw6YGtr64leEXD6foB0Vse2U7lUGF5kQDBruXBJ2apqDAqVGjDEpF0aiYmS3zira0eaMZRjoEyS0OMouSSLdoCa3ej96qY61b0PlVI8qIDObNLiLFoOb1ChuxRylSKjIwQcslgxIRQvB6ZTf7HX4SdSoGJ+po9QSptvsRDh9au5cLp+Yy0NojUrV7AmxocbMz3JEG/n979x3mZnUlfvx71TWSpvdmj8eFcbexMTEYDIbQWwKhBdKzpADJbpawv02y2TRCekijbEIIJSSEkIDBBBNKDMYY3Ls9tqf3XtSl+/vjyva4jPHY4xnhOZ/n0TOad169OrrS6EjnvcUsd/2R8jTyBxmCd6IicU1/JE5Ma7x2C06rhbjWrGsLsrzu4OJWik3hj2qcVkV5qoO4PrDcsd0CCkU4rllcmHLEVZvGIskTJ/f7RFzHKb+vnKquKgC+fs7X+fa/vs1lky5j6U1Lj37j0RaPm4l1QyG45mqI+sHqhhdmQE+iymJPg2s7Tb7TGs4/n56t6yj9RDcTyuaw9qd9sCPRS+ar0DpvCjnhHeb3TiANYvN/iVr3FSzRILx0Azz6JDgcpndEQS7c0wIPemFlH8ydCz//OV2zp+J4oYKUYAvxn03Dsm4LTABdDyoEXFUI2xtgxyGPyQ5cBQQXwtKVB7ZfWwhf+zpc/X2oqj7QGyMtzfTeuOkmM0zoULffboZAhUJwxhmwMbHs/Te+YQoIDQ1m8uNwmPCcubBtO3G7HUtRIY7t2wgUleCurwXgrU/cQUXTHtJffN4UCcaNg8pKOk6bTub2zcRsNqzRKHzlK8QffhjV0UHd7AWUrFtF9yVL8L36KpZgnFiOHWtrBB54wMR+110HhRzxpfLTl7djcdiZaAmx+NKzSK+vPuJLIOxKwRE0PWNaJ0zB296CisWo++cbrKzq4KM3LUFpjfra12DBAvStt6La2wl6U3H19RB2e2g6+zxKly+l5vSFtE2YwtynHjYHP/tsU0zx+83kzYmikE7x0PnhT5Hx6H2mN9d99x2YTPqgBxJBL1mCbm1DrViByjYnh16t7+ftlgDznniAC370NQBiNju/fmEdReUl7OgIwt5OKEplQm4KXeHY/rkSfXYLn5uWwa83d9IXjfPpinSyn3vG9Pp54AHTa2jZMjPRdH8/nHEGevVqE+fvf0/73AuJ+kPkpQYJTJ1LHAvusgLe2ptHEDcLeBvvEw+aIWYPPAC33UbAl0NVbxZFznZSN71p5i/atAkmTDBFyjPOgOZmNPBO2oVEvvo1Ft69CPWTn0A4jD7vfHZ84GNY0EzGrPDXSD6bmMHMb19Hzl2fZONjG5l06SS8+UOfd0iKQ0PQ0NvAS7tf4uYZN7OiZgUPrnmQyydfzi3P3EK+N5+aL9Uc1kX0aC55/BJerHyRp657imunXnsSIxdCjAXyoX/48sTW1q3c/NebmZg5kdeqXqPN38ZXz/oq31vyPSzVf4aVN0K/C/5qMYWisAteDEM0dvjB7HYzhnzRIpg2DSoqzAfR9xmtzUpTu1/eQ+OLu7D5I5QtKWPGTTNAw/a/bae7ppvpN0zHk+uhq6qLth1ttGxqobehF4fPwfjF48manMWK361nw6p6dDiG5cwSdJsf3daPGp8B21rRq+uId5pik7Iq0s8qpTvHC+1+4ltbUKkudGMP9EcOi9PmshENHt7jJiUnhZyKHOpW1RELx8iuyKZ9R/tx9bSyOqzEwgeea7vHjsVmIdQdOmy/4g8UU/36kT+IA7grcgifPY7YHzeCz4nK86K3t2JPdWLXGn+rn9TiVDy5HhrXNh52+4LTC7DarTjKM9ATMrH0h6kpSEMtLKUk282FDvDv6cThddDb1Mue16qpe72aceeO44w7F7Dqr9vZ8O3XCXeHuPTXl5I1KYv2Xe1klmcSj8bpqu6iubKTnrmFMK+Yi0s8ZBwyD5G/3U/r1la8eV6sDisNaxrIm5FH1uSsQR93LByjv7WfQHuAQGcAZ6oTX4GPlJwULIn5XHRcg2J/z6w9PWF2doXpj8bZ2xMmqk0RaMDcqFgww2GqEwW2SWkOrhrvO2zOrGQS6gkR6AiQPn7oZ3mHSvLE8H+fCEaDrKheQXV3NRZl4VPPfmr/3xQKjeY/PvAf/OiDPxq2+zxm995r5iZ54AGTiwazd68Z3rPZLL/O7U44MwQpxWbCYosNrB6IdMHVtWY1sZ9dAd8yQ21CH4MXzh7PNZ+p2n9IfYHi4W+9wq3Vl2J7OQC/BS4FPpkDoVZ4LBuWtUFKiln16YtfNPd/MWZeIZvdDL/Jz4N/XQUNzxNLm4W1/I/oubNRAVMIjp6bgu3ldiAGVY3wuyuhehuUZMIHPwpN94Ef+E8rdMXAAax+HGbdZL74X3qpCdjjMb0/PvaxA+3ypS8dONHzxS+aAtC+Fal6e81y5v/7v6aw9PTTZqLgH/940GauffD35N9+G2996kus/PR/cPOkNIraGiASwbJ9m3kOBlLKzEUTjUJPD29E3Cw8ZzaWRE+j1mmzWXvFjVz0fTMBdg8+tlFB5pdupmTlk7hWv8XOxZfw7E//wLXlqTitiuVP/ZPLvvNlMqdOZtuchWwPejntN7/FZrWx8bvfJf/ue3EFe9n4xM8YX1bM2rdqCcUdWGbmc9Vv7yHl0Rfw0YuLAD2k0Zo3hdo585nz4uMsy72JXlc+2dEacm48G06fgO3JP5B93nxsBbPY80oVEy+aiAoFWXPPcrxZDprb7TRuamNuXh2XZ7yJWvMuMZuTjY9tZNvT21hw5wIcXgcv/cdLtO9sJ9AZwOqwcvZ/nc3Ua6fy9kNr2WS1oaZm8zG9m/6N9Wz2p7HFmoNKdxFbugO9tQU8dixnFEO6G5s/jDUrhciZJWQ+t43Wul4cpxeSX9dFsDNIxvg0Ss8dT8fytVQu28UE9jCOairP+wyVr9biJMS0Ty5g1WO7iYVjTL1uKpV/20w0psga56V1rzmRYbPGmXLtDNLL0une0wEvvkhlTy5B3FgsmpJF40nJTiF3Ri7dVd1UvljJ3Bsnc27DH1nx5wZe06ZH2mW/uYzJV0xm21+3sf6362jaYOZwOv+8OO2vbmQDswCFxW7Bk+Oht6GXhXct5MJ7Lxz8f34QUhw6QVprpv16GtvatvHzi3/OHQvuOObb5f84n5b+FnbfsZsJGRNOcqRCiFOdfOg/OXni+Z3Pc8Ufr0CjuWzSZfzh6kfIfOt6aP7nwTsG3FD0Q9ijzIfJigro6THdewc67TSzasbq1eZM0Uc/CgsXmvHkXV0webK5XXW1OUZ3t+mKXFBgVrvo7DTdshcvNl2ZH3vM3L6iYlgf98m2uztMVW+YSelOXFZFOGaGB6U7rFgUdFWZIXKeXA9On5PG/giN/ig5bhub2oN01fWQ+4+dZJSkkj87n9o3aymYW0DB3AJ2Pr8Tb56XvFl5RPxmAvF9K8/52/0EOgJkTcqidWsrK3+0kq1/2UrejDwWfGkBNpeN5g3N+yf4fvP7b9Jd0838L8w3czhF4yy4YwEtm1pY99t17Hx+J+HECi5Wp5V4JI7D56BgbgFVr1YB4MpwUTCngL7mPrx5XlAQDUTp3NNJX1PfUdvJ4XPsP35qSSqeHA+BzgB5M/PYs3wPEf/hBTIwRbW00jS69nYd8e/HI29mHm072rC77fgKTSGnc08nPbU9R9y/5KwSZn50JoGOADUramhY00DWpCxcGS52v7SbeOTwHmEWm4Wy88tIyUlhy5+3kFqUSu6MXAIdATInZlKysITC+YV01PZQ+04D/r2dlFw+Gf85ZWxr6mdKT4Byj43GwjS8HX4sle30NvQybtE4nKlO3n3gXXpqekBBdkU2nhwPOq4JdgeZePFE8mflE+gI8PLdL9O+s51zvn4OE5ZMINwXpn51PSiIR+L01PWQOz2XgtMLiAai2D12uqu72fjYRso/WE7RGWbVpsZ1jbTvbGfKlVOwu+00rmtk+X8uJxaKkTM9h4kXT+T5256nv6WfS35xCfM/P/+g9qh7u46Xv/oy5ReVs/ArC7HaT6ywLHliePNEXMdZ9PAiVtauPGj7dVOv46mtTwEwPXc6Kz6xgnTXEIt/XVvg9cth+jcOTDa86wHTi2fOj8HyHq+Ft9+GM8801++/H/7t3w7+e7QfGl+CnEVw2fXwyisH5lFxAYsVODWcCUycBX4XbHsbrvod9D0Kt71qhmUBTACuB+4BPEA/xFO9VE0/g4wpKWQ8tgwiMbNs5vcwxZpvAy4X/OMfZgnyJ588eHnuDy+CPy2Htz4GNX8CRyZc/C54y2DVKgIvPULI+jqh675H3uSrD9yuYRm8dhnMvgcm3wEb/p+5/cuN8GvgujT4U4dZnQvMcJ1nnjH59G9/M5P53nmnGe61aZMZ6hONgs9Hf0s/3bXdWB1WMsszCfWEqL7rV+Q8+hNyrB0oq4X+sJ32796P2rIZb6Eby49+Si3F4PHSfOd32fD8Lvq6Qiifg6lz89m9dBexcIw5n5xN3xPP0t2tiU8/jZwsK4E+Tc2OAJnlmWROyiTgj9C2eTfpjTWkhjuxLDyTLWTh3LKXvI4q6nQhYcywR1uRh0U571J9zlVEd8RoWlnL+PPGU+VxEVlZQ+q0HHp7wsTfOPLJC1uWm3h36EAvYKcVp9tO6AhD24fL4v9dTHpZOq/9z2v7c5fFbsFqtx4x1ymLOqYTPAPz6LBTsH/8deJ6iiNCsaeTnZ1HXqEsd2IqrXt70bEjx77/JFfieBa7BR3T+x9rSoYDf+eBx2OxaMqWlLN7+R4AcqbmcO43z2XaddOG/nCkOHTi/rzlz1z/l+uxKivLb1nOeWXnHXX/WDzGT976CXe9fBdpzjQ6v9p5TEvLCiHE0ciH/pOXJ57f+Ty3PHMLncFOxqWN4/eX/5qz0rNZ1VpJVaCfhU2PUt6VmIeh6EpwF5gzrr5J8M5m+MtPYVc/1KZC6xG+SOfnQmu7Oft47rmmq3pnpzmjOnBVjPPmgD3HzGkApri0Z4/58Prww6ZrutNpzmz29JjJCHNyDtw+GjW9loaac3bvNoWruXOHftv3uVg4RrAriCf3yJMZa60J94aJRWK4M90HPiQCL9z+ArVv1nLNo9eQNyPvsNuGekIsu30ZjesaWfDt88ku9BFu91NwegHhvrAZ4leewYZHNtC+s52z7z4bV/qBCZkDHQFaNrcAUL+6nu6abuweO9WvVVO/uh4d19hctv0FjJScFHKm5VB6Vikrf7iSpvVNFC0oYt5t8wh0Blh2+zJ8hT7GnzueruoubC4bvkIfzjQnax9ce8QeWWAmSc+ZmkNfUx8Rf4S8WXnUr64ncoSeXfsp8OZ598+XFeoO0dvYu3944lDlz86nZUvL/oKTsqrDPnhbbJajD3dUUHpWKa1bWwl0HIjD7rETC8eOWMzax+FzEA1EzfEVzP7EbHwFPt68903i0Tgp2SlMvGQiO/6+g1DP4fNP7VN8ZjFp49Jo39GON99L1WtV+9vdV+TDm+el/OJylnx3ybE0y+EPUfLEsOaJffOHZrmzOKv0LJbuXIrdYmfL57dw75v3srp+Nc/d+BwlaSXHftBw2AyzevdO2HkfODLgqiqIheBvRRCPwLnPQ9GlZkjKz35m5hwZOHxZa3PSYNUq83thoZm/JCXFFD3+6wZ4+W+QFQFbCizzQ2YmbNsKV5XCqvf4Im0B4oAPiAF+0GeDegO4+TxYWWV6Iw2Un2/mcJloB2cxbNkL//M/8M1vHtjn/vvh9i+aXPiLMphSCi2vg80Hi5+H3EXH2IbdYE89kK9iYULv/ogdD/2Dsk9/Gt+Zt5jd+sM0LN9Kxy+ewHL+YvqsqTSta8KV5iC92IO3NIum9U2072inq7qLtm1t++9CWRRa6/3v+T56KKCR3WoSMT1685up+UXo2m54jxMP+1hdNgoTPVA79nbSNyETXdON3t2BsioyZ+TRA0TWmyHlOdNyCHWHCPeHSc2ykzYpl0BniLYdbUy9bipzPz2X+tX11KyooXNPp5lPsTOIJ8/DxEsmsv7h9cRCMc75xjlYbBYcXgdKKZ77zHMHxZV9Wjb5c/LZ/EfTm23WrbO44AcXkJKdws6lO/nL9X8hFoox85aZWKwWmjY00VPbQ9aULPJm5uHOdNPf0k9qcSpnfvlM+hr7TLG+2U9Gpou9K2rY8PQ2LB+ciFpQQllNB7POLCJ9fDpt29rY+8pebC4bFR+qYONjG+lv6af8onImXTKRva9UseaBNcz/4nzyZ+Xzzq/fYdpHppE1OYsdz+5g2kemkVqcSueeTnY8u4NgV5CM8gzQkF6WTunZpfQ29NK6tRV/q5+GNQ3YU+zkzcxj+VeW013TjcPr4OKfX0zNihrW/349FpuFyVdMpuJDFVR8uII1D67h5bteZsqVU1jy/SVklmdS82YN4d4w5R8sP2hV2yG9fqQ4NDzuWn4XP1z5Q8aljaPyjkpsliOPxY/rOLc8cwtPbDLjWL+1+Ft8/dyvH3FfIYQYCvnQf3LzRFVXFdc9dR3vNpjju21uAtHEPDvA/2RZuDsTHBzly2cUIjvOx96STWRGPrZ//hL1Rhw6AKsCpwP8iS+OebnQ3GLOrOYCzUGzZC2ALwX6AuYLgNsBgUE+yKemmrH7Vqs5M7ppE9piIXrG6dgXLzFd5SdMMHMkvPGGmcxw/nzIzET7fAQ2rsH90O9Ra9aY451zjjnLmpMD5eXmZyxmVvEIhczwhRdfNHMnLF5s/lZRYS579pgvH4WF5liRiInLajWrd7zzjrlddrb5crRrl/kSM368+dIzWFGqq8vMlZGZmFh630onra2mWDZ1qvmidTz6+g58mdonHoetW81klWlp5jEeYZhgu7+dDHcGFjU6XxIi/ggdlR2kl/pweh2mLQ6htT7o5NS+4V37hnUN1FPfQ9v2NvJn54PGTKy+s4G0ikIyT8sxt4nFTPvbbIT7wmz9y1Z2PLsDb4GXcYvGUTivkKYNTQS7gky+bPJh8yG0+dv4ztLvEF0eJT2cztxb5zI3ZS7+ej+uDBetW1upW1lH49pGfIU+CuYV4PA6eOOeN4iFYma+qMQE4+0723FnuSk6owh3hpvtf99OxB9hxo0zKL+4nFg4Rtv2NkLdIbTW6Khm4+Mb9xeASs8upWxJGW/f9zbBziDKoiiYW4DdY1bZ8+Z7qXmzhp7aHqxOq7l/q6LsvDL2vrr3oMJU5qRMOnZ17P996nVTmXfbPDY9sYkNj2xg+g3TGbd4HMtuX0Y0cHgBbtpHplH3dh3d1WY5pZkfnck1j14zlJfDfpInhi9PxHWc2ffPZlPLJn596a/53PzPUdVVRSASoCLnOHpyxuPw3e/Cd75jhjCd81forYLngPAc+MIlsPt7sBxY6YG8SWby2UjEFF7+7//g3nvA4YLGRvM+lZdnLvvmxklLg4rxsGrD4ff/WQd84ibY/Ht4JRNm3WXet//6FISi4LFBaic0AH2ATcGtGqqAVwYc5+GHzUmOfW28dKl5j7znHjMvX4spaFNQYN7nPYcU3jdtgBcuhJLEIkDuQli8DDJm7t8lFo4Ri8T29wjtb+2nbVsbGRMy8BX68Lf7adnUQtOGJlq3thIPx9n1wi78bX4cPgdnfulM7Cl23vrxW/jb/Bwrm9tG1uQsYqEY7bvasVgtlJxVQtu2tgO9QBUUzisEbd6HCIcYF9yBfcoEUi5YyJQrp5BWmkZ3TTfNG5sZd844dFyz+cnNZE7KJG9mHqGeEF1VpkBfdl7Z/l6mNrcNe4qdeCSOv92Pjmt0ioNNTjuNNT3YM93c9OEptPaE2PL9N6l5ZB05FTnM+OgMys4vY8ufttDY6mfvnCJSKtupSHOw6DNzSck2c7JprXmispueQJTLQiFyJmbizjCr83XXdBMNRo86XPhYRAIR4pE4ztSDJ3Zf+39r2fb0NiL+CNNumMbpnzkdZVWs+906gl1BPvDlDxxU8Gjb3ka4L2za+jht6QjyXLV53j51WvqwLbJwIuKxOKGeEK50s6hFLBxj17JdFC8oPixnxmPxI+brEyHFoWESi8eo+FUFuzp28cz1z3D1aVcfto/Wmv9+5b+554178Dq8/PHDf+TyyZePQrRCiFORfOg/+XkiFA3xgzd/wM/f/jntgXam5Uzj9MLTaeht4JW9r1BqjXN+CrgUjLdDmQ1SLfBS0I7LYuU7GYd3x17jh9ktYM3EnIF8BSgDZkFTt5s0TwS3PUqwzYLr53GoB74C8TBEdygcl2liSyGwxk44K4YDG+6YE6XtWLZ1HHZ/x8PvsqLsVtzD0S3bomBfN3CXyxRv1q49+m1OK4WoFWob0BPKIBBEdXSgoxGUP2AKR5dcYo63erUZhrePw2GKO6GQ+bvbbQoloZAZQlFaago9mZmmsNHUZI5XXQ2rVqGLi4nOmYV90xaz8kdXl5kHw+OB6dNNUWvaNLjqKrqba6C5iaruah517uDK7gIW9WeC14fS2sSRlWWGEHZ0ELVbsZz5ASzz5hPeuolmSwBrbx8Fb28lWjaOQHkpqZt3mfgqKsxwD4fDxNfSAsGgKcjE46ZYV1wMtbUmvur8rfNOAAAbrElEQVRqUySrrze9yW6+GU4/3cTQ3m6GS9TWmtu3t5uCXGmp2XffMb1es39Li3ns6elmUs7eXtObrLoaMjLMc1hfD3V1aLudzfPHUR/vwt4fxOP0UZRRQnHGOJTdYYZGulwHliru6QGvl3hRIX9veo1wcyPr82FrDsxphKzUXK6YcwNZISuxZ/6Ku7aRvqIcHFMqaMz38of+lViyZzG/byZn1W4ho2oXKhQiPHU29nmzULk5UF1NKBAnmpqBZ+Fs83iamswXVpvNtKnNRteLq2ip8pM5u5SsD52DuuACdE8PoX+7A7V1K87zzzKPuakJJkxAT5yEzsvHQpz+7gjK6SRclkaowca2Fe10NgSpWJTFlCsmsWlHI727HFj7ejkjYxeWiRNgzhxicbDOmQW9vYR+8SBV9kn4c0rJjrfS3Q3ukmwmLC4hvm4jHWv2EgnFcE4ZT9bHrxzsv+WoJE8MX554aM1DfHbpZylOLaby9kqctqOvYjYorc3/45e/bIZ27XMNUGOBNYkTDjbgSJ33CgpMMehQ2dnwyCPmPe+iiw78X4NZ1evfPwjZF8Lqv4C1Ei5pN2c6ACrugjn3Hny8WBh2/hL2PAJxO1z4IvxjPlQ1wI+yoC4Rw7ZtZvj0/oen0TGNxWZB795N+BcPEnxzDYFPfA616Gx8BT66qrvoqesh3BfGmeqkf+NSapf/i0g8m3jmIuKYIb3xSJxwX5jGtY1EQ1HSx6cT7gvjbz1Q4DnaUKO0cWn7i6z75E7PpWBuAQB2r53CeYWEe8N0VXXR29BLdkU2BXML8BX6yJ2eu38BiGgwitYau9uOjmuaNzbTsKaBcYvG7S+gaK0hHkctXWpOmKSlHTGu4RCKmefWeQzFgq5QDJ/DgvUIJ1201mjAMgZ6CWutWV7XTzSuuaTUKyN5kOLQsPrZqp/x5X98mSVlS3j51pcP+tuezj187vnP8dLul7AqK0tvWsrFEy8epUiFEKci+dA/cnkiEAnQHminOLV4/7bG3kb+tOVPrKhZQX1PPXPy5zA+fTz3r7l//8o1V2dmcpmtg4UuyLDCX4Me7mqNkUGQG7xwmQfOcJne+jbAnfiMtykEH2qEb2bAtXbYYIFZDnBaYHsYThusY8x6YBNmxZaJwGzMl4t3gEYgD6jBrCJzGtCNKT4FINIPYQeocyHlA0AEeA1oA7og1gzKn/gukYX5suGB6CyFrUlDHbRqcOyB1C5QuZizzYmTq9oKKjGns7YrAvN92Dr9OPrNOPtgaTbdkT5ytgWxHPxZ/iDaATqusAxY1j2a6iCcBRZ/BFfz8X+W0UqZos4hgj4brt7Bl5kfK7TLhQqevPknkkHcorAcx6TlQ7qPrCw0Gmu7KeZqiwUVH7wHYvC6D+H689PHdV+SJ048T3QGOllRs4LrnrqOcCzMo9c8ykdn3AzhDtAxUDawOMDmMcXjb3wdwhFTXM3MNHPOLZ4Hu1+F7zwBL7xiCq4AaS649dPwi18euEOvHSZHYC0mMczOggvbYfItMO8uU9CdNQsCATgHWABM+iR8/H4zCXXlQ7Dys5A2Cba1w7864NLp8Pm1YBkwSfWOXxL413/i703BtuQv2IsWYLFZiIai9Db00l3dbRYX8DpIyUnBneGmv7YWf0snsVg6PS+8QXenpi+1EE+uB3eWG3+bn72v7KW/uf/goZfDYOAwUXuKneyKbDoqOwh1h3CmOcmpyCFvdh55M/Kwp9hJG5fG+MXjqXyxkj0v7yHQFuC0a05jylVTpCggRIIUh4ZRV7CLop8U4Y/4eeMTb/Bi5Ys8tPYh5hfN5597/kkgGiDDlcH9l9/PR6Z9ZLTDFUKcYuRDf/Lmia5gF/3hfopSi6jvqaeqq4rZ+bPxODz0h/t5reo1Mt2Z5gx0RyV2qx2XsuBvf4faUJg27aDQV0g4FiYaizAl5zRc0X5C/jqaVBre9jfJ8+/Anr2AZ6pWsKVhNZ64n0meNDLsTjZ3N9ETjeBUcOtpl+Kw2mnqrma6L4udvc1s6+0g3elF9+5hij3KNIfCYxlQbLG46LamEXTm0hHsxh1sYKLNFEe6Y7A2BF1xmGCHWU7ojUNMQ/q+0VZx6AVe9UN3BOalQIUT6AH2AiVAYlRYMPG9wbXv5GcYutZBeiZQBLRiClE+U+eypWAO/i7EnRArAXsxB86ABzGTOtqACETDsDsIU1IS998O0XaI9ZvDkm72r7TAhnK4qBW87RAqBWcY07trImZoRRtUl8DmTW6cewOkp8PcPLAEgUroyoPl4yE9DiEFGcD8qAWHJw5pUNsDqRvM8fsLIXVfx6zpEKuD9c3wVj58PGzF2xkDnxnd0RWFdi9kusFmgdVBKGyEKUFw5wA5QDamaJcJsRboXAHpfWDTQAr48+Fxj5la5PoCWJwCjk7M/CHWRJsFoDcKO9wWevptTAiFGe+DgBMqU2BKGThaTRuu98IWD5QFYPJWC6luN/gcdGsXwf4W3PEYwQhsboVaP1QUgDMbwinQ7gdrG+SEFXNy07Gv74Qu0OUuIIgOQa2ykFphIWNyFNpgV61iYy2cFS7E3hSmPRpk5cwQDeVhQhaIV8HHOiE3BGt8UOCEzG4zSqfNC/1Z4NDQFYHeMKRFYXMe1GTB2U0wfzuU1oE9CnXTYc9FULkVmjLBWuyDpiAXdEUo8EO7goiCvCgUdoPfCvUO6LJDbwdYusAZhQLA5oY1pWBrgsldUBgBb2KUTeMEKyltMXy9UFMAYQ25AQsp8TjBPAstuYot0RjdZ5zLrfe9NqT3oH0kTxxfngjHwjxfdCMBv5V4SoRIVoRwRpQsq5NsvybeEyAYdeAIh3Hjx+0LEo66ie0GRzxMBBtBXIRwYiOKMyWEIxqhL+whiAuLNY6lKI5lShxL0TycG9ZibeohUjgD2/mXQGwL/VtX43csJKbcuPr/gdsbwF1YjmvadUTX/ovQltcJ5acR6teEgw6ivjNILclA1/6dxr352O0RnCkhcObSr2cTCSmcPieRQIRQdwh/u5++xmObp+ZE2FPsuDJcuDPcxKNxeup7SC1OJWNCBk6fk1BPCJvLxrhzx+HJ82CxWQ66WB1W8mbk4Ux10lHZgSvdZfazWtBxTTwax+p4/60IKkQykOLQMLtz2Z3ct/o+LMpCXB9cGb9x+o389KKfkuc9fFJKIYQ4UfKh//2RJ0ZDNB5lS8sWgtEgC4oXDLpfT6iHpr4mJmZMwBKoN8sVp5SAM+ugOX/iOs6uhpVkpOTiduezqv5tslOyiekYy7Y8zpbOGrKdXu6ZNIdwoJF32/awNOjG4ylkUuYk7FY7G2pfp615NYFgKwVuHyWpxbhTJ7Ois4XWzu1c7eiiOHsGltzF3LPuce5z72auPURb7oVkl15ByJaGvehyVm78FY6ml5gSbyEzsAetY/ytT7HJOZGPzP0CGaFGgm2rIdKFNyWf7OYXAOi3ZfBKNB2nv5oL3HEsCtpjsLQfLvdA1oDvFv0WD554P/1a0e+dQqfysqarkemxemYeOpJEWSFvCfRVQt+eI7bzxhBk2l0UWw7pdeMZT3j6/9JU+Qgl7a+hBsxfVReBVKsi1XL0z2bbo062xd3UhcK82+/nxlQLF7jj2BJPX5MlnT6tmKg7D7ttTDnQyoKFOCoeQxE7bJ+AcuLWocTrADaEIN8GBcM5VYPNa3pdBJtNLwwAneipZfOZ3hmxY58n5LhpIEyianj86qIWvGmTSe/ffuT72IUpcM7FdBuMYFaLGsQmSyEzbqg/rlgkTxxfnojHY9xn+wrdeogrjr3P2Nw2fAU+osEokUAEHdNYHVa8BV7SStPwFfqI+CP0t/QT6AjgyfXgyfXs3yd9XDreAi/9zf0Eu4M4vA6KFxSTXZFNuDeMPcUuhRshkpgUh4ZZOBbm889/nt+u+y0um4sHLn+AYDTI5KzJLB6/eLTDE0Kcwt5vH/qVUhcDP8f0U/g/rfX3D/m7E/gDcDrQDlyvta462jHfD3lCHKd4zHTvsacOvk80APEQIYt78Pk/GpZB+7sw5Q5wpBGJRdjV/C4eu5eqvnb+vvNZFuRWcF1eMRZ/PWTNg4zZNLRtITttAg67e/+hdCyMf88fCLWvwa0juNNPM6vVpU4GHYeml6FrI7jyIR6isa+FP7d3UFa0iCsmXoxqfgVceeAdD93bzYSrtsTkrF2boeoxwq1vscM+jm1Zl3BVxYdwxgPQXwX9teApgUgf1D4N7nxTlMo8HZQiGo+yvmk9ZellZDnc0L0VPOPAlVi9rvEl2PUbaH4N8s6F039hjjeQ1hCop6lmKc5QO2m+Iiyl14O/jljfbt7yR7E4M5noyyO37VWzNHRKMbiLwJFmYuurBGeOeZxdm2DNnRCog0mfh4KLzMpL/TUQ7TPdwHLOgvRZpsjWX2VuF+mB+ufAN9msVhTtgy33QOd68E00z2ewEdKmgWc8hFqhbRXkL4GSa6HxRUitMEtg1z9nnht7KnFlh841KH8DypVtiqHxsHn+XHnm8Yc7TZsSh72PEndk4rf6cIZasOUtRhVdCn17TfHKmQv5F9DXsR5/69vkxrqg6jHw15r2tKfCpM9B50ZofQOtFB2lH8dnBVuwmRZSyNC9OKN9YE8l1rWJcCxCW/ENRNzFZPRuJL3h76hJt8H0rw35Xwjef3niZDiuPKE1T3/9DlzV/eS1O4hvriPaGSSa4iGWk4fKzsPlshBxpeGP2gi29uNwRrFmpxLOmYDdFccVfgdH/+vE7FMJ6TMJRZx4JhaQkg7xaIS48hGv/juxxpWEornEC6/Hnp61f26bgYWYYGeQQHMzgZ2vEmzci81txZlXjnPyJTjT3Dj6V2Kt/QNdXSXEU2dSdPktaNT+lfI8OR7sKXZCvSHsbjvONCeudBepxanDPsGtEOL9Q4pDJ4HWmhd2vcC49HFMz50+2uEIIcaI99OHfqWUFdgJXAjUYWbBuVFrvXXAPp8HZmqtb1NK3QBco7W+/mjHfb/kCSHGrHjEFHccGaMdyciIx0yBsHsz5C4+UICLx0xvvKGuZhePQTyUGE85dO+nPHGyjGqeiMfAcpSeM/Eo1D8LOWeDK/fYjhkLgsV5+IqO0QBYXYOv9CiEEIc4Wo4Y/bXc3qeUUlw2+bLRDkMIIZLZGUCl1noPgFLqSeAqYOuAfa4Cvpm4/hfgl0oppZPtzIUQ4thZ7GOnMASmEJA5x1wO3X68x7McX2FIJIH3et4tNij50NCOaR1kDKLNfeTtQghxHI7pVIZS6mKl1A6lVKVS6u4j/P02pdQmpdR6pdQbSqmpie3jlVKBxPb1Sqn7h/sBCCGESFpFQO2A3+sS2464j9Y6illLK2tEohNCCCGEEEIAx9BzKDEs4FcMGBaglHp24LAA4Amt9f2J/a8EfgLsW8N9t9Z69vCGLYQQYixRSn0W+CxAaWnpKEcjhBBCCCHEqeVYeg7tHxagtQ4D+4YF7Ke17hnwqwezLoMQQoixrR6zgPk+xYltR9xHKWUD0jATUx9Ea/2g1nqe1npeTk7OSQpXCCGEEEKIselYikPHMiwApdQXlFK7gR8Adwz4U5lSap1S6nWl1KITilYIIcT7yTvAJKVUmVLKAdwAPHvIPs8CH0tcvxZ4ReYbEkIIIYQQYmQN2zqGWutfaa3Lga8C+9bebARKtdZzgH8HnlBKHbY+rVLqs0qpd5VS77a2tg5XSEIIIUZRYg6hLwL/ALYBf9Zab1FKfSsxBBngt0CWUqoSkycOm9dOCCGEEEIIcXIdy2plxzIsYKAngd8AaK1DQChxfU2iZ9Fk4KC1JbXWDwIPgll68liDF0IIkdy01i8ALxyy7RsDrgeB60Y6LiGEEEIIIcQBx9Jz6D2HBSilJg349TJgV2J7TmJCa5RSE4BJwJ7hCFwIIYQQQgghhBBCnLj37DmktY4qpfYNC7ACv9s3LAB4V2v9LPBFpdQFQATo5MD8EecA31JKRYA4cJvWuuNkPBAhhBBCCCGEEEIIMXTHMqzsWIYF3DnI7Z4Gnj6RAIUQQgghhBBCCCHEyTNsE1ILIYQQQgghhBBCiPcflWwrBiulWoHq47x5NtA2jOEMl2SMKxljguSMKxljguSMKxljguSM63hjGqe1zhnuYN5PJE+MmGSMCZIzrmSMCZIzrmSMCZIzLskTx0nyxIhJxpggOeNKxpggOeNKxpggOeM6npgGzRFJVxw6EUqpd7XW80Y7jkMlY1zJGBMkZ1zJGBMkZ1zJGBMkZ1zJGNNYkKztnoxxJWNMkJxxJWNMkJxxJWNMkJxxJWNMY0GytnsyxpWMMUFyxpWMMUFyxpWMMUFyxjXcMcmwMiGEEEIIIYQQQogxTIpDQgghhBBCCCGEEGPYqVYcenC0AxhEMsaVjDFBcsaVjDFBcsaVjDFBcsaVjDGNBcna7skYVzLGBMkZVzLGBMkZVzLGBMkZVzLGNBYka7snY1zJGBMkZ1zJGBMkZ1zJGBMkZ1zDGtMpNeeQEEIIIYQQQgghhBiaU63nkBBCCCGEEEIIIYQYglOmOKSUulgptUMpVamUunuUYihRSr2qlNqqlNqilLozsf2bSql6pdT6xOXSUYitSim1KXH/7ya2ZSqlliuldiV+ZoxgPFMGtMd6pVSPUupLo9FWSqnfKaValFKbB2w7Ytso477E62yjUmruCMb0Q6XU9sT9PqOUSk9sH6+UCgxos/tPRkxHiWvQ50wp9V+JttqhlLpoBGP604B4qpRS6xPbR7KtBns/GNXX1lgmeeI9Y5M8MXgskidOLC7JE4fHJDkiCUmeeM/YJE8MHovkiROLS/LE4TGNfJ7QWr/vL4AV2A1MABzABmDqKMRRAMxNXPcBO4GpwDeBr4xyG1UB2Yds+wFwd+L63cC9o/j8NQHjRqOtgHOAucDm92ob4FJgGaCAM4G3RzCmDwK2xPV7B8Q0fuB+o9BWR3zOEq/9DYATKEv8j1pHIqZD/v5j4Buj0FaDvR+M6mtrrF4kTxxTbJInBr9/yRMnFpfkicPvU3JEkl0kTxxTbJInBr9/yRMnFpfkicPvc8TzxKnSc+gMoFJrvUdrHQaeBK4a6SC01o1a67WJ673ANqBopOMYgquARxLXHwGuHqU4lgC7tdbVo3HnWut/AR2HbB6sba4C/qCNVUC6UqpgJGLSWr+ktY4mfl0FFA/3/R5PXEdxFfCk1jqktd4LVGL+V0csJqWUAj4C/HG47/e9HOX9YFRfW2OY5InjI3kCyRMnGtdRjNk8ITkiKUmeOD6SJ5A8caJxHYXkCUYuT5wqxaEioHbA73WM8puoUmo8MAd4O7Hpi4nuXb8bye6WA2jgJaXUGqXUZxPb8rTWjYnrTUDeKMQFcAMH/7ONdlvB4G2TLK+1T2Iqw/uUKaXWKaVeV0otGoV4jvScJUNbLQKatda7Bmwb8bY65P0g2V9bp6qka1/JE0MieWLoJE8cm1HPE5IjkkbStbHkiSGRPDF0kieOzZjJE6dKcSipKKW8wNPAl7TWPcBvgHJgNtCI6ZY20s7WWs8FLgG+oJQ6Z+AftemLNuJL1ymlHMCVwFOJTcnQVgcZrbYZjFLqv4Eo8HhiUyNQqrWeA/w78IRSKnUEQ0q652yAGzn4g8KIt9UR3g/2S7bXlhg5kieOneSJoZM8MSSjmickR4jBSJ44dpInhk7yxJCMmTxxqhSH6oGSAb8XJ7aNOKWUHfPkPa61/iuA1rpZax3TWseBhzgJXeHei9a6PvGzBXgmEUPzvq5miZ8tIx0XJrms1Vo3J+Ib9bZKGKxtRvW1ppT6OHA5cHPizYBEN8v2xPU1mLG4k0cqpqM8Z6PdVjbgQ8CfBsQ6om11pPcDkvS1NQYkTftKnhgyyRNDIHni2I12npAckXSSpo0lTwyZ5IkhkDxx7MZanjhVikPvAJOUUmWJyvENwLMjHYRSSgG/BbZprX8yYPvAsX7XAJsPve1JjsujlPLtu46ZiGwzpo0+ltjtY8DfRzKuhIMqsaPdVgMM1jbPArcq40yge0C3vpNKKXUxcBdwpdbaP2B7jlLKmrg+AZgE7BmJmBL3Odhz9ixwg1LKqZQqS8S1eqTiAi4Atmut6/ZtGMm2Guz9gCR8bY0RkieOHpfkiaFLuv9lyRNDNmp5QnJEUpI8cfS4JE8MXdL9P0ueGLKxlSf0CMxIPhIXzOzcOzGVu/8epRjOxnTr2gisT1wuBR4FNiW2PwsUjHBcEzCzvG8AtuxrHyAL+CewC3gZyBzhuDxAO5A2YNuItxUmmTQCEczYzE8N1jaY2d9/lXidbQLmjWBMlZhxpPteW/cn9v1w4nldD6wFrhjhthr0OQP+O9FWO4BLRiqmxPbfA7cdsu9IttVg7wej+toayxfJE0eNS/LE0eOQPHFicUmeODwmyRFJeJE8cdS4JE8cPQ7JEycWl+SJw2Ma8TyhEgcSQgghhBBCCCGEEGPQqTKsTAghhBBCCCGEEEIcBykOCSGEEEIIIYQQQoxhUhwSQgghhBBCCCGEGMOkOCSEEEIIIYQQQggxhklxSAghhBBCCCGEEGIMk+KQOKUppWJKqfUDLncP47HHK6U2D9fxhBBCjDzJE0IIIY5G8oQYK2yjHYAQJ1lAaz17tIMQQgiRtCRPCCGEOBrJE2JMkJ5DYkxSSlUppX6glNqklFqtlJqY2D5eKfWKUmqjUuqfSqnSxPY8pdQzSqkNicvCxKGsSqmHlFJblFIvKaXcif3vUEptTRznyVF6mEIIIY6T5AkhhBBHI3lCnGqkOCROde5DuoFeP+Bv3VrrGcAvgZ8ltv0CeERrPRN4HLgvsf0+4HWt9SxgLrAlsX0S8Cut9TSgC/hwYvvdwJzEcW47WQ9OCCHECZM8IYQQ4mgkT4gxQWmtRzsGIU4apVSf1tp7hO1VwPla6z1KKTvQpLXOUkq1AQVa60hie6PWOlsp1QoUa61DA44xHliutZ6U+P2rgF1r/R2l1ItAH/A34G9a676T/FCFEEIcB8kTQgghjkbyhBgrpOeQGMv0INeHIjTgeowD83hdBvwKc1bgHaWUzO8lhBDvP5InhBBCHI3kCXHKkOKQGMuuH/DzrcT1lcANies3AysS1/8JfA5AKWVVSqUNdlCllAUo0Vq/CnwVSAMOO9sghBAi6UmeEEIIcTSSJ8QpQ6qP4lTnVkqtH/D7i1rrfctPZiilNmKq9Tcmtt0OPKyU+k+gFfhEYvudwINKqU9hKvqfAxoHuU8r8FjiDV8B92mtu4btEQkhhBhOkieEEEIcjeQJMSbInENiTEqMEZ6ntW4b7ViEEEIkH8kTQgghjkbyhDjVyLAyIYQQQgghhBBCiDFMeg4JIYQQQgghhBBCjGHSc0gIIYQQQgghhBBiDJPikBBCCCGEEEIIIcQYJsUhIYQQQgghhBBCiDFMikNCCCGEEEIIIYQQY5gUh4QQQgghhBBCCCHGMCkOCSGEEEIIIYQQQoxh/x8/TseObiG6XQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run trainRNN_plot_utils.py\n",
    "plot_inputs(F1_scores, trainLosses, testLosses, n_epoch, \"Learning Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved into pickle.\n"
     ]
    }
   ],
   "source": [
    "# SAVE DATA\n",
    "# Save the created samples, such tha the NNs can load them easily\n",
    "\n",
    "# Save data into Python friendly file\n",
    "import pickle\n",
    "with open('resultsAttentionLearningRate_HBTRC.pickle', 'wb') as f:\n",
    "    pickle.dump( rSnpRnaA_tst_nXNS, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( rSnpRnaB_tst_nXNS, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( trainLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( testLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( F1_scores, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( trainAccuracy, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( attention_matrixA, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( attention_matrixB, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( tst_prediction, f, pickle.HIGHEST_PROTOCOL )\n",
    "    print( 'Data saved into pickle.' )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
