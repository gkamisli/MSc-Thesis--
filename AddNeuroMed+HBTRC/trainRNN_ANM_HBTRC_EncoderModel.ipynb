{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Explanation\n",
    "\n",
    "**trainRNN_ANM_HBTRC_EncoderModel.ipynb:**\n",
    "<br> This notebook is to load AddNeuroMed examples from 'preprocessData.pickle', and HBTRC examples from 'preprocessData_HBTRC.pickle' and create an \"Encoder Network\". Train the network on AddNeuroMed data set and test on HBTRC data set\n",
    "\n",
    "**Variables information**:\n",
    "<br> 1) Variables in the format of xxx_A represents data from AddNeuroMed\n",
    "<br> 2) Variables in the format of xxx_H represents data from HBTRC\n",
    "\n",
    "**Processes are as follows:**\n",
    "<br> 1) Load all variables from 'preprocessData.pickle' and 'preprocessData_HBTRC.pickle'\n",
    "<br> 2) Parameter and hyperparameter assignments (location: **3rd cell**)\n",
    "<br> 3) Create LSTM cells with Dropout Wrappers for gene A and gene B (function: **dropoutWrapper** in **trainRNN_network_utils.py**)\n",
    "<br> 4) Using LSTM cells, create multi-layer dynamic model (function: **dynamicLSTM** using **length** in **trainRNN_network_utils.py**)\n",
    "<br> 5) Create a single output based on the relevants outputs of encoder models of gene A and gene B \n",
    "<br> 6) Pass the output through a **dense** layer and make prediction with **softmax**\n",
    "<br> 7) Before starting the training: concatenate rSnpG_tr_nXSN and rRnaG_nXS where G represents gene A and gene B (function: **input_reshape** in **trainRNN_utils.py**)\n",
    "<br> 8) Train the network: every epoch (i.e., iteration) shuffle the data within each class (function: **shuffle_classes** in **trainRNN_utils.py**) and train in batches (function: **extract_batch_size** in **trainRNN_utils.py**)\n",
    "<br> 9) Plot results with **plot_one_input** in **trainRNN_plot_utils.py**)\n",
    "<br> 10) Save them in \"resultsEncoder_ANM_HBTRC.pickle\" to be called when necessary\n",
    "\n",
    "**Variables created:**\n",
    "<br> 1) **trainLosses**: Train losses, dictionary, keys of (dropout)\n",
    "<br> 2) **testLosses**: Test losses, dictionary, keys of (dropout)\n",
    "<br> 3) **F1_scores**: F1_scores, dictionary, keys of (dropout)\n",
    "<br> 4) **trainAccuracy**: Train accuracy, dictionary, keys of (dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.core.debugger import set_trace \n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[ \"CUDA_VISIBLE_DEVICES\" ] = \"3\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddNeuroMed data loaded from pickle.\n",
      "All AddNeuroMed samples loaded.\n",
      "Number of training samples (transcripts) of gene A: 1500\n",
      "Number of training samples (transcripts) of gene B: 1500\n",
      "Number of test samples (transcripts) of gene A: 45\n",
      "Number of test samples (transcripts) of gene B: 45\n",
      "Number of subjects iSnum: 206\n",
      "Number of SNPs iNnum: 100\n",
      "Number of association classes iCnum: 3\n"
     ]
    }
   ],
   "source": [
    "# LOAD AddNeuroMed DATA\n",
    "# Load data form the pickle produced by \"preprocessData.ipynb\" in AddNeuroMed folder\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('../AddNeuroMed/preprocessData.pickle', 'rb') as f:\n",
    "    rSnpA_nXSN_A = pickle.load( f )\n",
    "    rSnpB_nXSN_A = pickle.load( f )\n",
    "    rRnaA_nXS_A = pickle.load( f )\n",
    "    rRnaB_nXS_A = pickle.load( f )\n",
    "    rRelated_nXC_A = pickle.load( f )\n",
    "    rSnpA_tr_nXSN_A = pickle.load( f )\n",
    "    rSnpB_tr_nXSN_A = pickle.load( f )\n",
    "    rRnaA_tr_nXS_A = pickle.load( f )\n",
    "    rRnaB_tr_nXS_A = pickle.load( f )\n",
    "    rRelated_tr_nXC_A = pickle.load( f )\n",
    "    rSnpA_tst_nXSN_A = pickle.load( f )\n",
    "    rSnpB_tst_nXSN_A = pickle.load( f )\n",
    "    rRnaA_tst_nXS_A = pickle.load( f )\n",
    "    rRnaB_tst_nXS_A = pickle.load( f )\n",
    "    rRelated_tst_nXC_A = pickle.load( f )\n",
    "    sGeneNames_nX2_A = pickle.load( f )\n",
    "    nRs_A = pickle.load( f )\n",
    "    nSs_A = pickle.load( f )\n",
    "    print( 'AddNeuroMed data loaded from pickle.' )\n",
    "\n",
    "\n",
    "# Check the input dimensions\n",
    "assert( len( rSnpA_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_nXS_A.shape ) == 2)\n",
    "assert( len( rRelated_nXC_A.shape ) == 2 )\n",
    "assert( len( rSnpA_tr_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_tr_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_tr_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_tr_nXS_A.shape ) == 2 )\n",
    "assert( len( rRelated_tr_nXC_A.shape ) == 2 )\n",
    "assert( len( rSnpA_tst_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_tst_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_tst_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_tst_nXS_A.shape ) == 2 )\n",
    "assert( len( rRelated_tst_nXC_A.shape ) == 2)\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRnaA_nXS_A.shape[0] )\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRnaB_nXS_A.shape[0] )\n",
    "assert( rSnpB_nXSN_A.shape[ 0 ] == rRnaA_nXS_A.shape[0] )\n",
    "assert( rSnpB_nXSN_A.shape[ 0 ] == rRnaB_nXS_A.shape[0] )\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRelated_nXC_A.shape[ 0 ] )\n",
    "assert( rSnpA_nXSN_A.shape[ 1 ] == rRnaA_nXS_A.shape[ 1 ] )\n",
    "assert( rSnpB_nXSN_A.shape[ 1 ] == rRnaB_nXS_A.shape[ 1 ] )\n",
    "assert( rRelated_nXC_A.shape[ 1 ] == 3 )\n",
    "\n",
    "iSnum_A = rSnpA_nXSN_A.shape[ 1 ] # Number of subjects\n",
    "iNnum_A = rSnpA_nXSN_A.shape[ 2 ] # Number of snps\n",
    "iCnum_A = rRelated_nXC_A.shape[ 1 ] # Number of classes\n",
    "\n",
    "print('All AddNeuroMed samples loaded.' )\n",
    "print('Number of training samples (transcripts) of gene A: {}'.format( rSnpA_tr_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of training samples (transcripts) of gene B: {}'.format( rSnpB_tr_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene A: {}'.format( rSnpA_tst_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene B: {}'.format( rSnpB_tst_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of subjects iSnum: {}'.format( rSnpA_nXSN_A.shape[ 1 ] ) )\n",
    "print('Number of SNPs iNnum: {}'.format( rSnpA_nXSN_A.shape[ 2 ] ) )\n",
    "print('Number of association classes iCnum: {}'.format( rRelated_nXC_A.shape[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HBTRC data loaded from pickle.\n",
      "All HBTRC samples loaded.\n",
      "Number of training samples (transcripts) of gene A: 1500\n",
      "Number of training samples (transcripts) of gene B: 1500\n",
      "Number of test samples (transcripts) of gene A: 45\n",
      "Number of test samples (transcripts) of gene B: 45\n",
      "Number of subjects iSnum: 434\n",
      "Number of SNPs iNnum: 100\n",
      "Number of association classes iCnum: 3\n"
     ]
    }
   ],
   "source": [
    "# LOAD HBTRC DATA\n",
    "# Load data form the pickle produced by \"preprocessData_HBTRC.ipynb\"\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('../HBTRC/preprocessData_HBTRC.pickle', 'rb') as f:\n",
    "    rSnpA_nXSN_H = pickle.load( f )\n",
    "    rSnpB_nXSN_H = pickle.load( f )\n",
    "    rRnaA_nXS_H = pickle.load( f )\n",
    "    rRnaB_nXS_H = pickle.load( f )\n",
    "    rRelated_nXC_H = pickle.load( f )\n",
    "    rSnpA_tr_nXSN_H = pickle.load( f )\n",
    "    rSnpB_tr_nXSN_H = pickle.load( f )\n",
    "    rRnaA_tr_nXS_H = pickle.load( f )\n",
    "    rRnaB_tr_nXS_H = pickle.load( f )\n",
    "    rRelated_tr_nXC_H = pickle.load( f )\n",
    "    rSnpA_tst_nXSN_H = pickle.load( f )\n",
    "    rSnpB_tst_nXSN_H = pickle.load( f )\n",
    "    rRnaA_tst_nXS_H = pickle.load( f )\n",
    "    rRnaB_tst_nXS_H = pickle.load( f )\n",
    "    rRelated_tst_nXC_H = pickle.load( f )\n",
    "    sGeneNames_nX2_H = pickle.load( f )\n",
    "    nRs_H = pickle.load( f )\n",
    "    nSs_H = pickle.load( f )\n",
    "    print( 'HBTRC data loaded from pickle.' )\n",
    "\n",
    "\n",
    "# Check the input dimensions\n",
    "assert( len( rSnpA_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_nXS_H.shape ) == 2)\n",
    "assert( len( rRelated_nXC_H.shape ) == 2 )\n",
    "assert( len( rSnpA_tr_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_tr_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_tr_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_tr_nXS_H.shape ) == 2 )\n",
    "assert( len( rRelated_tr_nXC_H.shape ) == 2 )\n",
    "assert( len( rSnpA_tst_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_tst_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_tst_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_tst_nXS_H.shape ) == 2 )\n",
    "assert( len( rRelated_tst_nXC_H.shape ) == 2)\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRnaA_nXS_H.shape[0] )\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRnaB_nXS_H.shape[0] )\n",
    "assert( rSnpB_nXSN_H.shape[ 0 ] == rRnaA_nXS_H.shape[0] )\n",
    "assert( rSnpB_nXSN_H.shape[ 0 ] == rRnaB_nXS_H.shape[0] )\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRelated_nXC_H.shape[ 0 ] )\n",
    "assert( rSnpA_nXSN_H.shape[ 1 ] == rRnaA_nXS_H.shape[ 1 ] )\n",
    "assert( rSnpB_nXSN_H.shape[ 1 ] == rRnaB_nXS_H.shape[ 1 ] )\n",
    "assert( rRelated_nXC_H.shape[ 1 ] == 3 )\n",
    "\n",
    "iSnum_H = rSnpA_nXSN_H.shape[ 1 ] # Number of subjects\n",
    "iNnum_H = rSnpA_nXSN_H.shape[ 2 ] # Number of snps\n",
    "iCnum_H = rRelated_nXC_H.shape[ 1 ] # Number of classes\n",
    "\n",
    "print('All HBTRC samples loaded.' )\n",
    "print('Number of training samples (transcripts) of gene A: {}'.format( rSnpA_tr_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of training samples (transcripts) of gene B: {}'.format( rSnpB_tr_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene A: {}'.format( rSnpA_tst_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene B: {}'.format( rSnpB_tst_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of subjects iSnum: {}'.format( rSnpA_nXSN_H.shape[ 1 ] ) )\n",
    "print('Number of SNPs iNnum: {}'.format( rSnpA_nXSN_H.shape[ 2 ] ) )\n",
    "print('Number of association classes iCnum: {}'.format( rRelated_nXC_H.shape[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "## Input data\n",
    "time_steps = iNnum_A + 1                            # number of snps + number of rnas\n",
    "n_input = iSnum_A                                   # number of subjects\n",
    "\n",
    "## LSTM's internal structure\n",
    "n_hidden = 32                                       # number of nodes in hidden layer \n",
    "n_classes = iCnum_A                                 # number of classes\n",
    "n_layer = 3                                         # number of layers\n",
    "dropout = 0.5                                       # dropout percentage\n",
    "\n",
    "## Training data\n",
    "learning_rate = 0.001\n",
    "batch_size = 150\n",
    "n_epoch = 250\n",
    "n_batch = rSnpA_tr_nXSN_A.shape[0] // batch_size # number of batches\n",
    "lambda_l2_reg = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.1192009449005127: Accuracy = 0.41999998688697815\n",
      "Performance on test set: : Loss = 1.1556811332702637: Accuracy = 0.6615679084324138\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.147993803024292: Accuracy = 0.36000001430511475\n",
      "Performance on test set: : Loss = 1.1769559383392334: Accuracy = 0.634418625767411\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.1349546909332275: Accuracy = 0.3799999952316284\n",
      "Performance on test set: : Loss = 1.1283864974975586: Accuracy = 0.6313193689487061\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.075845718383789: Accuracy = 0.4533333480358124\n",
      "Performance on test set: : Loss = 1.1521117687225342: Accuracy = 0.6348470551868379\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.0326428413391113: Accuracy = 0.5\n",
      "Performance on test set: : Loss = 1.1736963987350464: Accuracy = 0.6305310143605296\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 1.0252174139022827: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.1764150857925415: Accuracy = 0.64341549260692\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 0.9748780131340027: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.1616266965866089: Accuracy = 0.6516796954292482\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 0.9542216062545776: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.1648036241531372: Accuracy = 0.660594211085961\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 0.9438701272010803: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.1426817178726196: Accuracy = 0.6691928623883245\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.9329315423965454: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.1288611888885498: Accuracy = 0.6773869476286486\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.9705473780632019: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.1509125232696533: Accuracy = 0.6857399885173956\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.8917444944381714: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.14790678024292: Accuracy = 0.6929860748666888\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.9134576320648193: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.1710524559020996: Accuracy = 0.7005063420995465\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.9382286667823792: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.1288107633590698: Accuracy = 0.706642424222037\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.9495486617088318: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.1803587675094604: Accuracy = 0.7123574624152057\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 0.9377613067626953: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.1654822826385498: Accuracy = 0.7153156914807177\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.9305462837219238: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.1324899196624756: Accuracy = 0.7195410136305842\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.9375090599060059: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.1771208047866821: Accuracy = 0.7233752583488327\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.9260359406471252: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.173239827156067: Accuracy = 0.7272288791026192\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.9168933033943176: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.1674375534057617: Accuracy = 0.7305561962012603\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.912989616394043: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.1602457761764526: Accuracy = 0.7319111829289024\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.8919109106063843: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.1532524824142456: Accuracy = 0.7341182107989384\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.8919306397438049: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.161714792251587: Accuracy = 0.735963419378366\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.9475392699241638: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.1598385572433472: Accuracy = 0.73792326161261\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.9275490045547485: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.1615355014801025: Accuracy = 0.7401321739883029\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.8922893404960632: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.1577000617980957: Accuracy = 0.7410959108593022\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.8641498684883118: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.1529266834259033: Accuracy = 0.743041905586198\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.8769268989562988: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.1367206573486328: Accuracy = 0.7449060277386503\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.9084746241569519: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.1479158401489258: Accuracy = 0.746274653002667\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.8786871433258057: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.1411216259002686: Accuracy = 0.748070774136644\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.8507688045501709: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.156314730644226: Accuracy = 0.7497877574108869\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.8796436786651611: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.180416464805603: Accuracy = 0.7512986778871479\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.8472813963890076: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.175987720489502: Accuracy = 0.75261226750753\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.9066059589385986: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.1808693408966064: Accuracy = 0.7540228136929383\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.861798882484436: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.1786236763000488: Accuracy = 0.7552152231117627\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.9095939993858337: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.1666194200515747: Accuracy = 0.7563963549382127\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.8473783731460571: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.141077995300293: Accuracy = 0.7571701441631494\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.8462058305740356: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.1642866134643555: Accuracy = 0.7581262587422566\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.8304933905601501: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.1273999214172363: Accuracy = 0.7591116908497505\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.851037323474884: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.1438987255096436: Accuracy = 0.7598274733314178\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.8213691711425781: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.1356751918792725: Accuracy = 0.7604775804124825\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.7941145300865173: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.140345811843872: Accuracy = 0.7612220749592546\n",
      "\n",
      "Data shuffled. Epoch:  42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.8401538729667664: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.1874812841415405: Accuracy = 0.7620347835227622\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.8060966730117798: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1490309238433838: Accuracy = 0.7628175675660166\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.8061252236366272: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.2130340337753296: Accuracy = 0.7636698136281292\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.8321079611778259: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1731587648391724: Accuracy = 0.764361189212388\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.8765391111373901: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.1634773015975952: Accuracy = 0.7651051487822459\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.7948993444442749: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1791192293167114: Accuracy = 0.7657569634892116\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.8283442258834839: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1538647413253784: Accuracy = 0.7663176996420644\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.8690076470375061: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.1584463119506836: Accuracy = 0.7669817149734491\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.7664938569068909: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1466537714004517: Accuracy = 0.7675672529689588\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.8287311792373657: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1515462398529053: Accuracy = 0.7682043001934182\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.7983721494674683: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.1622202396392822: Accuracy = 0.7688241938480787\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.8001044392585754: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.1805955171585083: Accuracy = 0.7694924832729679\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.8291181325912476: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.163731336593628: Accuracy = 0.7700562465512237\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.768372654914856: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1945980787277222: Accuracy = 0.7706218645058152\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.7677112817764282: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1665176153182983: Accuracy = 0.7711134818824534\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.8144119381904602: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1777201890945435: Accuracy = 0.7715062660055022\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.8002976775169373: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1456342935562134: Accuracy = 0.7719724634876118\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.7628046870231628: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1317015886306763: Accuracy = 0.7724235273576595\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.7971658110618591: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.1568713188171387: Accuracy = 0.7728310227540068\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.7943471074104309: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.18224036693573: Accuracy = 0.7731610632953485\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.8004795908927917: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.2119085788726807: Accuracy = 0.7736097750897797\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.7277858257293701: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.1669204235076904: Accuracy = 0.7740605552487492\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.7445002198219299: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.1811003684997559: Accuracy = 0.7744801823577925\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.8376088738441467: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.1333924531936646: Accuracy = 0.7749193450252575\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.759733259677887: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.172688603401184: Accuracy = 0.7753933557598215\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.7652186155319214: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1767324209213257: Accuracy = 0.775779785679446\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.7990342378616333: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1423425674438477: Accuracy = 0.7761478359170204\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.7855484485626221: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.1597044467926025: Accuracy = 0.7764715473740154\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.7725840210914612: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1483930349349976: Accuracy = 0.7768491634630033\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.777161717414856: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1544326543807983: Accuracy = 0.7771769786926045\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.7524617314338684: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1752177476882935: Accuracy = 0.7774806128809061\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.7568456530570984: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1968883275985718: Accuracy = 0.7777966225272106\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.7876349091529846: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1784937381744385: Accuracy = 0.7781204135889422\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.7926711440086365: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.2053282260894775: Accuracy = 0.7784556529447272\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.7669143676757812: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1938865184783936: Accuracy = 0.7787617304521243\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.7831432819366455: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.1663817167282104: Accuracy = 0.7790874101041574\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.739794135093689: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1406549215316772: Accuracy = 0.7793561436907976\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.7446336150169373: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1778346300125122: Accuracy = 0.7796315971568014\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.7366986274719238: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1589704751968384: Accuracy = 0.7799094202790882\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.7805063128471375: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.166732668876648: Accuracy = 0.7800975875823225\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.7303321361541748: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1815297603607178: Accuracy = 0.780342404092421\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.7809220552444458: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.151955485343933: Accuracy = 0.7805499154359316\n",
      "\n",
      "Data shuffled. Epoch:  84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.752912163734436: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.145447850227356: Accuracy = 0.7807834103228635\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.7767230272293091: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1352519989013672: Accuracy = 0.7809452826022607\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.9068183302879333: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.1392465829849243: Accuracy = 0.7811602178483692\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.8143777847290039: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.119598150253296: Accuracy = 0.7805664194531367\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.8038685917854309: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.0983573198318481: Accuracy = 0.7796887065303232\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.8563438057899475: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.1547222137451172: Accuracy = 0.7796232299280229\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.8339620232582092: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1247891187667847: Accuracy = 0.7794210541833981\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.8097720146179199: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1123396158218384: Accuracy = 0.7794233634016798\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.7697659134864807: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.119661808013916: Accuracy = 0.7794584639284199\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.8331531286239624: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.1142176389694214: Accuracy = 0.7792637242397653\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.841063380241394: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.1243093013763428: Accuracy = 0.7787858312962193\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.7881606817245483: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.09742271900177: Accuracy = 0.7787014905856179\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.7894056439399719: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.0971070528030396: Accuracy = 0.7788021312204448\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.8005857467651367: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.1210428476333618: Accuracy = 0.7787892810171764\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.7414242625236511: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.0763016939163208: Accuracy = 0.7788416591122588\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.8089627027511597: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1327126026153564: Accuracy = 0.778819155984731\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.7992749214172363: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.151648998260498: Accuracy = 0.7788697522595499\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.7209790349006653: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.118232250213623: Accuracy = 0.7789086860287097\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.7729265093803406: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.0874377489089966: Accuracy = 0.7790136906984009\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.8274636268615723: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.102049469947815: Accuracy = 0.7790868256048321\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.7487777471542358: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.1824936866760254: Accuracy = 0.7791581816791193\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.8224799036979675: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.1623364686965942: Accuracy = 0.7792750557378303\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.8064335584640503: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1479735374450684: Accuracy = 0.7794116153924256\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.7793656587600708: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1859291791915894: Accuracy = 0.7795153654614625\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.7230378985404968: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1317639350891113: Accuracy = 0.7795942805911437\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.7753698825836182: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.189823865890503: Accuracy = 0.7796675363599456\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.744290292263031: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1502314805984497: Accuracy = 0.7796709715079767\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.811968207359314: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.147705316543579: Accuracy = 0.7796892070961011\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.7564678192138672: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1224191188812256: Accuracy = 0.7797131454976446\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.7503531575202942: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1109671592712402: Accuracy = 0.7797697831502142\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.778892457485199: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.1300342082977295: Accuracy = 0.7796968434860639\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.7662580609321594: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1424978971481323: Accuracy = 0.7796093337307566\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.752025842666626: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1429628133773804: Accuracy = 0.7796319488718624\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.7405884265899658: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1144747734069824: Accuracy = 0.7796036909995767\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.7710035443305969: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.1384748220443726: Accuracy = 0.7796553798130542\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.7351791262626648: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.140683889389038: Accuracy = 0.7796533899573296\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.8192155361175537: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.134459376335144: Accuracy = 0.7795693706073713\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.7739439606666565: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1667275428771973: Accuracy = 0.7795432564655987\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.7407326698303223: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.162358283996582: Accuracy = 0.7795969544601538\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.702578604221344: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1158273220062256: Accuracy = 0.7795873652368401\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.7509280443191528: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.149525761604309: Accuracy = 0.7796183520527603\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.7414299249649048: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1772894859313965: Accuracy = 0.7797388389788465\n",
      "\n",
      "Data shuffled. Epoch:  126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.7724155783653259: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.149315595626831: Accuracy = 0.7797249905198131\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.6943260431289673: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.135230302810669: Accuracy = 0.7797162043470977\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.7609108090400696: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.141596794128418: Accuracy = 0.7797124740544832\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.7294976711273193: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.157089352607727: Accuracy = 0.7796484314740784\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.7367406487464905: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.138666033744812: Accuracy = 0.779635759535159\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.7049368023872375: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1539387702941895: Accuracy = 0.7795349449893534\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.7839426398277283: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.156900405883789: Accuracy = 0.7796527014344986\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.7687588930130005: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1389151811599731: Accuracy = 0.7795859770990107\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.7061886191368103: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1514521837234497: Accuracy = 0.7795380332578369\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.7489104270935059: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1118426322937012: Accuracy = 0.7795926738782971\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.7246151566505432: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.131751298904419: Accuracy = 0.779624799793026\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.6991146206855774: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.1588501930236816: Accuracy = 0.7795853147409548\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.7595211267471313: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.158692717552185: Accuracy = 0.7796648749691448\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.6929992437362671: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.1475838422775269: Accuracy = 0.7796169640873917\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.7571426630020142: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1230854988098145: Accuracy = 0.7795878482662403\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.7193820476531982: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.1381558179855347: Accuracy = 0.7795743876139571\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.6759138107299805: Accuracy = 0.9066666960716248\n",
      "Performance on test set: : Loss = 1.131293773651123: Accuracy = 0.779528106915269\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.768859326839447: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.1474446058273315: Accuracy = 0.7795297047111832\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.7092971205711365: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.1573678255081177: Accuracy = 0.7794875313861135\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.7138630747795105: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1423691511154175: Accuracy = 0.7795089269143685\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.7532076239585876: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1299299001693726: Accuracy = 0.7795664259867823\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.7634405493736267: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1168749332427979: Accuracy = 0.7796446782784465\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.7165560722351074: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1326515674591064: Accuracy = 0.7797313912980753\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.7310712337493896: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1341360807418823: Accuracy = 0.7796967266371342\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.6845142841339111: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 1.0957130193710327: Accuracy = 0.7797068509907198\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.7167494297027588: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1267129182815552: Accuracy = 0.7796372136417205\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.7336884140968323: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1335163116455078: Accuracy = 0.7796524109045434\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.726214587688446: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1456058025360107: Accuracy = 0.7796214172461517\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.7907968759536743: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.168189525604248: Accuracy = 0.7795560554335398\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.7012827396392822: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.117030382156372: Accuracy = 0.7795207717642463\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.7075523138046265: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1275519132614136: Accuracy = 0.779548409023132\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.71073979139328: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1443970203399658: Accuracy = 0.7794982111174958\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.6905439496040344: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 1.1287070512771606: Accuracy = 0.7795256659078775\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.7229742407798767: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1251903772354126: Accuracy = 0.7795649843468788\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.7099304795265198: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.152416706085205: Accuracy = 0.7794986803079047\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.7368104457855225: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.144784927368164: Accuracy = 0.7794859517365864\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.6775639057159424: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 1.171830415725708: Accuracy = 0.7794980356728846\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.7004227042198181: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1274141073226929: Accuracy = 0.7793929082673247\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.6994866728782654: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.1424146890640259: Accuracy = 0.7793592362163915\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.7168910503387451: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.167798399925232: Accuracy = 0.7793257983101722\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.7212661504745483: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1556757688522339: Accuracy = 0.7793193356739196\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.6938125491142273: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 1.15045166015625: Accuracy = 0.779305473575248\n",
      "\n",
      "Data shuffled. Epoch:  168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.7431504130363464: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.121247410774231: Accuracy = 0.7792676044938364\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.6905151009559631: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 1.0946621894836426: Accuracy = 0.7792396052248941\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.6979484558105469: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.0710283517837524: Accuracy = 0.7792129679081752\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.6992658972740173: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.159053921699524: Accuracy = 0.7792307070714339\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.700031578540802: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.183289647102356: Accuracy = 0.7791798965676372\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.6976912021636963: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.1483906507492065: Accuracy = 0.7791015364647411\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.6856701374053955: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 1.0770612955093384: Accuracy = 0.7789969329031509\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.7352238893508911: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.1204826831817627: Accuracy = 0.7785984973555138\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.6938398480415344: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.143402338027954: Accuracy = 0.7783126175927193\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.6961626410484314: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1776947975158691: Accuracy = 0.7779660278352963\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.7053877711296082: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1231286525726318: Accuracy = 0.7777225043148254\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.7114778161048889: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.155113697052002: Accuracy = 0.777640305961338\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.7581937313079834: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1901752948760986: Accuracy = 0.7776921686160522\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.7541916370391846: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1960923671722412: Accuracy = 0.7778242324371701\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.7224076986312866: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.192811131477356: Accuracy = 0.777935558601471\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.743261992931366: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.2417629957199097: Accuracy = 0.778070693088287\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.732048511505127: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1902819871902466: Accuracy = 0.7782042948220383\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.7664452791213989: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1934950351715088: Accuracy = 0.7783302798152708\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.7531557679176331: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1931403875350952: Accuracy = 0.7784549248242932\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.7057576775550842: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.1716911792755127: Accuracy = 0.7785839385166743\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.7892645597457886: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1927164793014526: Accuracy = 0.778702347303303\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.7040137648582458: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.192359209060669: Accuracy = 0.7788227174591803\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.7439164519309998: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.1645078659057617: Accuracy = 0.7789416555467676\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.7216264605522156: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.2179135084152222: Accuracy = 0.779059388405683\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.694995105266571: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.205409049987793: Accuracy = 0.7791667181926412\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.7005324363708496: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1855992078781128: Accuracy = 0.7792818579118198\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.7213333249092102: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.1898270845413208: Accuracy = 0.7793956478193026\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.7035647034645081: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1987351179122925: Accuracy = 0.7795083309155252\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.71942538022995: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1932942867279053: Accuracy = 0.7796020778915822\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.7142477035522461: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1979663372039795: Accuracy = 0.7797091463444761\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.7494716644287109: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1620715856552124: Accuracy = 0.77980638488442\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.7535681128501892: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1944434642791748: Accuracy = 0.779916809795513\n",
      "\n",
      "Data shuffled. Epoch:  200\n",
      "Performance on training data: Loss = 0.7601379156112671: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.2059069871902466: Accuracy = 0.7800237603081658\n",
      "\n",
      "Data shuffled. Epoch:  201\n",
      "Performance on training data: Loss = 0.760101854801178: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.2041847705841064: Accuracy = 0.780129396101662\n",
      "\n",
      "Data shuffled. Epoch:  202\n",
      "Performance on training data: Loss = 0.7327413558959961: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1931229829788208: Accuracy = 0.7802394560305576\n",
      "\n",
      "Data shuffled. Epoch:  203\n",
      "Performance on training data: Loss = 0.7281578779220581: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1744471788406372: Accuracy = 0.7803429975593094\n",
      "\n",
      "Data shuffled. Epoch:  204\n",
      "Performance on training data: Loss = 0.7374734282493591: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1918089389801025: Accuracy = 0.7804563716893006\n",
      "\n",
      "Data shuffled. Epoch:  205\n",
      "Performance on training data: Loss = 0.6974403262138367: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.196300983428955: Accuracy = 0.7805683387314861\n",
      "\n",
      "Data shuffled. Epoch:  206\n",
      "Performance on training data: Loss = 0.7156649827957153: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.1879682540893555: Accuracy = 0.7806685700529998\n",
      "\n",
      "Data shuffled. Epoch:  207\n",
      "Performance on training data: Loss = 0.7402461767196655: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.194056510925293: Accuracy = 0.780761836779269\n",
      "\n",
      "Data shuffled. Epoch:  208\n",
      "Performance on training data: Loss = 0.7784337997436523: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.223905324935913: Accuracy = 0.7808599569722036\n",
      "\n",
      "Data shuffled. Epoch:  209\n",
      "Performance on training data: Loss = 0.7270135283470154: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.2027360200881958: Accuracy = 0.7809623820856152\n",
      "\n",
      "Data shuffled. Epoch:  210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.6975954174995422: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.2079379558563232: Accuracy = 0.7810691340591325\n",
      "\n",
      "Data shuffled. Epoch:  211\n",
      "Performance on training data: Loss = 0.7062863707542419: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1859971284866333: Accuracy = 0.7811747768027072\n",
      "\n",
      "Data shuffled. Epoch:  212\n",
      "Performance on training data: Loss = 0.7243844866752625: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1866371631622314: Accuracy = 0.781266048197162\n",
      "\n",
      "Data shuffled. Epoch:  213\n",
      "Performance on training data: Loss = 0.6414548754692078: Accuracy = 0.9266666769981384\n",
      "Performance on test set: : Loss = 1.1992852687835693: Accuracy = 0.7813644595387232\n",
      "\n",
      "Data shuffled. Epoch:  214\n",
      "Performance on training data: Loss = 0.7045615911483765: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.1651508808135986: Accuracy = 0.781456739253997\n",
      "\n",
      "Data shuffled. Epoch:  215\n",
      "Performance on training data: Loss = 0.7807758450508118: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.176268219947815: Accuracy = 0.7815373362092715\n",
      "\n",
      "Data shuffled. Epoch:  216\n",
      "Performance on training data: Loss = 0.7002385258674622: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1943461894989014: Accuracy = 0.7816351264474503\n",
      "\n",
      "Data shuffled. Epoch:  217\n",
      "Performance on training data: Loss = 0.7062081098556519: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.2046668529510498: Accuracy = 0.7817298871131437\n",
      "\n",
      "Data shuffled. Epoch:  218\n",
      "Performance on training data: Loss = 0.7113503217697144: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.2058727741241455: Accuracy = 0.7818158698584017\n",
      "\n",
      "Data shuffled. Epoch:  219\n",
      "Performance on training data: Loss = 0.7128542065620422: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.199169635772705: Accuracy = 0.7819037367703526\n",
      "\n",
      "Data shuffled. Epoch:  220\n",
      "Performance on training data: Loss = 0.6848334670066833: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 1.1792389154434204: Accuracy = 0.7819957968823972\n",
      "\n",
      "Data shuffled. Epoch:  221\n",
      "Performance on training data: Loss = 0.7159513235092163: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1956756114959717: Accuracy = 0.782086943410889\n",
      "\n",
      "Data shuffled. Epoch:  222\n",
      "Performance on training data: Loss = 0.7071943283081055: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.2124080657958984: Accuracy = 0.7821822374861543\n",
      "\n",
      "Data shuffled. Epoch:  223\n",
      "Performance on training data: Loss = 0.7387709617614746: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.1881415843963623: Accuracy = 0.7822716328343009\n",
      "\n",
      "Data shuffled. Epoch:  224\n",
      "Performance on training data: Loss = 0.7183623313903809: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.1907514333724976: Accuracy = 0.7823602663526192\n",
      "\n",
      "Data shuffled. Epoch:  225\n",
      "Performance on training data: Loss = 0.7258350253105164: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.2053143978118896: Accuracy = 0.7824529392612279\n",
      "\n",
      "Data shuffled. Epoch:  226\n",
      "Performance on training data: Loss = 0.6815062165260315: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 1.178062915802002: Accuracy = 0.782544732983411\n",
      "\n",
      "Data shuffled. Epoch:  227\n",
      "Performance on training data: Loss = 0.7208492159843445: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1951944828033447: Accuracy = 0.7826356743044313\n",
      "\n",
      "Data shuffled. Epoch:  228\n",
      "Performance on training data: Loss = 0.6970819234848022: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.2088770866394043: Accuracy = 0.7827209417866335\n",
      "\n",
      "Data shuffled. Epoch:  229\n",
      "Performance on training data: Loss = 0.7103403806686401: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1812934875488281: Accuracy = 0.7827979280778038\n",
      "\n",
      "Data shuffled. Epoch:  230\n",
      "Performance on training data: Loss = 0.7250901460647583: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.198887586593628: Accuracy = 0.7828816899135387\n",
      "\n",
      "Data shuffled. Epoch:  231\n",
      "Performance on training data: Loss = 0.7027873992919922: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.1936098337173462: Accuracy = 0.7829524899789969\n",
      "\n",
      "Data shuffled. Epoch:  232\n",
      "Performance on training data: Loss = 0.6725308895111084: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 1.1909419298171997: Accuracy = 0.7830300068095404\n",
      "\n",
      "Data shuffled. Epoch:  233\n",
      "Performance on training data: Loss = 0.7078144550323486: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.197640299797058: Accuracy = 0.783106819788485\n",
      "\n",
      "Data shuffled. Epoch:  234\n",
      "Performance on training data: Loss = 0.7177780270576477: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.1965727806091309: Accuracy = 0.7831877451600118\n",
      "\n",
      "Data shuffled. Epoch:  235\n",
      "Performance on training data: Loss = 0.7147819995880127: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.214665174484253: Accuracy = 0.7832558209353625\n",
      "\n",
      "Data shuffled. Epoch:  236\n",
      "Performance on training data: Loss = 0.7178292870521545: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.174588918685913: Accuracy = 0.7833399633168978\n",
      "\n",
      "Data shuffled. Epoch:  237\n",
      "Performance on training data: Loss = 0.730437695980072: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.1814693212509155: Accuracy = 0.7834140145520372\n",
      "\n",
      "Data shuffled. Epoch:  238\n",
      "Performance on training data: Loss = 0.7344242334365845: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1774822473526: Accuracy = 0.7834921020681406\n",
      "\n",
      "Data shuffled. Epoch:  239\n",
      "Performance on training data: Loss = 0.7278501987457275: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.203095555305481: Accuracy = 0.7835649323991543\n",
      "\n",
      "Data shuffled. Epoch:  240\n",
      "Performance on training data: Loss = 0.7135816216468811: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.2003990411758423: Accuracy = 0.7836370373065451\n",
      "\n",
      "Data shuffled. Epoch:  241\n",
      "Performance on training data: Loss = 0.6889368891716003: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.169667363166809: Accuracy = 0.7837085337524472\n",
      "\n",
      "Data shuffled. Epoch:  242\n",
      "Performance on training data: Loss = 0.7284440398216248: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1875277757644653: Accuracy = 0.7837793801757366\n",
      "\n",
      "Data shuffled. Epoch:  243\n",
      "Performance on training data: Loss = 0.7407156229019165: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1901023387908936: Accuracy = 0.7838496513456261\n",
      "\n",
      "Data shuffled. Epoch:  244\n",
      "Performance on training data: Loss = 0.6767905950546265: Accuracy = 0.9066666960716248\n",
      "Performance on test set: : Loss = 1.1925294399261475: Accuracy = 0.7839238497678224\n",
      "\n",
      "Data shuffled. Epoch:  245\n",
      "Performance on training data: Loss = 0.684775710105896: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 1.1902683973312378: Accuracy = 0.7839928807916187\n",
      "\n",
      "Data shuffled. Epoch:  246\n",
      "Performance on training data: Loss = 0.7349994778633118: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.2205623388290405: Accuracy = 0.7840612639468744\n",
      "\n",
      "Data shuffled. Epoch:  247\n",
      "Performance on training data: Loss = 0.6948664784431458: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 1.1818326711654663: Accuracy = 0.784129206274138\n",
      "\n",
      "Data shuffled. Epoch:  248\n",
      "Performance on training data: Loss = 0.698489248752594: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.2016379833221436: Accuracy = 0.7841964435827717\n",
      "\n",
      "Data shuffled. Epoch:  249\n",
      "Performance on training data: Loss = 0.7210895419120789: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.2102203369140625: Accuracy = 0.7842631988617956\n",
      "\n",
      "Optimisation finished!\n"
     ]
    }
   ],
   "source": [
    "%run trainRNN_utils.py\n",
    "%run trainRNN_network_utils.py\n",
    "\n",
    "trainLosses = {}\n",
    "testLosses = {}\n",
    "F1_scores = {}\n",
    "trainAccuracy = {}\n",
    "\n",
    "# Create network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Gene A and Gene B input and output placeholders\n",
    "## Input placeholders\n",
    "with tf.variable_scope('geneA'):\n",
    "\n",
    "    rSnpRnaA_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum_A + 1, iSnum_A])\n",
    "\n",
    "    hidden_output_A, current_state_A = dynamicLSTM(rSnpRnaA_pXNS, \n",
    "                                                       n_layer, \n",
    "                                                       n_hidden, \n",
    "                                                       dropout)\n",
    "    \n",
    "    lastA = last_relevant(hidden_output_A, length(rSnpRnaA_pXNS))\n",
    "\n",
    "with tf.variable_scope('geneB'):\n",
    "\n",
    "    rSnpRnaB_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum_A + 1, iSnum_A])\n",
    "\n",
    "    hidden_output_B, current_state_B = dynamicLSTM(rSnpRnaB_pXNS, \n",
    "                                                       n_layer, \n",
    "                                                       n_hidden, \n",
    "                                                       dropout)\n",
    "    \n",
    "    lastB = last_relevant(hidden_output_B, length(rSnpRnaB_pXNS))\n",
    "\n",
    "last = tf.math.add(lastA, lastB)\n",
    "\n",
    "rRelated_pXC = tf.placeholder(tf.float32, \n",
    "                              shape = [None, iCnum_A],\n",
    "                              name = 'rRelated_pXC')  \n",
    "\n",
    "# Dense Layer\n",
    "logit = tf.layers.dense(last,\n",
    "                        units = n_classes, \n",
    "                        activation = None,\n",
    "                        kernel_regularizer=tf.contrib.layers.l2_regularizer(0.3),\n",
    "                        kernel_initializer = tf.initializers.random_normal() )\n",
    "\n",
    "prediction = tf.nn.softmax( logit )\n",
    "\n",
    "l2 = lambda_l2_reg * sum(\n",
    "    tf.nn.l2_loss(tf_var)\n",
    "        for tf_var in tf.trainable_variables()\n",
    "        if not (\"bias\" in tf_var.name))\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, \n",
    "                                                                     labels=tf.argmax(rRelated_pXC,1)) + l2)\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy; precision, and recall for f1 score\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(rRelated_pXC,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "rec, rec_op = tf.metrics.recall(labels = tf.argmax(rRelated_pXC, 1), predictions = tf.argmax(prediction, 1))\n",
    "pre, pre_op = tf.metrics.precision(labels = tf.argmax(rRelated_pXC, 1), predictions = tf.argmax(prediction, 1))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    # Train the network \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    train_f1_score = [None] * n_epoch\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    test_f1_score = []\n",
    "\n",
    "    # Reshape rSnpRnaA_tst_nXSN_H, rRnaA_tst_nXS_H,  rSnpRnaB_tst_nXSN_H, and rRnaB_tst_nXS_H before \n",
    "    # feeding it to the network ( Reason: iSnum_A = 206, iSnum_H = 434). For HBTRC data, randomly select 206\n",
    "    # subjects to align iSnum.\n",
    "    rand_iSnum = np.random.permutation(iSnum_H)[0:206] \n",
    "    rSnpA_tst_nXSN_H_2 = rSnpA_tst_nXSN_H[:, rand_iSnum, :]\n",
    "    rRnaA_tst_nXS_H_2 = rRnaA_tst_nXS_H[:, rand_iSnum]\n",
    "    rSnpB_tst_nXSN_H_2 = rSnpB_tst_nXSN_H[:, rand_iSnum, :]\n",
    "    rRnaB_tst_nXS_H_2 = rRnaB_tst_nXS_H[:, rand_iSnum]\n",
    "\n",
    "    # Reshape and retrive the merged training and test data\n",
    "    rSnpRnaA_tr_nXNS = input_reshape(rSnpA_tr_nXSN_A, rRnaA_tr_nXS_A)\n",
    "    rSnpRnaB_tr_nXNS = input_reshape(rSnpB_tr_nXSN_A, rRnaB_tr_nXS_A)\n",
    "    rSnpRnaA_tst_nXNS = input_reshape(rSnpA_tst_nXSN_H_2, rRnaA_tst_nXS_H_2)\n",
    "    rSnpRnaB_tst_nXNS = input_reshape(rSnpB_tst_nXSN_H_2, rRnaB_tst_nXS_H_2)\n",
    "\n",
    "    for epoch_idx in range(n_epoch): \n",
    "\n",
    "\n",
    "        print(\"Data shuffled.\" + \\\n",
    "              \" Epoch: \", epoch_idx)\n",
    "\n",
    "        # Shuffle classes\n",
    "        rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS = shuffle_classes(rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS)\n",
    "\n",
    "        for batch_idx in range(n_batch):\n",
    "\n",
    "            batch_rSnpRnaA_tXNS = extract_batch_size(rSnpRnaA_tr_nXNS, batch_idx, batch_size)\n",
    "            batch_rSnpRnaB_tXNS = extract_batch_size(rSnpRnaB_tr_nXNS, batch_idx, batch_size)\n",
    "            batch_rRelated_tXC = extract_batch_size(rRelated_tr_nXC_A, batch_idx, batch_size)\n",
    "\n",
    "            # Fit training data\n",
    "            opt, tr_loss, tr_acc = sess.run(\n",
    "                [optimiser, cost, accuracy], \n",
    "                feed_dict = {\n",
    "                    rSnpRnaA_pXNS: batch_rSnpRnaA_tXNS,\n",
    "                    rSnpRnaB_pXNS: batch_rSnpRnaB_tXNS,\n",
    "                    rRelated_pXC: batch_rRelated_tXC                      \n",
    "                })\n",
    "\n",
    "            tst_loss, tst_pre, _, tst_rec, _ = sess.run(\n",
    "                [cost, pre, pre_op, rec, rec_op],\n",
    "                feed_dict = {\n",
    "                    rSnpRnaA_pXNS: rSnpRnaA_tst_nXNS,\n",
    "                    rSnpRnaB_pXNS: rSnpRnaB_tst_nXNS,\n",
    "                    rRelated_pXC: rRelated_tst_nXC_H\n",
    "                    })            \n",
    "\n",
    "            if batch_idx == (n_batch - 1):\n",
    "\n",
    "                train_losses.append(tr_loss)\n",
    "                train_accuracies.append(tr_acc)\n",
    "\n",
    "                tst_f1_score = 2 * ( tst_rec * tst_pre ) / (tst_rec + tst_pre) \n",
    "\n",
    "                test_losses.append(tst_loss)\n",
    "                test_f1_score.append(tst_f1_score)\n",
    "\n",
    "        print(\"Performance on training data\" + \n",
    "             \": Loss = {}\".format(tr_loss) + \n",
    "             \": Accuracy = {}\".format( tr_acc ) )\n",
    "\n",
    "        print(\"Performance on test set: \" + \n",
    "              \": Loss = {}\".format(tst_loss) + \n",
    "              \": Accuracy = {}\".format(tst_f1_score) )\n",
    "        print(\"\")\n",
    "\n",
    "    trainLosses[dropout] = train_losses\n",
    "    testLosses[dropout] = test_losses\n",
    "    F1_scores[dropout] = test_f1_score\n",
    "print(\"Optimisation finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run trainRNN_plot_utils.py\n",
    "plot_one_input(F1_scores, trainLosses, testLosses, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved into pickle.\n"
     ]
    }
   ],
   "source": [
    "# SAVE DATA\n",
    "# Save the created samples, such tha the NNs can load them easily\n",
    "\n",
    "# Save data into Python friendly file\n",
    "import pickle\n",
    "with open('resultsEncoder_ANM_HBTRC.pickle', 'wb') as f:\n",
    "    pickle.dump( trainLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( testLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( F1_scores, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( trainAccuracy, f, pickle.HIGHEST_PROTOCOL )\n",
    "    print( 'Data saved into pickle.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
