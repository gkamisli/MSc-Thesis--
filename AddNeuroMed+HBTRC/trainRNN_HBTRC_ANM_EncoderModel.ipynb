{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Explanation\n",
    "\n",
    "**trainRNN_HBTRC_ANM_EncoderModel.ipynb:**\n",
    "<br> This notebook is to load AddNeuroMed examples from 'preprocessData.pickle', and HBTRC examples from 'preprocessData_HBTRC.pickle' and create an \"Encoder Network\". Train the network on HBTRC data set and test on AddNeuroMed data set\n",
    "\n",
    "**Variables information**:\n",
    "<br> 1) Variables in the format of xxx_A represents data from AddNeuroMed\n",
    "<br> 2) Variables in the format of xxx_H represents data from HBTRC\n",
    "\n",
    "**Processes are as follows:**\n",
    "<br> 1) Load all variables from 'preprocessData.pickle' and 'preprocessData_HBTRC.pickle'\n",
    "<br> 2) Parameter and hyperparameter assignments (location: **3rd cell**)\n",
    "<br> 3) Create LSTM cells with Dropout Wrappers for gene A and gene B (function: **dropoutWrapper** in **trainRNN_network_utils.py**)\n",
    "<br> 4) Using LSTM cells, create multi-layer dynamic model (function: **dynamicLSTM** using **length** in **trainRNN_network_utils.py**)\n",
    "<br> 5) Create a single output by using the relevants outputs of encoder models of gene A and gene B \n",
    "<br> 6) Pass the output through a **dense** layer and make prediction with **softmax**\n",
    "<br> 7) Before starting the training: concatenate rSnpG_tr_nXSN and rRnaG_nXS where G represents gene A and gene B (function: **input_reshape** in **trainRNN_utils.py**)\n",
    "<br> 8) Train the network: every epoch (i.e., iteration) shuffle the data within each class (function: **shuffle_classes** in **trainRNN_utils.py**) and train in batches (function: **extract_batch_size** in **trainRNN_utils.py**)\n",
    "<br> 9) Plot results with **plot_one_input** in **trainRNN_plot_utils.py**)\n",
    "<br> 10) Save them in \"resultsEncoder_HBTRC_ANM.pickle\" to be called when necessary\n",
    "\n",
    "**Variables created:**\n",
    "<br> 1) **trainLosses**: Train losses, dictionary, keys of (dropout)\n",
    "<br> 2) **testLosses**: Test losses, dictionary, keys of (dropout)\n",
    "<br> 3) **F1_scores**: F1_scores, dictionary, keys of (dropout)\n",
    "<br> 4) **trainAccuracy**: Train accuracy, dictionary, keys of (dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.core.debugger import set_trace #set_trace()\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[ \"CUDA_VISIBLE_DEVICES\" ] = \"3\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddNeuroMed data loaded from pickle.\n",
      "All AddNeuroMed samples loaded.\n",
      "Number of training samples (transcripts) of gene A: 1500\n",
      "Number of training samples (transcripts) of gene B: 1500\n",
      "Number of test samples (transcripts) of gene A: 45\n",
      "Number of test samples (transcripts) of gene B: 45\n",
      "Number of subjects iSnum: 206\n",
      "Number of SNPs iNnum: 100\n",
      "Number of association classes iCnum: 3\n"
     ]
    }
   ],
   "source": [
    "# LOAD AddNeuroMed DATA\n",
    "# Load data form the pickle produced by \"preprocessData.ipynb\" in AddNeuroMed folder\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('../AddNeuroMed/preprocessData.pickle', 'rb') as f:\n",
    "    rSnpA_nXSN_A = pickle.load( f )\n",
    "    rSnpB_nXSN_A = pickle.load( f )\n",
    "    rRnaA_nXS_A = pickle.load( f )\n",
    "    rRnaB_nXS_A = pickle.load( f )\n",
    "    rRelated_nXC_A = pickle.load( f )\n",
    "    rSnpA_tr_nXSN_A = pickle.load( f )\n",
    "    rSnpB_tr_nXSN_A = pickle.load( f )\n",
    "    rRnaA_tr_nXS_A = pickle.load( f )\n",
    "    rRnaB_tr_nXS_A = pickle.load( f )\n",
    "    rRelated_tr_nXC_A = pickle.load( f )\n",
    "    rSnpA_tst_nXSN_A = pickle.load( f )\n",
    "    rSnpB_tst_nXSN_A = pickle.load( f )\n",
    "    rRnaA_tst_nXS_A = pickle.load( f )\n",
    "    rRnaB_tst_nXS_A = pickle.load( f )\n",
    "    rRelated_tst_nXC_A = pickle.load( f )\n",
    "    sGeneNames_nX2_A = pickle.load( f )\n",
    "    nRs_A = pickle.load( f )\n",
    "    nSs_A = pickle.load( f )\n",
    "    print( 'AddNeuroMed data loaded from pickle.' )\n",
    "\n",
    "\n",
    "# Check the input dimensions\n",
    "assert( len( rSnpA_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_nXS_A.shape ) == 2)\n",
    "assert( len( rRelated_nXC_A.shape ) == 2 )\n",
    "assert( len( rSnpA_tr_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_tr_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_tr_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_tr_nXS_A.shape ) == 2 )\n",
    "assert( len( rRelated_tr_nXC_A.shape ) == 2 )\n",
    "assert( len( rSnpA_tst_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_tst_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_tst_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_tst_nXS_A.shape ) == 2 )\n",
    "assert( len( rRelated_tst_nXC_A.shape ) == 2)\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRnaA_nXS_A.shape[0] )\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRnaB_nXS_A.shape[0] )\n",
    "assert( rSnpB_nXSN_A.shape[ 0 ] == rRnaA_nXS_A.shape[0] )\n",
    "assert( rSnpB_nXSN_A.shape[ 0 ] == rRnaB_nXS_A.shape[0] )\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRelated_nXC_A.shape[ 0 ] )\n",
    "assert( rSnpA_nXSN_A.shape[ 1 ] == rRnaA_nXS_A.shape[ 1 ] )\n",
    "assert( rSnpB_nXSN_A.shape[ 1 ] == rRnaB_nXS_A.shape[ 1 ] )\n",
    "assert( rRelated_nXC_A.shape[ 1 ] == 3 )\n",
    "\n",
    "iSnum_A = rSnpA_nXSN_A.shape[ 1 ] # Number of subjects\n",
    "iNnum_A = rSnpA_nXSN_A.shape[ 2 ] # Number of snps\n",
    "iCnum_A = rRelated_nXC_A.shape[ 1 ] # Number of classes\n",
    "\n",
    "print('All AddNeuroMed samples loaded.' )\n",
    "print('Number of training samples (transcripts) of gene A: {}'.format( rSnpA_tr_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of training samples (transcripts) of gene B: {}'.format( rSnpB_tr_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene A: {}'.format( rSnpA_tst_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene B: {}'.format( rSnpB_tst_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of subjects iSnum: {}'.format( rSnpA_nXSN_A.shape[ 1 ] ) )\n",
    "print('Number of SNPs iNnum: {}'.format( rSnpA_nXSN_A.shape[ 2 ] ) )\n",
    "print('Number of association classes iCnum: {}'.format( rRelated_nXC_A.shape[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HBTRC data loaded from pickle.\n",
      "All HBTRC samples loaded.\n",
      "Number of training samples (transcripts) of gene A: 1500\n",
      "Number of training samples (transcripts) of gene B: 1500\n",
      "Number of test samples (transcripts) of gene A: 45\n",
      "Number of test samples (transcripts) of gene B: 45\n",
      "Number of subjects iSnum: 434\n",
      "Number of SNPs iNnum: 100\n",
      "Number of association classes iCnum: 3\n"
     ]
    }
   ],
   "source": [
    "# LOAD HBTRC DATA\n",
    "# Load data form the pickle produced by \"preprocessData_HBTRC.ipynb\"\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('../HBTRC/preprocessData_HBTRC.pickle', 'rb') as f:\n",
    "    rSnpA_nXSN_H = pickle.load( f )\n",
    "    rSnpB_nXSN_H = pickle.load( f )\n",
    "    rRnaA_nXS_H = pickle.load( f )\n",
    "    rRnaB_nXS_H = pickle.load( f )\n",
    "    rRelated_nXC_H = pickle.load( f )\n",
    "    rSnpA_tr_nXSN_H = pickle.load( f )\n",
    "    rSnpB_tr_nXSN_H = pickle.load( f )\n",
    "    rRnaA_tr_nXS_H = pickle.load( f )\n",
    "    rRnaB_tr_nXS_H = pickle.load( f )\n",
    "    rRelated_tr_nXC_H = pickle.load( f )\n",
    "    rSnpA_tst_nXSN_H = pickle.load( f )\n",
    "    rSnpB_tst_nXSN_H = pickle.load( f )\n",
    "    rRnaA_tst_nXS_H = pickle.load( f )\n",
    "    rRnaB_tst_nXS_H = pickle.load( f )\n",
    "    rRelated_tst_nXC_H = pickle.load( f )\n",
    "    sGeneNames_nX2_H = pickle.load( f )\n",
    "    nRs_H = pickle.load( f )\n",
    "    nSs_H = pickle.load( f )\n",
    "    print( 'HBTRC data loaded from pickle.' )\n",
    "\n",
    "\n",
    "# Check the input dimensions\n",
    "assert( len( rSnpA_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_nXS_H.shape ) == 2)\n",
    "assert( len( rRelated_nXC_H.shape ) == 2 )\n",
    "assert( len( rSnpA_tr_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_tr_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_tr_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_tr_nXS_H.shape ) == 2 )\n",
    "assert( len( rRelated_tr_nXC_H.shape ) == 2 )\n",
    "assert( len( rSnpA_tst_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_tst_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_tst_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_tst_nXS_H.shape ) == 2 )\n",
    "assert( len( rRelated_tst_nXC_H.shape ) == 2)\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRnaA_nXS_H.shape[0] )\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRnaB_nXS_H.shape[0] )\n",
    "assert( rSnpB_nXSN_H.shape[ 0 ] == rRnaA_nXS_H.shape[0] )\n",
    "assert( rSnpB_nXSN_H.shape[ 0 ] == rRnaB_nXS_H.shape[0] )\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRelated_nXC_H.shape[ 0 ] )\n",
    "assert( rSnpA_nXSN_H.shape[ 1 ] == rRnaA_nXS_H.shape[ 1 ] )\n",
    "assert( rSnpB_nXSN_H.shape[ 1 ] == rRnaB_nXS_H.shape[ 1 ] )\n",
    "assert( rRelated_nXC_H.shape[ 1 ] == 3 )\n",
    "\n",
    "iSnum_H = rSnpA_nXSN_H.shape[ 1 ] # Number of subjects\n",
    "iNnum_H = rSnpA_nXSN_H.shape[ 2 ] # Number of snps\n",
    "iCnum_H = rRelated_nXC_H.shape[ 1 ] # Number of classes\n",
    "\n",
    "print('All HBTRC samples loaded.' )\n",
    "print('Number of training samples (transcripts) of gene A: {}'.format( rSnpA_tr_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of training samples (transcripts) of gene B: {}'.format( rSnpB_tr_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene A: {}'.format( rSnpA_tst_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene B: {}'.format( rSnpB_tst_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of subjects iSnum: {}'.format( rSnpA_nXSN_H.shape[ 1 ] ) )\n",
    "print('Number of SNPs iNnum: {}'.format( rSnpA_nXSN_H.shape[ 2 ] ) )\n",
    "print('Number of association classes iCnum: {}'.format( rRelated_nXC_H.shape[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "## Input data\n",
    "time_steps = iNnum_A + 1                            # number of snps + number of rnas\n",
    "n_input = iSnum_A                                   # number of subjects\n",
    "\n",
    "## LSTM's internal structure\n",
    "n_hidden = 32                                       # number of nodes in hidden layer \n",
    "n_classes = iCnum_A                                 # number of classes\n",
    "n_layer = 3                                         # number of layers\n",
    "dropout = 0.5                                       # dropout percentage\n",
    "\n",
    "## Training data\n",
    "learning_rate = 0.001\n",
    "batch_size = 150\n",
    "n_epoch = 250\n",
    "n_batch = rSnpA_tr_nXSN_A.shape[0] // batch_size # number of batches\n",
    "lambda_l2_reg = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.1259554624557495: Accuracy = 0.3933333456516266\n",
      "Performance on test set: : Loss = 1.2022032737731934: Accuracy = 0.6450450328999034\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.122206449508667: Accuracy = 0.3866666555404663\n",
      "Performance on test set: : Loss = 1.1645159721374512: Accuracy = 0.6195652570854817\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.1228768825531006: Accuracy = 0.3866666555404663\n",
      "Performance on test set: : Loss = 1.1571111679077148: Accuracy = 0.6479999845474486\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.1075416803359985: Accuracy = 0.4333333373069763\n",
      "Performance on test set: : Loss = 1.1300578117370605: Accuracy = 0.6638865529479157\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.1304410696029663: Accuracy = 0.4000000059604645\n",
      "Performance on test set: : Loss = 1.1703611612319946: Accuracy = 0.6500341462976299\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 1.0998635292053223: Accuracy = 0.4533333480358124\n",
      "Performance on test set: : Loss = 1.1486241817474365: Accuracy = 0.645714284923177\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 1.105047345161438: Accuracy = 0.40666666626930237\n",
      "Performance on test set: : Loss = 1.1601204872131348: Accuracy = 0.6548886209014995\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 1.0704578161239624: Accuracy = 0.4866666793823242\n",
      "Performance on test set: : Loss = 1.0479594469070435: Accuracy = 0.6498490914961532\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 1.0552265644073486: Accuracy = 0.4866666793823242\n",
      "Performance on test set: : Loss = 1.1704909801483154: Accuracy = 0.6567107027481494\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 1.034698247909546: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.0941908359527588: Accuracy = 0.6585997986870343\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 1.0901561975479126: Accuracy = 0.41999998688697815\n",
      "Performance on test set: : Loss = 1.1253924369812012: Accuracy = 0.6648902421674627\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 1.0109256505966187: Accuracy = 0.5266666412353516\n",
      "Performance on test set: : Loss = 1.158064842224121: Accuracy = 0.6713486934751578\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.9900888800621033: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.1795740127563477: Accuracy = 0.6703910381277187\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 1.0160166025161743: Accuracy = 0.54666668176651\n",
      "Performance on test set: : Loss = 1.1139439344406128: Accuracy = 0.6684890644556698\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.9999418258666992: Accuracy = 0.5333333611488342\n",
      "Performance on test set: : Loss = 1.1363437175750732: Accuracy = 0.6699919420824964\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 1.0312590599060059: Accuracy = 0.4933333396911621\n",
      "Performance on test set: : Loss = 1.1378862857818604: Accuracy = 0.6716628588581467\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 1.0012959241867065: Accuracy = 0.5066666603088379\n",
      "Performance on test set: : Loss = 1.1654196977615356: Accuracy = 0.6713716301747255\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.9614316821098328: Accuracy = 0.5733333230018616\n",
      "Performance on test set: : Loss = 1.1504713296890259: Accuracy = 0.6707281514932613\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.9681714773178101: Accuracy = 0.5400000214576721\n",
      "Performance on test set: : Loss = 1.173507809638977: Accuracy = 0.6697871027444213\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.972978413105011: Accuracy = 0.5533333420753479\n",
      "Performance on test set: : Loss = 1.1005918979644775: Accuracy = 0.6684721227646067\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.9836428761482239: Accuracy = 0.5600000023841858\n",
      "Performance on test set: : Loss = 1.128119707107544: Accuracy = 0.669882740814561\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.9391541481018066: Accuracy = 0.5666666626930237\n",
      "Performance on test set: : Loss = 1.1566370725631714: Accuracy = 0.670211083066048\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.941297173500061: Accuracy = 0.5866666436195374\n",
      "Performance on test set: : Loss = 1.1872422695159912: Accuracy = 0.6707603500677458\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.9245032668113708: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.104416012763977: Accuracy = 0.672132365987083\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.9308671355247498: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.1562541723251343: Accuracy = 0.6737164306714488\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.9191367626190186: Accuracy = 0.6133333444595337\n",
      "Performance on test set: : Loss = 1.0895720720291138: Accuracy = 0.6744217342738849\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.9096838235855103: Accuracy = 0.6066666841506958\n",
      "Performance on test set: : Loss = 1.1673542261123657: Accuracy = 0.6764440397478603\n",
      "\n",
      "Data shuffled. Epoch:  27\n",
      "Performance on training data: Loss = 0.8875614404678345: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.1245386600494385: Accuracy = 0.6783212533999217\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.9079359173774719: Accuracy = 0.6333333253860474\n",
      "Performance on test set: : Loss = 1.0665035247802734: Accuracy = 0.6797127738197816\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.9111345410346985: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.1767687797546387: Accuracy = 0.6803729330953258\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.8909294605255127: Accuracy = 0.6399999856948853\n",
      "Performance on test set: : Loss = 1.0823874473571777: Accuracy = 0.6806981991609973\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.8836753368377686: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.1754488945007324: Accuracy = 0.6810528148439142\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.9169681072235107: Accuracy = 0.6000000238418579\n",
      "Performance on test set: : Loss = 1.1216880083084106: Accuracy = 0.6804473945470594\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.8821496367454529: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.1691350936889648: Accuracy = 0.6803772885705196\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.887833833694458: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.184903860092163: Accuracy = 0.6797772108891134\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.8765676021575928: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.175716757774353: Accuracy = 0.6796638131609686\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.8686766624450684: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.1658300161361694: Accuracy = 0.6787417155578108\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.8588674664497375: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.1072946786880493: Accuracy = 0.6782754056003863\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.8651300072669983: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.0768530368804932: Accuracy = 0.677196190575722\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.8491515517234802: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.1432408094406128: Accuracy = 0.6767232193176741\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.8590031862258911: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.1158612966537476: Accuracy = 0.6761851162163879\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.8581452369689941: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.0915855169296265: Accuracy = 0.6753866882904495\n",
      "\n",
      "Data shuffled. Epoch:  42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.8638238310813904: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.107874870300293: Accuracy = 0.6748456242489829\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.8374191522598267: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.0884966850280762: Accuracy = 0.6738347560650686\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.8486235737800598: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.108849048614502: Accuracy = 0.6731570528331172\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.856423556804657: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.0911825895309448: Accuracy = 0.6723283912985674\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.855273425579071: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.1251749992370605: Accuracy = 0.6715519564155851\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.8370760083198547: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.1069482564926147: Accuracy = 0.670804166623682\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.8858972191810608: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.1926963329315186: Accuracy = 0.6701823240728103\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.859897792339325: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.1314868927001953: Accuracy = 0.6698731815877473\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.8453185558319092: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.1158239841461182: Accuracy = 0.6691710416732346\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.7981791496276855: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1472114324569702: Accuracy = 0.6684939212043152\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.8418253064155579: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.1466410160064697: Accuracy = 0.6680247876866758\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.8396623134613037: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1828798055648804: Accuracy = 0.6667570738051647\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.8285833597183228: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.1031984090805054: Accuracy = 0.6655323380755026\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.8014726042747498: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1293100118637085: Accuracy = 0.6643693733616399\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.8687718510627747: Accuracy = 0.6866666674613953\n",
      "Performance on test set: : Loss = 1.1701840162277222: Accuracy = 0.6626805860261531\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.8530637621879578: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 1.138301134109497: Accuracy = 0.6620461851062356\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.8315115571022034: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1361719369888306: Accuracy = 0.6618502672187052\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.819146990776062: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1164218187332153: Accuracy = 0.662299286579721\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.783229410648346: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1467622518539429: Accuracy = 0.662368708259935\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.8270493745803833: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.1534428596496582: Accuracy = 0.6624173822747458\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.8193066120147705: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1491342782974243: Accuracy = 0.6625230438458811\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.8215926885604858: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.1287286281585693: Accuracy = 0.662876284596154\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.8601173758506775: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.1713095903396606: Accuracy = 0.6630864202138976\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.8065168857574463: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1341696977615356: Accuracy = 0.6631037041296216\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.8140138983726501: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1501046419143677: Accuracy = 0.6631570107808951\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.7836230397224426: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1215704679489136: Accuracy = 0.6635176898672507\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.8120623230934143: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1400561332702637: Accuracy = 0.6634559047166956\n",
      "\n",
      "Data shuffled. Epoch:  69\n",
      "Performance on training data: Loss = 0.8107709884643555: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1305123567581177: Accuracy = 0.6636948656562792\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.818905234336853: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.1271724700927734: Accuracy = 0.6642746066504216\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.780364453792572: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1449048519134521: Accuracy = 0.6652149290844651\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.7928849458694458: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.153406023979187: Accuracy = 0.6659429566535373\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.8352860808372498: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 1.1184636354446411: Accuracy = 0.6664840998324165\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.7662976980209351: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1997593641281128: Accuracy = 0.6666667108912853\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.7903048992156982: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.16353440284729: Accuracy = 0.6671186062185986\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.8380149006843567: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.145509958267212: Accuracy = 0.6673991950789504\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.7864125370979309: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.1308887004852295: Accuracy = 0.6678136660863875\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.8264616131782532: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1503130197525024: Accuracy = 0.6682480802586012\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.8084893226623535: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1939512491226196: Accuracy = 0.6686711037215103\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.7996020317077637: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.187975525856018: Accuracy = 0.6687063237886081\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.8159548044204712: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1772540807724: Accuracy = 0.6691424705885466\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.8169518113136292: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1438509225845337: Accuracy = 0.6694653042872634\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.7960830926895142: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1735093593597412: Accuracy = 0.6697660566499181\n",
      "\n",
      "Data shuffled. Epoch:  84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.7777248024940491: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.1972912549972534: Accuracy = 0.670202680368406\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.8222585320472717: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1882508993148804: Accuracy = 0.6704444176771751\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.8168025016784668: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.150322675704956: Accuracy = 0.670805943808524\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.8216304779052734: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1708128452301025: Accuracy = 0.6711595988607245\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.8205432891845703: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1891968250274658: Accuracy = 0.6713965136341359\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.7831296324729919: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.195406198501587: Accuracy = 0.6717082107847123\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.8090541362762451: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1335163116455078: Accuracy = 0.6720524116851349\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.7924443483352661: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.146160364151001: Accuracy = 0.6725600635938537\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.7905365228652954: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.1733567714691162: Accuracy = 0.6729530121110082\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.8057976961135864: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.1703439950942993: Accuracy = 0.673144547343068\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.7816441059112549: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.1443723440170288: Accuracy = 0.6734831615800286\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.7815973162651062: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1764554977416992: Accuracy = 0.6739671837880904\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.8021759390830994: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.1490261554718018: Accuracy = 0.6744281923234747\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.8130984306335449: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1234550476074219: Accuracy = 0.674842285725293\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.8040274977684021: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1918994188308716: Accuracy = 0.6751261591429231\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.8021542429924011: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.145781397819519: Accuracy = 0.6754156026005851\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.8194321393966675: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.1943074464797974: Accuracy = 0.6755805383076382\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.8180875778198242: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1574161052703857: Accuracy = 0.6756834195365379\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.8496248722076416: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.1469976902008057: Accuracy = 0.6757727151291651\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.7752056121826172: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.2170511484146118: Accuracy = 0.6760346424914256\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.7974416017532349: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.2119616270065308: Accuracy = 0.6760734963987625\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.7871186137199402: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.1899361610412598: Accuracy = 0.6761435377758821\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.8518444299697876: Accuracy = 0.7133333086967468\n",
      "Performance on test set: : Loss = 1.1931124925613403: Accuracy = 0.6763479345927426\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.7705433964729309: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1694512367248535: Accuracy = 0.6764596465124569\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.8387647271156311: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.1565816402435303: Accuracy = 0.6765924370019499\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.8025079965591431: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1509461402893066: Accuracy = 0.6766137685281203\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.8065556883811951: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.1928218603134155: Accuracy = 0.6766124714269618\n",
      "\n",
      "Data shuffled. Epoch:  111\n",
      "Performance on training data: Loss = 0.8249009847640991: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.1930426359176636: Accuracy = 0.6767408576058986\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.7588095664978027: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.149778962135315: Accuracy = 0.6770277720747107\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.852892279624939: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.1360934972763062: Accuracy = 0.6772967319873611\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.7767391204833984: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.1906969547271729: Accuracy = 0.6773401503551555\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.7680166959762573: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1867148876190186: Accuracy = 0.6776446935178305\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.7678210139274597: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1409590244293213: Accuracy = 0.6776131425570925\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.8052415251731873: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1329668760299683: Accuracy = 0.6775806157280616\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.8056695461273193: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1284891366958618: Accuracy = 0.6777623309367425\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.7644689083099365: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.2125588655471802: Accuracy = 0.677809268317186\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.8234426379203796: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.2247177362442017: Accuracy = 0.67803537676631\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.7912081480026245: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.188849925994873: Accuracy = 0.6780884466280449\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.8253269195556641: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1536380052566528: Accuracy = 0.6781521125316678\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.7788998484611511: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1720632314682007: Accuracy = 0.6781957888956203\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.7940731644630432: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.174058437347412: Accuracy = 0.6783059694845252\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.7583370208740234: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1908468008041382: Accuracy = 0.6784801735992416\n",
      "\n",
      "Data shuffled. Epoch:  126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.8073001503944397: Accuracy = 0.7333333492279053\n",
      "Performance on test set: : Loss = 1.2090662717819214: Accuracy = 0.6787283869014248\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.8352252244949341: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1847554445266724: Accuracy = 0.6787845026002162\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.7923806309700012: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.2207696437835693: Accuracy = 0.6789044953899287\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.7851802706718445: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1848504543304443: Accuracy = 0.6788016020379375\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.8291597366333008: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1934422254562378: Accuracy = 0.6787814922005831\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.7857064604759216: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1548832654953003: Accuracy = 0.6788074223607219\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.782508134841919: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.151082992553711: Accuracy = 0.6789953019269789\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.801551103591919: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.1613264083862305: Accuracy = 0.6791706217959534\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.8181418180465698: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1588375568389893: Accuracy = 0.6793701266787154\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.7774818539619446: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1933233737945557: Accuracy = 0.6795927117890778\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.7861151099205017: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.1866168975830078: Accuracy = 0.6798469247934855\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.8031295537948608: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.189388394355774: Accuracy = 0.6800883242433488\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.7437760829925537: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1597493886947632: Accuracy = 0.6803166442113263\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.7766920328140259: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.1961629390716553: Accuracy = 0.6805591606175513\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.7706274390220642: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1514276266098022: Accuracy = 0.6807471720388036\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.8336227536201477: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.1793310642242432: Accuracy = 0.6810149281741267\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.7664356827735901: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.206422209739685: Accuracy = 0.6812210437551189\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.8051632642745972: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.122254490852356: Accuracy = 0.681306517779513\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.7956655025482178: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.208705186843872: Accuracy = 0.6814582022519724\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.8123221397399902: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.160203218460083: Accuracy = 0.6815018005182449\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.782375693321228: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1311051845550537: Accuracy = 0.6815700076590823\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.8065547943115234: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.2382006645202637: Accuracy = 0.6816610751162955\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.7554931640625: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1510231494903564: Accuracy = 0.6817812871319622\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.783918023109436: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.1724302768707275: Accuracy = 0.6818301980702159\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.7339268922805786: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.1327968835830688: Accuracy = 0.6820882169298476\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.747616171836853: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1552315950393677: Accuracy = 0.6823339242095212\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.7338539361953735: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1933492422103882: Accuracy = 0.6825922814643868\n",
      "\n",
      "Data shuffled. Epoch:  153\n",
      "Performance on training data: Loss = 0.7713246941566467: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1947360038757324: Accuracy = 0.6828097828104246\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.8048368096351624: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.1697238683700562: Accuracy = 0.6830453460719851\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.8082382082939148: Accuracy = 0.7666666507720947\n",
      "Performance on test set: : Loss = 1.1532821655273438: Accuracy = 0.6832550199260999\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.7404265999794006: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.2005093097686768: Accuracy = 0.683537350957831\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.755554735660553: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1720144748687744: Accuracy = 0.683740850222847\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.7001500725746155: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1463373899459839: Accuracy = 0.683965374981659\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.7449916005134583: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1294293403625488: Accuracy = 0.6841567259740989\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.753716230392456: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.21568763256073: Accuracy = 0.6841018900548709\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.7778214812278748: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.1163843870162964: Accuracy = 0.6841668040811406\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.750775933265686: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1666048765182495: Accuracy = 0.6843026825792504\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.7772412896156311: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.1900725364685059: Accuracy = 0.6843297451274675\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.7208390831947327: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.159274935722351: Accuracy = 0.6845058123754756\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.7565116286277771: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.178194284439087: Accuracy = 0.6844948943713494\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.7847468852996826: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.1981267929077148: Accuracy = 0.6843585999607358\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.7552039623260498: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.135452151298523: Accuracy = 0.6842386442613443\n",
      "\n",
      "Data shuffled. Epoch:  168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.7913571000099182: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.240386962890625: Accuracy = 0.6841697470099187\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.7453666925430298: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.1792532205581665: Accuracy = 0.684013479833624\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.7912742495536804: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.1801756620407104: Accuracy = 0.6839644440377394\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.7584176659584045: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.2102069854736328: Accuracy = 0.6838891290541318\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.7609308362007141: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.179245114326477: Accuracy = 0.6840649656652539\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.7141004204750061: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.2027467489242554: Accuracy = 0.6842110712301679\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.7838005423545837: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.218648910522461: Accuracy = 0.6843903098617706\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.7158100008964539: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 1.1655043363571167: Accuracy = 0.6845395986116615\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.7707070112228394: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1771914958953857: Accuracy = 0.6845147927512907\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.766023576259613: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.177849292755127: Accuracy = 0.6843913734322721\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.7601432204246521: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.260068655014038: Accuracy = 0.684316246858795\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.7909417152404785: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.215460181236267: Accuracy = 0.6841163867447178\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.748224139213562: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1944146156311035: Accuracy = 0.6840031814970374\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.7905706763267517: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.1754040718078613: Accuracy = 0.6838647254777405\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.7652991414070129: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1775813102722168: Accuracy = 0.6837099256662208\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.7268942594528198: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1984825134277344: Accuracy = 0.6837286093109722\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.7957470417022705: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.2138488292694092: Accuracy = 0.6839184213294337\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.735191822052002: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.195189356803894: Accuracy = 0.6840423471301446\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.8113935589790344: Accuracy = 0.7599999904632568\n",
      "Performance on test set: : Loss = 1.1865050792694092: Accuracy = 0.6841020214836282\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.7601843476295471: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.229021430015564: Accuracy = 0.684273929787314\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.7161871194839478: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.249947190284729: Accuracy = 0.6844552897642338\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.6827796697616577: Accuracy = 0.9066666960716248\n",
      "Performance on test set: : Loss = 1.2073856592178345: Accuracy = 0.6846660722054612\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.7604424357414246: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1922898292541504: Accuracy = 0.6848308235828183\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.7574402093887329: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1744424104690552: Accuracy = 0.6850372337559956\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.7702360153198242: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.182936429977417: Accuracy = 0.6851747354988086\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.7644010186195374: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.173596739768982: Accuracy = 0.6852987748336831\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.7667099237442017: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.137805700302124: Accuracy = 0.6854511906281074\n",
      "\n",
      "Data shuffled. Epoch:  195\n",
      "Performance on training data: Loss = 0.7540280818939209: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.1588202714920044: Accuracy = 0.6856614315406891\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.7645089626312256: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.1751759052276611: Accuracy = 0.6858400375078401\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.726344883441925: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.1690295934677124: Accuracy = 0.6858639212376895\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.7437402009963989: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.2192906141281128: Accuracy = 0.6859926347928771\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.7427976727485657: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.180051565170288: Accuracy = 0.6861960581050154\n",
      "\n",
      "Data shuffled. Epoch:  200\n",
      "Performance on training data: Loss = 0.761205792427063: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.236512303352356: Accuracy = 0.686437488574216\n",
      "\n",
      "Data shuffled. Epoch:  201\n",
      "Performance on training data: Loss = 0.7169092297554016: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1975812911987305: Accuracy = 0.6865781347460812\n",
      "\n",
      "Data shuffled. Epoch:  202\n",
      "Performance on training data: Loss = 0.7329679727554321: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.189326286315918: Accuracy = 0.6868434559349008\n",
      "\n",
      "Data shuffled. Epoch:  203\n",
      "Performance on training data: Loss = 0.772479236125946: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.189527153968811: Accuracy = 0.6870380545009489\n",
      "\n",
      "Data shuffled. Epoch:  204\n",
      "Performance on training data: Loss = 0.7619812488555908: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.2163199186325073: Accuracy = 0.6872581105273443\n",
      "\n",
      "Data shuffled. Epoch:  205\n",
      "Performance on training data: Loss = 0.7534921765327454: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1890010833740234: Accuracy = 0.6873689518070905\n",
      "\n",
      "Data shuffled. Epoch:  206\n",
      "Performance on training data: Loss = 0.7627654075622559: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1953662633895874: Accuracy = 0.687568960049634\n",
      "\n",
      "Data shuffled. Epoch:  207\n",
      "Performance on training data: Loss = 0.7604143023490906: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.2151546478271484: Accuracy = 0.6877545887384625\n",
      "\n",
      "Data shuffled. Epoch:  208\n",
      "Performance on training data: Loss = 0.7488526105880737: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.2983765602111816: Accuracy = 0.6879009096955228\n",
      "\n",
      "Data shuffled. Epoch:  209\n",
      "Performance on training data: Loss = 0.7326854467391968: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.2050517797470093: Accuracy = 0.6879457110650208\n",
      "\n",
      "Data shuffled. Epoch:  210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.7454568147659302: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.174187183380127: Accuracy = 0.6879848906029308\n",
      "\n",
      "Data shuffled. Epoch:  211\n",
      "Performance on training data: Loss = 0.7357878684997559: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1425679922103882: Accuracy = 0.6880230451486996\n",
      "\n",
      "Data shuffled. Epoch:  212\n",
      "Performance on training data: Loss = 0.775628924369812: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.2064142227172852: Accuracy = 0.6882675895244607\n",
      "\n",
      "Data shuffled. Epoch:  213\n",
      "Performance on training data: Loss = 0.6981686353683472: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.1922658681869507: Accuracy = 0.688342731072112\n",
      "\n",
      "Data shuffled. Epoch:  214\n",
      "Performance on training data: Loss = 0.773043692111969: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.17876136302948: Accuracy = 0.6884608080932006\n",
      "\n",
      "Data shuffled. Epoch:  215\n",
      "Performance on training data: Loss = 0.766091525554657: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1380115747451782: Accuracy = 0.6885184867575584\n",
      "\n",
      "Data shuffled. Epoch:  216\n",
      "Performance on training data: Loss = 0.7115809321403503: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.1713976860046387: Accuracy = 0.6886602425327076\n",
      "\n",
      "Data shuffled. Epoch:  217\n",
      "Performance on training data: Loss = 0.7215241193771362: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.2284034490585327: Accuracy = 0.6887901559614575\n",
      "\n",
      "Data shuffled. Epoch:  218\n",
      "Performance on training data: Loss = 0.7365408539772034: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1807628870010376: Accuracy = 0.688872637141474\n",
      "\n",
      "Data shuffled. Epoch:  219\n",
      "Performance on training data: Loss = 0.746414840221405: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.205578327178955: Accuracy = 0.6889222090804076\n",
      "\n",
      "Data shuffled. Epoch:  220\n",
      "Performance on training data: Loss = 0.7203364968299866: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.197725534439087: Accuracy = 0.6889888585634322\n",
      "\n",
      "Data shuffled. Epoch:  221\n",
      "Performance on training data: Loss = 0.7524048089981079: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 1.149057149887085: Accuracy = 0.6890067436307998\n",
      "\n",
      "Data shuffled. Epoch:  222\n",
      "Performance on training data: Loss = 0.7336888909339905: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1554237604141235: Accuracy = 0.6891029573175804\n",
      "\n",
      "Data shuffled. Epoch:  223\n",
      "Performance on training data: Loss = 0.7285628914833069: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1805381774902344: Accuracy = 0.6892537109901786\n",
      "\n",
      "Data shuffled. Epoch:  224\n",
      "Performance on training data: Loss = 0.7276740074157715: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.2151544094085693: Accuracy = 0.6893809188095328\n",
      "\n",
      "Data shuffled. Epoch:  225\n",
      "Performance on training data: Loss = 0.7053378820419312: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1625710725784302: Accuracy = 0.689537467510774\n",
      "\n",
      "Data shuffled. Epoch:  226\n",
      "Performance on training data: Loss = 0.7352322340011597: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1539785861968994: Accuracy = 0.6896931081911765\n",
      "\n",
      "Data shuffled. Epoch:  227\n",
      "Performance on training data: Loss = 0.7871667742729187: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.2015399932861328: Accuracy = 0.689867584522213\n",
      "\n",
      "Data shuffled. Epoch:  228\n",
      "Performance on training data: Loss = 0.7296550869941711: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 1.1675909757614136: Accuracy = 0.6900508976059421\n",
      "\n",
      "Data shuffled. Epoch:  229\n",
      "Performance on training data: Loss = 0.732009768486023: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 1.217712163925171: Accuracy = 0.6901461321281185\n",
      "\n",
      "Data shuffled. Epoch:  230\n",
      "Performance on training data: Loss = 0.7273471355438232: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1374515295028687: Accuracy = 0.690261445606379\n",
      "\n",
      "Data shuffled. Epoch:  231\n",
      "Performance on training data: Loss = 0.7775687575340271: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.2054873704910278: Accuracy = 0.6903751531638833\n",
      "\n",
      "Data shuffled. Epoch:  232\n",
      "Performance on training data: Loss = 0.7059502005577087: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.1803990602493286: Accuracy = 0.690429121767246\n",
      "\n",
      "Data shuffled. Epoch:  233\n",
      "Performance on training data: Loss = 0.721825361251831: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 1.1869937181472778: Accuracy = 0.6904438064874494\n",
      "\n",
      "Data shuffled. Epoch:  234\n",
      "Performance on training data: Loss = 0.7678160667419434: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.230468988418579: Accuracy = 0.6905609310735272\n",
      "\n",
      "Data shuffled. Epoch:  235\n",
      "Performance on training data: Loss = 0.7321521639823914: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1737942695617676: Accuracy = 0.6906179604366589\n",
      "\n",
      "Data shuffled. Epoch:  236\n",
      "Performance on training data: Loss = 0.7358935475349426: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.1781977415084839: Accuracy = 0.6906760940232003\n",
      "\n",
      "Data shuffled. Epoch:  237\n",
      "Performance on training data: Loss = 0.7817752361297607: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.165575385093689: Accuracy = 0.6907899854206735\n",
      "\n",
      "Data shuffled. Epoch:  238\n",
      "Performance on training data: Loss = 0.7560715079307556: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.2186131477355957: Accuracy = 0.6909318261004219\n",
      "\n",
      "Data shuffled. Epoch:  239\n",
      "Performance on training data: Loss = 0.7174875736236572: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.2358406782150269: Accuracy = 0.6908915850808671\n",
      "\n",
      "Data shuffled. Epoch:  240\n",
      "Performance on training data: Loss = 0.760755717754364: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 1.217187523841858: Accuracy = 0.6909128310557754\n",
      "\n",
      "Data shuffled. Epoch:  241\n",
      "Performance on training data: Loss = 0.7753140330314636: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.2109044790267944: Accuracy = 0.6909573502527153\n",
      "\n",
      "Data shuffled. Epoch:  242\n",
      "Performance on training data: Loss = 0.7594465017318726: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 1.1993649005889893: Accuracy = 0.6910586809786081\n",
      "\n",
      "Data shuffled. Epoch:  243\n",
      "Performance on training data: Loss = 0.7094718217849731: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.1738659143447876: Accuracy = 0.6911823962367344\n",
      "\n",
      "Data shuffled. Epoch:  244\n",
      "Performance on training data: Loss = 0.7502129673957825: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1654529571533203: Accuracy = 0.6913045317798344\n",
      "\n",
      "Data shuffled. Epoch:  245\n",
      "Performance on training data: Loss = 0.7913703322410583: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 1.2068045139312744: Accuracy = 0.6913279986433672\n",
      "\n",
      "Data shuffled. Epoch:  246\n",
      "Performance on training data: Loss = 0.7716206908226013: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 1.1930164098739624: Accuracy = 0.6913517324121411\n",
      "\n",
      "Data shuffled. Epoch:  247\n",
      "Performance on training data: Loss = 0.7024774551391602: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.192657709121704: Accuracy = 0.69114082388344\n",
      "\n",
      "Data shuffled. Epoch:  248\n",
      "Performance on training data: Loss = 0.7571600675582886: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 1.1511844396591187: Accuracy = 0.6910464950422001\n",
      "\n",
      "Data shuffled. Epoch:  249\n",
      "Performance on training data: Loss = 0.71845543384552: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.2561142444610596: Accuracy = 0.6910397945157043\n",
      "\n",
      "Optimisation finished!\n"
     ]
    }
   ],
   "source": [
    "%run trainRNN_utils.py\n",
    "%run trainRNN_network_utils.py\n",
    "\n",
    "trainLosses = {}\n",
    "testLosses = {}\n",
    "F1_scores = {}\n",
    "trainAccuracy = {}\n",
    "\n",
    "# Create network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Gene A and Gene B input and output placeholders\n",
    "## Input placeholders\n",
    "with tf.variable_scope('geneA'):\n",
    "\n",
    "    rSnpRnaA_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum_A + 1, iSnum_A])\n",
    "\n",
    "    hidden_output_A, current_state_A = dynamicLSTM(rSnpRnaA_pXNS, \n",
    "                                                       n_layer, \n",
    "                                                       n_hidden, \n",
    "                                                       dropout)\n",
    "    \n",
    "    lastA = last_relevant(hidden_output_A, length(rSnpRnaA_pXNS))\n",
    "\n",
    "with tf.variable_scope('geneB'):\n",
    "\n",
    "    rSnpRnaB_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum_A + 1, iSnum_A])\n",
    "\n",
    "    hidden_output_B, current_state_B = dynamicLSTM(rSnpRnaB_pXNS, \n",
    "                                                       n_layer, \n",
    "                                                       n_hidden, \n",
    "                                                       dropout)\n",
    "    \n",
    "    lastB = last_relevant(hidden_output_B, length(rSnpRnaB_pXNS))\n",
    "\n",
    "last = tf.math.add(lastA, lastB)\n",
    "\n",
    "rRelated_pXC = tf.placeholder(tf.float32, \n",
    "                              shape = [None, iCnum_A],\n",
    "                              name = 'rRelated_pXC')  \n",
    "\n",
    "# Dense Layer\n",
    "logit = tf.layers.dense(last,\n",
    "                        units = n_classes, \n",
    "                        activation = None,\n",
    "                        kernel_regularizer=tf.contrib.layers.l2_regularizer(0.3),\n",
    "                        kernel_initializer = tf.initializers.random_normal() )\n",
    "\n",
    "prediction = tf.nn.softmax( logit )\n",
    "\n",
    "l2 = lambda_l2_reg * sum(\n",
    "    tf.nn.l2_loss(tf_var)\n",
    "        for tf_var in tf.trainable_variables()\n",
    "        if not (\"bias\" in tf_var.name))\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, \n",
    "                                                                     labels=tf.argmax(rRelated_pXC,1)) + l2)\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy; precision, and recall for f1 score\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(rRelated_pXC,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "rec, rec_op = tf.metrics.recall(labels = tf.argmax(rRelated_pXC, 1), predictions = tf.argmax(prediction, 1))\n",
    "pre, pre_op = tf.metrics.precision(labels = tf.argmax(rRelated_pXC, 1), predictions = tf.argmax(prediction, 1))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    # Train the network \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    train_f1_score = [None] * n_epoch\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    test_f1_score = []\n",
    "\n",
    "    # Reshape rSnpRnaA_tst_nXSN_H, rRnaA_tst_nXS_H,  rSnpRnaB_tst_nXSN_H, and rRnaB_tst_nXS_H before \n",
    "    # feeding it to the network ( Reason: iSnum_A = 206, iSnum_H = 434). For HBTRC data, randomly select 206\n",
    "    # subjects to align iSnum.\n",
    "    rand_iSnum = np.random.permutation(iSnum_H)[0:206] \n",
    "    rSnpA_tr_nXSN_H_2 = rSnpA_tr_nXSN_H[:, rand_iSnum, :]\n",
    "    rRnaA_tr_nXS_H_2 = rRnaA_tr_nXS_H[:, rand_iSnum]\n",
    "    rSnpB_tr_nXSN_H_2 = rSnpB_tr_nXSN_H[:, rand_iSnum, :]\n",
    "    rRnaB_tr_nXS_H_2 = rRnaB_tr_nXS_H[:, rand_iSnum]\n",
    "\n",
    "    # Reshape and retrive the merged training and test data\n",
    "    rSnpRnaA_tr_nXNS = input_reshape(rSnpA_tr_nXSN_H_2, rRnaA_tr_nXS_H_2)\n",
    "    rSnpRnaB_tr_nXNS = input_reshape(rSnpB_tr_nXSN_H_2, rRnaB_tr_nXS_H_2)\n",
    "    rSnpRnaA_tst_nXNS = input_reshape(rSnpA_tst_nXSN_A, rRnaA_tst_nXS_A)\n",
    "    rSnpRnaB_tst_nXNS = input_reshape(rSnpB_tst_nXSN_A, rRnaB_tst_nXS_A)\n",
    "\n",
    "    for epoch_idx in range(n_epoch): \n",
    "\n",
    "\n",
    "        print(\"Data shuffled.\" + \\\n",
    "              \" Epoch: \", epoch_idx)\n",
    "\n",
    "        # Shuffle classes\n",
    "        rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS = shuffle_classes(rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS)\n",
    "\n",
    "        for batch_idx in range(n_batch):\n",
    "\n",
    "            batch_rSnpRnaA_tXNS = extract_batch_size(rSnpRnaA_tr_nXNS, batch_idx, batch_size)\n",
    "            batch_rSnpRnaB_tXNS = extract_batch_size(rSnpRnaB_tr_nXNS, batch_idx, batch_size)\n",
    "            batch_rRelated_tXC = extract_batch_size(rRelated_tr_nXC_H, batch_idx, batch_size)\n",
    "\n",
    "            # Fit training data\n",
    "            opt, tr_loss, tr_acc = sess.run(\n",
    "                [optimiser, cost, accuracy], \n",
    "                feed_dict = {\n",
    "                    rSnpRnaA_pXNS: batch_rSnpRnaA_tXNS,\n",
    "                    rSnpRnaB_pXNS: batch_rSnpRnaB_tXNS,\n",
    "                    rRelated_pXC: batch_rRelated_tXC                      \n",
    "                })\n",
    "\n",
    "            tst_loss, tst_pre, _, tst_rec, _ = sess.run(\n",
    "                [cost, pre, pre_op, rec, rec_op],\n",
    "                feed_dict = {\n",
    "                    rSnpRnaA_pXNS: rSnpRnaA_tst_nXNS,\n",
    "                    rSnpRnaB_pXNS: rSnpRnaB_tst_nXNS,\n",
    "                    rRelated_pXC: rRelated_tst_nXC_A\n",
    "                    })            \n",
    "\n",
    "            if batch_idx == (n_batch - 1):\n",
    "\n",
    "                train_losses.append(tr_loss)\n",
    "                train_accuracies.append(tr_acc)\n",
    "\n",
    "                tst_f1_score = 2 * ( tst_rec * tst_pre ) / (tst_rec + tst_pre) \n",
    "\n",
    "                test_losses.append(tst_loss)\n",
    "                test_f1_score.append(tst_f1_score)\n",
    "\n",
    "        print(\"Performance on training data\" + \n",
    "             \": Loss = {}\".format(tr_loss) + \n",
    "             \": Accuracy = {}\".format( tr_acc ) )\n",
    "\n",
    "        print(\"Performance on test set: \" + \n",
    "              \": Loss = {}\".format(tst_loss) + \n",
    "              \": Accuracy = {}\".format(tst_f1_score) )\n",
    "        print(\"\")\n",
    "\n",
    "    trainLosses[dropout] = train_losses\n",
    "    testLosses[dropout] = test_losses\n",
    "    F1_scores[dropout] = test_f1_score\n",
    "print(\"Optimisation finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run trainRNN_plot_utils.py\n",
    "plot_one_input(F1_scores, trainLosses, testLosses, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved into pickle.\n"
     ]
    }
   ],
   "source": [
    "# SAVE DATA\n",
    "# Save the created samples, such tha the NNs can load them easily\n",
    "\n",
    "# Save data into Python friendly file\n",
    "import pickle\n",
    "with open('resultsEncoder_HBTRC_ANM.pickle', 'wb') as f:\n",
    "    pickle.dump( trainLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( testLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( F1_scores, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( trainAccuracy, f, pickle.HIGHEST_PROTOCOL )\n",
    "    print( 'Data saved into pickle.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
