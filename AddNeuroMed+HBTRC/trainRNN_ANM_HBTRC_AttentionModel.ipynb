{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Explanation\n",
    "\n",
    "**trainRNN_ANM_HBTRC_AttentionModel.ipynb:**\n",
    "<br> This notebook is to load AddNeuroMed examples from 'preprocessData.pickle', and HBTRC examples from 'preprocessData_HBTRC.pickle' and create an \"Attention Network\". Train the network on AddNeuroMed data set and test on HBTRC data set\n",
    "\n",
    "**Variables information**:\n",
    "<br> 1) Variables in the format of xxx_A represents data from AddNeuroMed\n",
    "<br> 2) Variables in the format of xxx_H represents data from HBTRC\n",
    "\n",
    "**Processes are as follows:**\n",
    "<br> 1) Load all variables from 'preprocessData.pickle' and 'preprocessData_HBTRC.pickle'\n",
    "<br> 2) Parameter and hyperparameter assignments (location: **3rd cell**)\n",
    "<br> 3) Create LSTM cells with Dropout Wrappers for gene A and gene B (function: **dropoutWrapper** in **trainRNN_network_utils.py**)\n",
    "<br> 4) Using LSTM cells, create multi-layer dynamic model from fixed length sequences (function: **dynamicLSTM_Attention** in **trainRNN_network_utils.py**)\n",
    "<br> 5) Create an attention mechanism based on a fully-connected layer of states and output, which is followed by a tanh layer to calculate score. Then, calculate attention weights and context vector using softmax and dense layers \n",
    "<br> 6) Create a single output from a concatenation of context vectors of gene A and gene B\n",
    "<br> 7) Pass the output through a **dense** layer and make prediction\n",
    "<br> 8) Before starting the training: concatenate rSnpG_tr_nXSN and rRnaG_nXS where G represents gene A and gene B (function: **input_reshape** in **trainRNN_utils.py**)\n",
    "<br> 9) Train the network: every epoch (i.e., iteration) shuffle the data within each class (function: **shuffle_classes** in **trainRNN_utils.py**) and train in batches (function: **extract_batch_size** in **trainRNN_utils.py**)\n",
    "<br> 10) Plot results with **plot_one_input** in **trainRNN_plot_utils.py**)\n",
    "<br> 11) Save them in \"resultsAttention_ANM_HBTRC.pickle\" to be called when necessary\n",
    "\n",
    "**Variables created:**\n",
    "<br> 1) **trainLosses**: Train losses, dictionary, keys of (dropout)\n",
    "<br> 2) **testLosses**: Test losses, dictionary, keys of (dropout)\n",
    "<br> 3) **F1_scores**: F1_scores, dictionary, keys of (dropout)\n",
    "<br> 4) **trainAccuracy**: Train accuracy, dictionary, keys of (dropout)\n",
    "<br> 5) **attention_matrixA**: Attention weights of gene A, dictionary, keys of (dropout)\n",
    "<br> 6) **attention_matrixB**: Attention weights of gene B, dictionary, keys of (dropout)\n",
    "<br> 7) **tst_prediction**: Test predictions, dictionary, keys of (dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.core.debugger import set_trace\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[ \"CUDA_VISIBLE_DEVICES\" ] = \"3\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddNeuroMed data loaded from pickle.\n",
      "All AddNeuroMed samples loaded.\n",
      "Number of training samples (transcripts) of gene A: 1500\n",
      "Number of training samples (transcripts) of gene B: 1500\n",
      "Number of test samples (transcripts) of gene A: 45\n",
      "Number of test samples (transcripts) of gene B: 45\n",
      "Number of subjects iSnum: 206\n",
      "Number of SNPs iNnum: 100\n",
      "Number of association classes iCnum: 3\n"
     ]
    }
   ],
   "source": [
    "# LOAD AddNeuroMed DATA\n",
    "# Load data form the pickle produced by \"preprocessData.ipynb\" in AddNeuroMed folder\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('../AddNeuroMed/preprocessData.pickle', 'rb') as f:\n",
    "    rSnpA_nXSN_A = pickle.load( f )\n",
    "    rSnpB_nXSN_A = pickle.load( f )\n",
    "    rRnaA_nXS_A = pickle.load( f )\n",
    "    rRnaB_nXS_A = pickle.load( f )\n",
    "    rRelated_nXC_A = pickle.load( f )\n",
    "    rSnpA_tr_nXSN_A = pickle.load( f )\n",
    "    rSnpB_tr_nXSN_A = pickle.load( f )\n",
    "    rRnaA_tr_nXS_A = pickle.load( f )\n",
    "    rRnaB_tr_nXS_A = pickle.load( f )\n",
    "    rRelated_tr_nXC_A = pickle.load( f )\n",
    "    rSnpA_tst_nXSN_A = pickle.load( f )\n",
    "    rSnpB_tst_nXSN_A = pickle.load( f )\n",
    "    rRnaA_tst_nXS_A = pickle.load( f )\n",
    "    rRnaB_tst_nXS_A = pickle.load( f )\n",
    "    rRelated_tst_nXC_A = pickle.load( f )\n",
    "    sGeneNames_nX2_A = pickle.load( f )\n",
    "    nRs_A = pickle.load( f )\n",
    "    nSs_A = pickle.load( f )\n",
    "    print( 'AddNeuroMed data loaded from pickle.' )\n",
    "\n",
    "\n",
    "# Check the input dimensions\n",
    "assert( len( rSnpA_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_nXS_A.shape ) == 2)\n",
    "assert( len( rRelated_nXC_A.shape ) == 2 )\n",
    "assert( len( rSnpA_tr_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_tr_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_tr_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_tr_nXS_A.shape ) == 2 )\n",
    "assert( len( rRelated_tr_nXC_A.shape ) == 2 )\n",
    "assert( len( rSnpA_tst_nXSN_A.shape ) == 3 )\n",
    "assert( len( rSnpB_tst_nXSN_A.shape ) == 3 )\n",
    "assert( len( rRnaA_tst_nXS_A.shape ) == 2 )\n",
    "assert( len( rRnaB_tst_nXS_A.shape ) == 2 )\n",
    "assert( len( rRelated_tst_nXC_A.shape ) == 2)\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRnaA_nXS_A.shape[0] )\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRnaB_nXS_A.shape[0] )\n",
    "assert( rSnpB_nXSN_A.shape[ 0 ] == rRnaA_nXS_A.shape[0] )\n",
    "assert( rSnpB_nXSN_A.shape[ 0 ] == rRnaB_nXS_A.shape[0] )\n",
    "assert( rSnpA_nXSN_A.shape[ 0 ] == rRelated_nXC_A.shape[ 0 ] )\n",
    "assert( rSnpA_nXSN_A.shape[ 1 ] == rRnaA_nXS_A.shape[ 1 ] )\n",
    "assert( rSnpB_nXSN_A.shape[ 1 ] == rRnaB_nXS_A.shape[ 1 ] )\n",
    "assert( rRelated_nXC_A.shape[ 1 ] == 3 )\n",
    "\n",
    "iSnum_A = rSnpA_nXSN_A.shape[ 1 ] # Number of subjects\n",
    "iNnum_A = rSnpA_nXSN_A.shape[ 2 ] # Number of snps\n",
    "iCnum_A = rRelated_nXC_A.shape[ 1 ] # Number of classes\n",
    "\n",
    "print('All AddNeuroMed samples loaded.' )\n",
    "print('Number of training samples (transcripts) of gene A: {}'.format( rSnpA_tr_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of training samples (transcripts) of gene B: {}'.format( rSnpB_tr_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene A: {}'.format( rSnpA_tst_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene B: {}'.format( rSnpB_tst_nXSN_A.shape[ 0 ] ) )\n",
    "print('Number of subjects iSnum: {}'.format( rSnpA_nXSN_A.shape[ 1 ] ) )\n",
    "print('Number of SNPs iNnum: {}'.format( rSnpA_nXSN_A.shape[ 2 ] ) )\n",
    "print('Number of association classes iCnum: {}'.format( rRelated_nXC_A.shape[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HBTRC data loaded from pickle.\n",
      "All HBTRC samples loaded.\n",
      "Number of training samples (transcripts) of gene A: 1500\n",
      "Number of training samples (transcripts) of gene B: 1500\n",
      "Number of test samples (transcripts) of gene A: 45\n",
      "Number of test samples (transcripts) of gene B: 45\n",
      "Number of subjects iSnum: 434\n",
      "Number of SNPs iNnum: 100\n",
      "Number of association classes iCnum: 3\n"
     ]
    }
   ],
   "source": [
    "# LOAD HBTRC DATA\n",
    "# Load data form the pickle produced by \"preprocessData_HBTRC.ipynb\"\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('../HBTRC/preprocessData_HBTRC.pickle', 'rb') as f:\n",
    "    rSnpA_nXSN_H = pickle.load( f )\n",
    "    rSnpB_nXSN_H = pickle.load( f )\n",
    "    rRnaA_nXS_H = pickle.load( f )\n",
    "    rRnaB_nXS_H = pickle.load( f )\n",
    "    rRelated_nXC_H = pickle.load( f )\n",
    "    rSnpA_tr_nXSN_H = pickle.load( f )\n",
    "    rSnpB_tr_nXSN_H = pickle.load( f )\n",
    "    rRnaA_tr_nXS_H = pickle.load( f )\n",
    "    rRnaB_tr_nXS_H = pickle.load( f )\n",
    "    rRelated_tr_nXC_H = pickle.load( f )\n",
    "    rSnpA_tst_nXSN_H = pickle.load( f )\n",
    "    rSnpB_tst_nXSN_H = pickle.load( f )\n",
    "    rRnaA_tst_nXS_H = pickle.load( f )\n",
    "    rRnaB_tst_nXS_H = pickle.load( f )\n",
    "    rRelated_tst_nXC_H = pickle.load( f )\n",
    "    sGeneNames_nX2_H = pickle.load( f )\n",
    "    nRs_H = pickle.load( f )\n",
    "    nSs_H = pickle.load( f )\n",
    "    print( 'HBTRC data loaded from pickle.' )\n",
    "\n",
    "\n",
    "# Check the input dimensions\n",
    "assert( len( rSnpA_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_nXS_H.shape ) == 2)\n",
    "assert( len( rRelated_nXC_H.shape ) == 2 )\n",
    "assert( len( rSnpA_tr_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_tr_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_tr_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_tr_nXS_H.shape ) == 2 )\n",
    "assert( len( rRelated_tr_nXC_H.shape ) == 2 )\n",
    "assert( len( rSnpA_tst_nXSN_H.shape ) == 3 )\n",
    "assert( len( rSnpB_tst_nXSN_H.shape ) == 3 )\n",
    "assert( len( rRnaA_tst_nXS_H.shape ) == 2 )\n",
    "assert( len( rRnaB_tst_nXS_H.shape ) == 2 )\n",
    "assert( len( rRelated_tst_nXC_H.shape ) == 2)\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRnaA_nXS_H.shape[0] )\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRnaB_nXS_H.shape[0] )\n",
    "assert( rSnpB_nXSN_H.shape[ 0 ] == rRnaA_nXS_H.shape[0] )\n",
    "assert( rSnpB_nXSN_H.shape[ 0 ] == rRnaB_nXS_H.shape[0] )\n",
    "assert( rSnpA_nXSN_H.shape[ 0 ] == rRelated_nXC_H.shape[ 0 ] )\n",
    "assert( rSnpA_nXSN_H.shape[ 1 ] == rRnaA_nXS_H.shape[ 1 ] )\n",
    "assert( rSnpB_nXSN_H.shape[ 1 ] == rRnaB_nXS_H.shape[ 1 ] )\n",
    "assert( rRelated_nXC_H.shape[ 1 ] == 3 )\n",
    "\n",
    "iSnum_H = rSnpA_nXSN_H.shape[ 1 ] # Number of subjects\n",
    "iNnum_H = rSnpA_nXSN_H.shape[ 2 ] # Number of snps\n",
    "iCnum_H = rRelated_nXC_H.shape[ 1 ] # Number of classes\n",
    "\n",
    "print('All HBTRC samples loaded.' )\n",
    "print('Number of training samples (transcripts) of gene A: {}'.format( rSnpA_tr_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of training samples (transcripts) of gene B: {}'.format( rSnpB_tr_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene A: {}'.format( rSnpA_tst_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of test samples (transcripts) of gene B: {}'.format( rSnpB_tst_nXSN_H.shape[ 0 ] ) )\n",
    "print('Number of subjects iSnum: {}'.format( rSnpA_nXSN_H.shape[ 1 ] ) )\n",
    "print('Number of SNPs iNnum: {}'.format( rSnpA_nXSN_H.shape[ 2 ] ) )\n",
    "print('Number of association classes iCnum: {}'.format( rRelated_nXC_H.shape[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "## Input data\n",
    "time_steps = iNnum_A + 1                            # number of snps + number of rnas\n",
    "n_input = iSnum_A                                   # number of subjects\n",
    "\n",
    "## LSTM's internal structure\n",
    "n_hidden = 32                                       # number of nodes in hidden layer \n",
    "n_classes = iCnum_A                                 # number of classes\n",
    "n_layer = 3                                         # number of layers\n",
    "dropout = 0.5                                       # dropout percentage\n",
    "\n",
    "## Training data\n",
    "learning_rate = 0.001\n",
    "batch_size = 150\n",
    "n_epoch = 250\n",
    "n_batch = rSnpA_tr_nXSN_A.shape[0] // batch_size # number of batches\n",
    "lambda_l2_reg = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/AddNeuroMed+HBTRC/trainRNN_network_utils.py:15: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/AddNeuroMed+HBTRC/trainRNN_network_utils.py:70: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/AddNeuroMed+HBTRC/trainRNN_network_utils.py:74: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/gulkamisli/Google Drive /Oxford/MSc Dissertation 2019/MSc_Dissertation2019_1019089/Source Code/AddNeuroMed+HBTRC/trainRNN_network_utils.py:99: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:1472: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:2176: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Data shuffled. Epoch:  0\n",
      "Performance on training data: Loss = 1.144459843635559: Accuracy = 0.3400000035762787\n",
      "Performance on test set: : Loss = 1.1672039031982422: Accuracy = 0.5400844153553221\n",
      "\n",
      "Data shuffled. Epoch:  1\n",
      "Performance on training data: Loss = 1.0896421670913696: Accuracy = 0.4866666793823242\n",
      "Performance on test set: : Loss = 1.1575323343276978: Accuracy = 0.5340206283715677\n",
      "\n",
      "Data shuffled. Epoch:  2\n",
      "Performance on training data: Loss = 1.0925589799880981: Accuracy = 0.47333332896232605\n",
      "Performance on test set: : Loss = 1.1772511005401611: Accuracy = 0.5603164035122594\n",
      "\n",
      "Data shuffled. Epoch:  3\n",
      "Performance on training data: Loss = 1.0672128200531006: Accuracy = 0.4333333373069763\n",
      "Performance on test set: : Loss = 1.1628119945526123: Accuracy = 0.5937499441905265\n",
      "\n",
      "Data shuffled. Epoch:  4\n",
      "Performance on training data: Loss = 1.0751595497131348: Accuracy = 0.41999998688697815\n",
      "Performance on test set: : Loss = 1.1625925302505493: Accuracy = 0.6376080905067782\n",
      "\n",
      "Data shuffled. Epoch:  5\n",
      "Performance on training data: Loss = 0.9352388381958008: Accuracy = 0.5199999809265137\n",
      "Performance on test set: : Loss = 1.1636698246002197: Accuracy = 0.6539589245311525\n",
      "\n",
      "Data shuffled. Epoch:  6\n",
      "Performance on training data: Loss = 0.7757422924041748: Accuracy = 0.6266666650772095\n",
      "Performance on test set: : Loss = 1.1807756423950195: Accuracy = 0.6608911364064496\n",
      "\n",
      "Data shuffled. Epoch:  7\n",
      "Performance on training data: Loss = 0.7279438972473145: Accuracy = 0.6466666460037231\n",
      "Performance on test set: : Loss = 1.208701491355896: Accuracy = 0.6721658426991799\n",
      "\n",
      "Data shuffled. Epoch:  8\n",
      "Performance on training data: Loss = 0.7050964832305908: Accuracy = 0.6600000262260437\n",
      "Performance on test set: : Loss = 1.2402926683425903: Accuracy = 0.6720480823246708\n",
      "\n",
      "Data shuffled. Epoch:  9\n",
      "Performance on training data: Loss = 0.7770067453384399: Accuracy = 0.5933333039283752\n",
      "Performance on test set: : Loss = 1.212630033493042: Accuracy = 0.6763478696263042\n",
      "\n",
      "Data shuffled. Epoch:  10\n",
      "Performance on training data: Loss = 0.7543313503265381: Accuracy = 0.5799999833106995\n",
      "Performance on test set: : Loss = 1.202543020248413: Accuracy = 0.6762742420575628\n",
      "\n",
      "Data shuffled. Epoch:  11\n",
      "Performance on training data: Loss = 0.7045373320579529: Accuracy = 0.6200000047683716\n",
      "Performance on test set: : Loss = 1.2162585258483887: Accuracy = 0.6756344450478126\n",
      "\n",
      "Data shuffled. Epoch:  12\n",
      "Performance on training data: Loss = 0.6054231524467468: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.271618366241455: Accuracy = 0.6747853018669441\n",
      "\n",
      "Data shuffled. Epoch:  13\n",
      "Performance on training data: Loss = 0.5730239748954773: Accuracy = 0.6800000071525574\n",
      "Performance on test set: : Loss = 1.2690356969833374: Accuracy = 0.676407710068329\n",
      "\n",
      "Data shuffled. Epoch:  14\n",
      "Performance on training data: Loss = 0.6232052445411682: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.3626112937927246: Accuracy = 0.6758375503265682\n",
      "\n",
      "Data shuffled. Epoch:  15\n",
      "Performance on training data: Loss = 0.5845983028411865: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.460970401763916: Accuracy = 0.6782014266602835\n",
      "\n",
      "Data shuffled. Epoch:  16\n",
      "Performance on training data: Loss = 0.5640329718589783: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.404930591583252: Accuracy = 0.6783352422060319\n",
      "\n",
      "Data shuffled. Epoch:  17\n",
      "Performance on training data: Loss = 0.6292781829833984: Accuracy = 0.653333306312561\n",
      "Performance on test set: : Loss = 1.5166444778442383: Accuracy = 0.6765437052449466\n",
      "\n",
      "Data shuffled. Epoch:  18\n",
      "Performance on training data: Loss = 0.5538191795349121: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.5517303943634033: Accuracy = 0.6798857455956999\n",
      "\n",
      "Data shuffled. Epoch:  19\n",
      "Performance on training data: Loss = 0.5691251158714294: Accuracy = 0.6733333468437195\n",
      "Performance on test set: : Loss = 1.5150641202926636: Accuracy = 0.6818591370902112\n",
      "\n",
      "Data shuffled. Epoch:  20\n",
      "Performance on training data: Loss = 0.5890260338783264: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.6067967414855957: Accuracy = 0.6830217686785288\n",
      "\n",
      "Data shuffled. Epoch:  21\n",
      "Performance on training data: Loss = 0.5237278938293457: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 1.5446579456329346: Accuracy = 0.6841753800162705\n",
      "\n",
      "Data shuffled. Epoch:  22\n",
      "Performance on training data: Loss = 0.5210711359977722: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 1.598655343055725: Accuracy = 0.6847471992501412\n",
      "\n",
      "Data shuffled. Epoch:  23\n",
      "Performance on training data: Loss = 0.5407828092575073: Accuracy = 0.6666666865348816\n",
      "Performance on test set: : Loss = 1.7243281602859497: Accuracy = 0.6861550713797575\n",
      "\n",
      "Data shuffled. Epoch:  24\n",
      "Performance on training data: Loss = 0.5477643609046936: Accuracy = 0.7066666483879089\n",
      "Performance on test set: : Loss = 1.814587950706482: Accuracy = 0.6888299672241157\n",
      "\n",
      "Data shuffled. Epoch:  25\n",
      "Performance on training data: Loss = 0.5172176361083984: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.955288052558899: Accuracy = 0.6900439399676876\n",
      "\n",
      "Data shuffled. Epoch:  26\n",
      "Performance on training data: Loss = 0.4946037232875824: Accuracy = 0.753333330154419\n",
      "Performance on test set: : Loss = 1.760429859161377: Accuracy = 0.6915077208873909\n",
      "\n",
      "Data shuffled. Epoch:  27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.5053737163543701: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.7969613075256348: Accuracy = 0.6933302830249222\n",
      "\n",
      "Data shuffled. Epoch:  28\n",
      "Performance on training data: Loss = 0.5101398825645447: Accuracy = 0.6933333277702332\n",
      "Performance on test set: : Loss = 2.089505434036255: Accuracy = 0.6937070856798948\n",
      "\n",
      "Data shuffled. Epoch:  29\n",
      "Performance on training data: Loss = 0.5305909514427185: Accuracy = 0.699999988079071\n",
      "Performance on test set: : Loss = 1.8194619417190552: Accuracy = 0.6939728703028342\n",
      "\n",
      "Data shuffled. Epoch:  30\n",
      "Performance on training data: Loss = 0.4857485890388489: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.7774525880813599: Accuracy = 0.6943818272614027\n",
      "\n",
      "Data shuffled. Epoch:  31\n",
      "Performance on training data: Loss = 0.46134594082832336: Accuracy = 0.7400000095367432\n",
      "Performance on test set: : Loss = 2.227677345275879: Accuracy = 0.6955360260529088\n",
      "\n",
      "Data shuffled. Epoch:  32\n",
      "Performance on training data: Loss = 0.4238470792770386: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 1.9234602451324463: Accuracy = 0.6963601886513087\n",
      "\n",
      "Data shuffled. Epoch:  33\n",
      "Performance on training data: Loss = 0.4851706326007843: Accuracy = 0.7200000286102295\n",
      "Performance on test set: : Loss = 1.790725588798523: Accuracy = 0.698666921499738\n",
      "\n",
      "Data shuffled. Epoch:  34\n",
      "Performance on training data: Loss = 0.4271167516708374: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.0710091590881348: Accuracy = 0.6989445548189075\n",
      "\n",
      "Data shuffled. Epoch:  35\n",
      "Performance on training data: Loss = 0.4642181992530823: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 1.9778245687484741: Accuracy = 0.6997952953047228\n",
      "\n",
      "Data shuffled. Epoch:  36\n",
      "Performance on training data: Loss = 0.4395037889480591: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.1432712078094482: Accuracy = 0.7002495695965075\n",
      "\n",
      "Data shuffled. Epoch:  37\n",
      "Performance on training data: Loss = 0.47562143206596375: Accuracy = 0.746666669845581\n",
      "Performance on test set: : Loss = 2.0496039390563965: Accuracy = 0.7014085892921595\n",
      "\n",
      "Data shuffled. Epoch:  38\n",
      "Performance on training data: Loss = 0.4885918200016022: Accuracy = 0.7266666889190674\n",
      "Performance on test set: : Loss = 2.0313146114349365: Accuracy = 0.7017137122515135\n",
      "\n",
      "Data shuffled. Epoch:  39\n",
      "Performance on training data: Loss = 0.3888825476169586: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.0896949768066406: Accuracy = 0.7036950184045936\n",
      "\n",
      "Data shuffled. Epoch:  40\n",
      "Performance on training data: Loss = 0.39053866267204285: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.077732563018799: Accuracy = 0.7042327977736252\n",
      "\n",
      "Data shuffled. Epoch:  41\n",
      "Performance on training data: Loss = 0.41439464688301086: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 2.2276055812835693: Accuracy = 0.7047948410685233\n",
      "\n",
      "Data shuffled. Epoch:  42\n",
      "Performance on training data: Loss = 0.40289628505706787: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.045151710510254: Accuracy = 0.7059921579107638\n",
      "\n",
      "Data shuffled. Epoch:  43\n",
      "Performance on training data: Loss = 0.4155113697052002: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.6203112602233887: Accuracy = 0.707335008903771\n",
      "\n",
      "Data shuffled. Epoch:  44\n",
      "Performance on training data: Loss = 0.43829208612442017: Accuracy = 0.7866666913032532\n",
      "Performance on test set: : Loss = 1.9472426176071167: Accuracy = 0.7086957815002166\n",
      "\n",
      "Data shuffled. Epoch:  45\n",
      "Performance on training data: Loss = 0.3853335380554199: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.3141067028045654: Accuracy = 0.7094604224101677\n",
      "\n",
      "Data shuffled. Epoch:  46\n",
      "Performance on training data: Loss = 0.3714146912097931: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.282735824584961: Accuracy = 0.7115834309402712\n",
      "\n",
      "Data shuffled. Epoch:  47\n",
      "Performance on training data: Loss = 0.38597995042800903: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.0444462299346924: Accuracy = 0.7127342092137575\n",
      "\n",
      "Data shuffled. Epoch:  48\n",
      "Performance on training data: Loss = 0.37708181142807007: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.5508925914764404: Accuracy = 0.7140906673078885\n",
      "\n",
      "Data shuffled. Epoch:  49\n",
      "Performance on training data: Loss = 0.4137008786201477: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.1078970432281494: Accuracy = 0.7147889927255183\n",
      "\n",
      "Data shuffled. Epoch:  50\n",
      "Performance on training data: Loss = 0.3693471848964691: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.305396556854248: Accuracy = 0.7164959301989955\n",
      "\n",
      "Data shuffled. Epoch:  51\n",
      "Performance on training data: Loss = 0.3370557427406311: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.473280191421509: Accuracy = 0.7179054543252587\n",
      "\n",
      "Data shuffled. Epoch:  52\n",
      "Performance on training data: Loss = 0.377451092004776: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.4422523975372314: Accuracy = 0.7193286712138748\n",
      "\n",
      "Data shuffled. Epoch:  53\n",
      "Performance on training data: Loss = 0.34960225224494934: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.427079439163208: Accuracy = 0.7207999963972979\n",
      "\n",
      "Data shuffled. Epoch:  54\n",
      "Performance on training data: Loss = 0.3879352807998657: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.1874895095825195: Accuracy = 0.7221767650263081\n",
      "\n",
      "Data shuffled. Epoch:  55\n",
      "Performance on training data: Loss = 0.4041329026222229: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.556095600128174: Accuracy = 0.7235670464533394\n",
      "\n",
      "Data shuffled. Epoch:  56\n",
      "Performance on training data: Loss = 0.42822936177253723: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.1535143852233887: Accuracy = 0.7246924293499248\n",
      "\n",
      "Data shuffled. Epoch:  57\n",
      "Performance on training data: Loss = 0.4157913327217102: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.8979032039642334: Accuracy = 0.7259160225583895\n",
      "\n",
      "Data shuffled. Epoch:  58\n",
      "Performance on training data: Loss = 0.38713428378105164: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.1349451541900635: Accuracy = 0.7271900938391752\n",
      "\n",
      "Data shuffled. Epoch:  59\n",
      "Performance on training data: Loss = 0.31456002593040466: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.3531084060668945: Accuracy = 0.7285431384367963\n",
      "\n",
      "Data shuffled. Epoch:  60\n",
      "Performance on training data: Loss = 0.33499300479888916: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.5721051692962646: Accuracy = 0.7298467624799081\n",
      "\n",
      "Data shuffled. Epoch:  61\n",
      "Performance on training data: Loss = 0.3759731352329254: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.233285903930664: Accuracy = 0.7311211559424244\n",
      "\n",
      "Data shuffled. Epoch:  62\n",
      "Performance on training data: Loss = 0.4108894169330597: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.442896842956543: Accuracy = 0.7322740047013375\n",
      "\n",
      "Data shuffled. Epoch:  63\n",
      "Performance on training data: Loss = 0.32941383123397827: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.487760543823242: Accuracy = 0.7333456239911931\n",
      "\n",
      "Data shuffled. Epoch:  64\n",
      "Performance on training data: Loss = 0.41645094752311707: Accuracy = 0.7733333110809326\n",
      "Performance on test set: : Loss = 2.6257073879241943: Accuracy = 0.7344504752251457\n",
      "\n",
      "Data shuffled. Epoch:  65\n",
      "Performance on training data: Loss = 0.34165337681770325: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.4300663471221924: Accuracy = 0.7353819632865778\n",
      "\n",
      "Data shuffled. Epoch:  66\n",
      "Performance on training data: Loss = 0.3882110118865967: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.812889814376831: Accuracy = 0.7364449942408069\n",
      "\n",
      "Data shuffled. Epoch:  67\n",
      "Performance on training data: Loss = 0.410183846950531: Accuracy = 0.7799999713897705\n",
      "Performance on test set: : Loss = 2.6031744480133057: Accuracy = 0.7374463132881173\n",
      "\n",
      "Data shuffled. Epoch:  68\n",
      "Performance on training data: Loss = 0.32956650853157043: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.703904151916504: Accuracy = 0.7383622257484309\n",
      "\n",
      "Data shuffled. Epoch:  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.3926032483577728: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.7633473873138428: Accuracy = 0.7393285861777998\n",
      "\n",
      "Data shuffled. Epoch:  70\n",
      "Performance on training data: Loss = 0.28238895535469055: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.6417784690856934: Accuracy = 0.7402650771150577\n",
      "\n",
      "Data shuffled. Epoch:  71\n",
      "Performance on training data: Loss = 0.36112406849861145: Accuracy = 0.7933333516120911\n",
      "Performance on test set: : Loss = 2.962932586669922: Accuracy = 0.7411731881823985\n",
      "\n",
      "Data shuffled. Epoch:  72\n",
      "Performance on training data: Loss = 0.3530977964401245: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.886988639831543: Accuracy = 0.7420539732090039\n",
      "\n",
      "Data shuffled. Epoch:  73\n",
      "Performance on training data: Loss = 0.3065890669822693: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.717468023300171: Accuracy = 0.7429088201107541\n",
      "\n",
      "Data shuffled. Epoch:  74\n",
      "Performance on training data: Loss = 0.34028762578964233: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.721741199493408: Accuracy = 0.7436901582957902\n",
      "\n",
      "Data shuffled. Epoch:  75\n",
      "Performance on training data: Loss = 0.34801074862480164: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.7943105697631836: Accuracy = 0.7444970474188686\n",
      "\n",
      "Data shuffled. Epoch:  76\n",
      "Performance on training data: Loss = 0.291985422372818: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.882018804550171: Accuracy = 0.7452812316747816\n",
      "\n",
      "Data shuffled. Epoch:  77\n",
      "Performance on training data: Loss = 0.295296311378479: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 3.0444955825805664: Accuracy = 0.7460435182376405\n",
      "\n",
      "Data shuffled. Epoch:  78\n",
      "Performance on training data: Loss = 0.33446648716926575: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.475555181503296: Accuracy = 0.7467848953080775\n",
      "\n",
      "Data shuffled. Epoch:  79\n",
      "Performance on training data: Loss = 0.362777441740036: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.105550527572632: Accuracy = 0.7475061828559078\n",
      "\n",
      "Data shuffled. Epoch:  80\n",
      "Performance on training data: Loss = 0.33464840054512024: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.773541212081909: Accuracy = 0.7482081298508346\n",
      "\n",
      "Data shuffled. Epoch:  81\n",
      "Performance on training data: Loss = 0.3524259328842163: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.802129030227661: Accuracy = 0.7488915918807943\n",
      "\n",
      "Data shuffled. Epoch:  82\n",
      "Performance on training data: Loss = 0.3025516867637634: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.5247578620910645: Accuracy = 0.7495571999349117\n",
      "\n",
      "Data shuffled. Epoch:  83\n",
      "Performance on training data: Loss = 0.33725208044052124: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.8516671657562256: Accuracy = 0.750205712649034\n",
      "\n",
      "Data shuffled. Epoch:  84\n",
      "Performance on training data: Loss = 0.36054009199142456: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.67692232131958: Accuracy = 0.7508377826095083\n",
      "\n",
      "Data shuffled. Epoch:  85\n",
      "Performance on training data: Loss = 0.30130594968795776: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.842759609222412: Accuracy = 0.7514539768483943\n",
      "\n",
      "Data shuffled. Epoch:  86\n",
      "Performance on training data: Loss = 0.3487192392349243: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 3.0287678241729736: Accuracy = 0.7520548745781216\n",
      "\n",
      "Data shuffled. Epoch:  87\n",
      "Performance on training data: Loss = 0.35673606395721436: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.8058457374572754: Accuracy = 0.752641165671069\n",
      "\n",
      "Data shuffled. Epoch:  88\n",
      "Performance on training data: Loss = 0.3402594327926636: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.8773210048675537: Accuracy = 0.7532132609345499\n",
      "\n",
      "Data shuffled. Epoch:  89\n",
      "Performance on training data: Loss = 0.33663228154182434: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.7675957679748535: Accuracy = 0.7537717608142305\n",
      "\n",
      "Data shuffled. Epoch:  90\n",
      "Performance on training data: Loss = 0.31396612524986267: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 3.082127571105957: Accuracy = 0.7543170649114693\n",
      "\n",
      "Data shuffled. Epoch:  91\n",
      "Performance on training data: Loss = 0.37274369597435: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.698420524597168: Accuracy = 0.7548495894391996\n",
      "\n",
      "Data shuffled. Epoch:  92\n",
      "Performance on training data: Loss = 0.3144242763519287: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.8830952644348145: Accuracy = 0.7553698221628224\n",
      "\n",
      "Data shuffled. Epoch:  93\n",
      "Performance on training data: Loss = 0.31637999415397644: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.9328463077545166: Accuracy = 0.755878208350417\n",
      "\n",
      "Data shuffled. Epoch:  94\n",
      "Performance on training data: Loss = 0.33840814232826233: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.89856219291687: Accuracy = 0.756360558703354\n",
      "\n",
      "Data shuffled. Epoch:  95\n",
      "Performance on training data: Loss = 0.3084968626499176: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.989053726196289: Accuracy = 0.7568466375694238\n",
      "\n",
      "Data shuffled. Epoch:  96\n",
      "Performance on training data: Loss = 0.32312583923339844: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 3.098017692565918: Accuracy = 0.757303822051103\n",
      "\n",
      "Data shuffled. Epoch:  97\n",
      "Performance on training data: Loss = 0.2824188470840454: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.5910251140594482: Accuracy = 0.7577509519982303\n",
      "\n",
      "Data shuffled. Epoch:  98\n",
      "Performance on training data: Loss = 0.31182432174682617: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.819279909133911: Accuracy = 0.7582064176514102\n",
      "\n",
      "Data shuffled. Epoch:  99\n",
      "Performance on training data: Loss = 0.31859302520751953: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.913804531097412: Accuracy = 0.7586520928978623\n",
      "\n",
      "Data shuffled. Epoch:  100\n",
      "Performance on training data: Loss = 0.3255027234554291: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.4668164253234863: Accuracy = 0.7590708623151922\n",
      "\n",
      "Data shuffled. Epoch:  101\n",
      "Performance on training data: Loss = 0.3714541494846344: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.9439985752105713: Accuracy = 0.7594982024941765\n",
      "\n",
      "Data shuffled. Epoch:  102\n",
      "Performance on training data: Loss = 0.28029507398605347: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.7728774547576904: Accuracy = 0.7599167430846868\n",
      "\n",
      "Data shuffled. Epoch:  103\n",
      "Performance on training data: Loss = 0.30620041489601135: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.6647183895111084: Accuracy = 0.7603267075998861\n",
      "\n",
      "Data shuffled. Epoch:  104\n",
      "Performance on training data: Loss = 0.3023368716239929: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.63493013381958: Accuracy = 0.7607284339665267\n",
      "\n",
      "Data shuffled. Epoch:  105\n",
      "Performance on training data: Loss = 0.2530219554901123: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.4484946727752686: Accuracy = 0.7611220433046494\n",
      "\n",
      "Data shuffled. Epoch:  106\n",
      "Performance on training data: Loss = 0.31931471824645996: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.6918795108795166: Accuracy = 0.7614422697285141\n",
      "\n",
      "Data shuffled. Epoch:  107\n",
      "Performance on training data: Loss = 0.3368542492389679: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.722437858581543: Accuracy = 0.7618048997723799\n",
      "\n",
      "Data shuffled. Epoch:  108\n",
      "Performance on training data: Loss = 0.3457064926624298: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.453366994857788: Accuracy = 0.7619875941184849\n",
      "\n",
      "Data shuffled. Epoch:  109\n",
      "Performance on training data: Loss = 0.29916754364967346: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.6896915435791016: Accuracy = 0.7623221355344029\n",
      "\n",
      "Data shuffled. Epoch:  110\n",
      "Performance on training data: Loss = 0.3437272012233734: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.9828484058380127: Accuracy = 0.7626503751780215\n",
      "\n",
      "Data shuffled. Epoch:  111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.36421647667884827: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.370222806930542: Accuracy = 0.7629723882669205\n",
      "\n",
      "Data shuffled. Epoch:  112\n",
      "Performance on training data: Loss = 0.32954269647598267: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.8093507289886475: Accuracy = 0.7627940994684577\n",
      "\n",
      "Data shuffled. Epoch:  113\n",
      "Performance on training data: Loss = 0.2785111367702484: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.525897741317749: Accuracy = 0.7631395681899503\n",
      "\n",
      "Data shuffled. Epoch:  114\n",
      "Performance on training data: Loss = 0.28376877307891846: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.3675003051757812: Accuracy = 0.7634333610093365\n",
      "\n",
      "Data shuffled. Epoch:  115\n",
      "Performance on training data: Loss = 0.3201899230480194: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.4224729537963867: Accuracy = 0.7635598932976013\n",
      "\n",
      "Data shuffled. Epoch:  116\n",
      "Performance on training data: Loss = 0.31973764300346375: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.451289176940918: Accuracy = 0.763859409354532\n",
      "\n",
      "Data shuffled. Epoch:  117\n",
      "Performance on training data: Loss = 0.34006163477897644: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.60581111907959: Accuracy = 0.7640537885817315\n",
      "\n",
      "Data shuffled. Epoch:  118\n",
      "Performance on training data: Loss = 0.2798703908920288: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 2.433476448059082: Accuracy = 0.7642628627393495\n",
      "\n",
      "Data shuffled. Epoch:  119\n",
      "Performance on training data: Loss = 0.2552824020385742: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.575042486190796: Accuracy = 0.7643356685930149\n",
      "\n",
      "Data shuffled. Epoch:  120\n",
      "Performance on training data: Loss = 0.2687932848930359: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.286132574081421: Accuracy = 0.7644675059378374\n",
      "\n",
      "Data shuffled. Epoch:  121\n",
      "Performance on training data: Loss = 0.2717578411102295: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.792001962661743: Accuracy = 0.7646909882473919\n",
      "\n",
      "Data shuffled. Epoch:  122\n",
      "Performance on training data: Loss = 0.25680986046791077: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.543564796447754: Accuracy = 0.7649657145229051\n",
      "\n",
      "Data shuffled. Epoch:  123\n",
      "Performance on training data: Loss = 0.3061155378818512: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.519587278366089: Accuracy = 0.7651358453443649\n",
      "\n",
      "Data shuffled. Epoch:  124\n",
      "Performance on training data: Loss = 0.22004638612270355: Accuracy = 0.9133333563804626\n",
      "Performance on test set: : Loss = 2.320042371749878: Accuracy = 0.7653309590842416\n",
      "\n",
      "Data shuffled. Epoch:  125\n",
      "Performance on training data: Loss = 0.2845885455608368: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.398486614227295: Accuracy = 0.7645559339528581\n",
      "\n",
      "Data shuffled. Epoch:  126\n",
      "Performance on training data: Loss = 0.32319650053977966: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.5605356693267822: Accuracy = 0.7643476004319474\n",
      "\n",
      "Data shuffled. Epoch:  127\n",
      "Performance on training data: Loss = 0.2970346212387085: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.5657408237457275: Accuracy = 0.7642725650390793\n",
      "\n",
      "Data shuffled. Epoch:  128\n",
      "Performance on training data: Loss = 0.2819844186306: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 3.0396389961242676: Accuracy = 0.7645381905094624\n",
      "\n",
      "Data shuffled. Epoch:  129\n",
      "Performance on training data: Loss = 0.31494107842445374: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.8304333686828613: Accuracy = 0.7647728000367463\n",
      "\n",
      "Data shuffled. Epoch:  130\n",
      "Performance on training data: Loss = 0.2531060576438904: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 2.4785478115081787: Accuracy = 0.7645825214298771\n",
      "\n",
      "Data shuffled. Epoch:  131\n",
      "Performance on training data: Loss = 0.31655821204185486: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.6353697776794434: Accuracy = 0.7648439926138183\n",
      "\n",
      "Data shuffled. Epoch:  132\n",
      "Performance on training data: Loss = 0.33475562930107117: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.4887216091156006: Accuracy = 0.7649362444410891\n",
      "\n",
      "Data shuffled. Epoch:  133\n",
      "Performance on training data: Loss = 0.30100518465042114: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.362548589706421: Accuracy = 0.7643606955265422\n",
      "\n",
      "Data shuffled. Epoch:  134\n",
      "Performance on training data: Loss = 0.3199557065963745: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.7749156951904297: Accuracy = 0.7643330654713293\n",
      "\n",
      "Data shuffled. Epoch:  135\n",
      "Performance on training data: Loss = 0.3046359717845917: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.552178382873535: Accuracy = 0.7644187398298934\n",
      "\n",
      "Data shuffled. Epoch:  136\n",
      "Performance on training data: Loss = 0.316519558429718: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.7137362957000732: Accuracy = 0.7645031259744653\n",
      "\n",
      "Data shuffled. Epoch:  137\n",
      "Performance on training data: Loss = 0.2925160527229309: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.616359233856201: Accuracy = 0.7644589292406004\n",
      "\n",
      "Data shuffled. Epoch:  138\n",
      "Performance on training data: Loss = 0.3271935284137726: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.863175392150879: Accuracy = 0.7642893117458466\n",
      "\n",
      "Data shuffled. Epoch:  139\n",
      "Performance on training data: Loss = 0.31072136759757996: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.902665138244629: Accuracy = 0.7643160425112772\n",
      "\n",
      "Data shuffled. Epoch:  140\n",
      "Performance on training data: Loss = 0.2844450771808624: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.85278058052063: Accuracy = 0.7645418145411221\n",
      "\n",
      "Data shuffled. Epoch:  141\n",
      "Performance on training data: Loss = 0.2981768548488617: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.359794855117798: Accuracy = 0.7647204832680047\n",
      "\n",
      "Data shuffled. Epoch:  142\n",
      "Performance on training data: Loss = 0.2702140808105469: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.376249074935913: Accuracy = 0.7641143287282223\n",
      "\n",
      "Data shuffled. Epoch:  143\n",
      "Performance on training data: Loss = 0.3266231417655945: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.344799041748047: Accuracy = 0.7639398401285336\n",
      "\n",
      "Data shuffled. Epoch:  144\n",
      "Performance on training data: Loss = 0.35850074887275696: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.3855035305023193: Accuracy = 0.7639462949229253\n",
      "\n",
      "Data shuffled. Epoch:  145\n",
      "Performance on training data: Loss = 0.3332439661026001: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.54077410697937: Accuracy = 0.7640414808368686\n",
      "\n",
      "Data shuffled. Epoch:  146\n",
      "Performance on training data: Loss = 0.24809862673282623: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.357516050338745: Accuracy = 0.7634005956227039\n",
      "\n",
      "Data shuffled. Epoch:  147\n",
      "Performance on training data: Loss = 0.3230721652507782: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.926502227783203: Accuracy = 0.7634404518409039\n",
      "\n",
      "Data shuffled. Epoch:  148\n",
      "Performance on training data: Loss = 0.28377750515937805: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.827450752258301: Accuracy = 0.7636239381087854\n",
      "\n",
      "Data shuffled. Epoch:  149\n",
      "Performance on training data: Loss = 0.31726741790771484: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.9757370948791504: Accuracy = 0.7634690483325974\n",
      "\n",
      "Data shuffled. Epoch:  150\n",
      "Performance on training data: Loss = 0.3054385185241699: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.850389003753662: Accuracy = 0.7636863750955906\n",
      "\n",
      "Data shuffled. Epoch:  151\n",
      "Performance on training data: Loss = 0.31181836128234863: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.4531466960906982: Accuracy = 0.7637604467885946\n",
      "\n",
      "Data shuffled. Epoch:  152\n",
      "Performance on training data: Loss = 0.3129598796367645: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.5568480491638184: Accuracy = 0.7638176462733769\n",
      "\n",
      "Data shuffled. Epoch:  153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.30731791257858276: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.629544496536255: Accuracy = 0.763921896489097\n",
      "\n",
      "Data shuffled. Epoch:  154\n",
      "Performance on training data: Loss = 0.26707297563552856: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.680042266845703: Accuracy = 0.7641061298462922\n",
      "\n",
      "Data shuffled. Epoch:  155\n",
      "Performance on training data: Loss = 0.2804195284843445: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.5893425941467285: Accuracy = 0.7643498040052955\n",
      "\n",
      "Data shuffled. Epoch:  156\n",
      "Performance on training data: Loss = 0.29936984181404114: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.8173890113830566: Accuracy = 0.7644006733417134\n",
      "\n",
      "Data shuffled. Epoch:  157\n",
      "Performance on training data: Loss = 0.3032219111919403: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.5639307498931885: Accuracy = 0.7646171104834837\n",
      "\n",
      "Data shuffled. Epoch:  158\n",
      "Performance on training data: Loss = 0.3043723404407501: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.370973825454712: Accuracy = 0.7644369848828156\n",
      "\n",
      "Data shuffled. Epoch:  159\n",
      "Performance on training data: Loss = 0.295097678899765: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.3695924282073975: Accuracy = 0.764299965427383\n",
      "\n",
      "Data shuffled. Epoch:  160\n",
      "Performance on training data: Loss = 0.26616594195365906: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.5884790420532227: Accuracy = 0.76448719861633\n",
      "\n",
      "Data shuffled. Epoch:  161\n",
      "Performance on training data: Loss = 0.26103851199150085: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.6389894485473633: Accuracy = 0.7645901043433865\n",
      "\n",
      "Data shuffled. Epoch:  162\n",
      "Performance on training data: Loss = 0.25020354986190796: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.6951799392700195: Accuracy = 0.7643462674548818\n",
      "\n",
      "Data shuffled. Epoch:  163\n",
      "Performance on training data: Loss = 0.27902767062187195: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.458310842514038: Accuracy = 0.7644102965846684\n",
      "\n",
      "Data shuffled. Epoch:  164\n",
      "Performance on training data: Loss = 0.3250158727169037: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 3.088960886001587: Accuracy = 0.7646173679083862\n",
      "\n",
      "Data shuffled. Epoch:  165\n",
      "Performance on training data: Loss = 0.26339173316955566: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.5633938312530518: Accuracy = 0.7647693721448559\n",
      "\n",
      "Data shuffled. Epoch:  166\n",
      "Performance on training data: Loss = 0.2834198772907257: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.323913097381592: Accuracy = 0.7647814700744411\n",
      "\n",
      "Data shuffled. Epoch:  167\n",
      "Performance on training data: Loss = 0.29783880710601807: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.3684182167053223: Accuracy = 0.7649369810427799\n",
      "\n",
      "Data shuffled. Epoch:  168\n",
      "Performance on training data: Loss = 0.27950623631477356: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.724349021911621: Accuracy = 0.7647972157874299\n",
      "\n",
      "Data shuffled. Epoch:  169\n",
      "Performance on training data: Loss = 0.28694480657577515: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.667414903640747: Accuracy = 0.7649508108590785\n",
      "\n",
      "Data shuffled. Epoch:  170\n",
      "Performance on training data: Loss = 0.2423572838306427: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.545252799987793: Accuracy = 0.7650923999970192\n",
      "\n",
      "Data shuffled. Epoch:  171\n",
      "Performance on training data: Loss = 0.2644062340259552: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.543208360671997: Accuracy = 0.764869854398748\n",
      "\n",
      "Data shuffled. Epoch:  172\n",
      "Performance on training data: Loss = 0.27685192227363586: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.7177934646606445: Accuracy = 0.7649485133594791\n",
      "\n",
      "Data shuffled. Epoch:  173\n",
      "Performance on training data: Loss = 0.2812744081020355: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.437140703201294: Accuracy = 0.7649594970196351\n",
      "\n",
      "Data shuffled. Epoch:  174\n",
      "Performance on training data: Loss = 0.25897902250289917: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.3506686687469482: Accuracy = 0.7648879791329226\n",
      "\n",
      "Data shuffled. Epoch:  175\n",
      "Performance on training data: Loss = 0.26005449891090393: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 2.315359354019165: Accuracy = 0.764788358592672\n",
      "\n",
      "Data shuffled. Epoch:  176\n",
      "Performance on training data: Loss = 0.2782214879989624: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.5343868732452393: Accuracy = 0.7645097511709277\n",
      "\n",
      "Data shuffled. Epoch:  177\n",
      "Performance on training data: Loss = 0.2771219313144684: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.7624826431274414: Accuracy = 0.76468768497589\n",
      "\n",
      "Data shuffled. Epoch:  178\n",
      "Performance on training data: Loss = 0.24920794367790222: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.4269535541534424: Accuracy = 0.7647392875620079\n",
      "\n",
      "Data shuffled. Epoch:  179\n",
      "Performance on training data: Loss = 0.3259469270706177: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.3325610160827637: Accuracy = 0.7644346553842936\n",
      "\n",
      "Data shuffled. Epoch:  180\n",
      "Performance on training data: Loss = 0.3390994369983673: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.7252347469329834: Accuracy = 0.7645752125676306\n",
      "\n",
      "Data shuffled. Epoch:  181\n",
      "Performance on training data: Loss = 0.25148093700408936: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 3.3270273208618164: Accuracy = 0.7646361684277688\n",
      "\n",
      "Data shuffled. Epoch:  182\n",
      "Performance on training data: Loss = 0.31160271167755127: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.37414813041687: Accuracy = 0.7647476136016318\n",
      "\n",
      "Data shuffled. Epoch:  183\n",
      "Performance on training data: Loss = 0.2795324921607971: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.362351179122925: Accuracy = 0.7645380791902957\n",
      "\n",
      "Data shuffled. Epoch:  184\n",
      "Performance on training data: Loss = 0.25997865200042725: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 3.1261181831359863: Accuracy = 0.76463904226617\n",
      "\n",
      "Data shuffled. Epoch:  185\n",
      "Performance on training data: Loss = 0.2437378466129303: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.492400884628296: Accuracy = 0.7647308819162881\n",
      "\n",
      "Data shuffled. Epoch:  186\n",
      "Performance on training data: Loss = 0.28997358679771423: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.574982166290283: Accuracy = 0.7643794737409566\n",
      "\n",
      "Data shuffled. Epoch:  187\n",
      "Performance on training data: Loss = 0.26963189244270325: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.4605531692504883: Accuracy = 0.7644837647895688\n",
      "\n",
      "Data shuffled. Epoch:  188\n",
      "Performance on training data: Loss = 0.28417474031448364: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.5371811389923096: Accuracy = 0.7644515492534634\n",
      "\n",
      "Data shuffled. Epoch:  189\n",
      "Performance on training data: Loss = 0.2450731098651886: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 2.327697277069092: Accuracy = 0.7641803383949842\n",
      "\n",
      "Data shuffled. Epoch:  190\n",
      "Performance on training data: Loss = 0.26830175518989563: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.378519296646118: Accuracy = 0.7639626876282942\n",
      "\n",
      "Data shuffled. Epoch:  191\n",
      "Performance on training data: Loss = 0.23722724616527557: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.532287359237671: Accuracy = 0.7638515314423221\n",
      "\n",
      "Data shuffled. Epoch:  192\n",
      "Performance on training data: Loss = 0.23629412055015564: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.3726389408111572: Accuracy = 0.7639374932604182\n",
      "\n",
      "Data shuffled. Epoch:  193\n",
      "Performance on training data: Loss = 0.28857117891311646: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.345681667327881: Accuracy = 0.763648541302355\n",
      "\n",
      "Data shuffled. Epoch:  194\n",
      "Performance on training data: Loss = 0.33138951659202576: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.5506412982940674: Accuracy = 0.7635192753670387\n",
      "\n",
      "Data shuffled. Epoch:  195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.21418263018131256: Accuracy = 0.9066666960716248\n",
      "Performance on test set: : Loss = 2.228489875793457: Accuracy = 0.7632023471653375\n",
      "\n",
      "Data shuffled. Epoch:  196\n",
      "Performance on training data: Loss = 0.258134126663208: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.4869072437286377: Accuracy = 0.763201945723401\n",
      "\n",
      "Data shuffled. Epoch:  197\n",
      "Performance on training data: Loss = 0.2630707919597626: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.1713953018188477: Accuracy = 0.7631677114669264\n",
      "\n",
      "Data shuffled. Epoch:  198\n",
      "Performance on training data: Loss = 0.29243719577789307: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.5306549072265625: Accuracy = 0.762988435264983\n",
      "\n",
      "Data shuffled. Epoch:  199\n",
      "Performance on training data: Loss = 0.26044681668281555: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.449331283569336: Accuracy = 0.7629264434854964\n",
      "\n",
      "Data shuffled. Epoch:  200\n",
      "Performance on training data: Loss = 0.386735737323761: Accuracy = 0.800000011920929\n",
      "Performance on test set: : Loss = 2.1958401203155518: Accuracy = 0.7628309591898201\n",
      "\n",
      "Data shuffled. Epoch:  201\n",
      "Performance on training data: Loss = 0.25090765953063965: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.47617506980896: Accuracy = 0.7627709757705269\n",
      "\n",
      "Data shuffled. Epoch:  202\n",
      "Performance on training data: Loss = 0.20651507377624512: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.2823758125305176: Accuracy = 0.7627162205842546\n",
      "\n",
      "Data shuffled. Epoch:  203\n",
      "Performance on training data: Loss = 0.28584539890289307: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.3539090156555176: Accuracy = 0.7623890907726442\n",
      "\n",
      "Data shuffled. Epoch:  204\n",
      "Performance on training data: Loss = 0.2862413227558136: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.407533884048462: Accuracy = 0.7622044263196425\n",
      "\n",
      "Data shuffled. Epoch:  205\n",
      "Performance on training data: Loss = 0.23616498708724976: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.359386444091797: Accuracy = 0.7623484890638194\n",
      "\n",
      "Data shuffled. Epoch:  206\n",
      "Performance on training data: Loss = 0.2452353984117508: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.7712979316711426: Accuracy = 0.7624909795181191\n",
      "\n",
      "Data shuffled. Epoch:  207\n",
      "Performance on training data: Loss = 0.25513598322868347: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.617954730987549: Accuracy = 0.7626152065679557\n",
      "\n",
      "Data shuffled. Epoch:  208\n",
      "Performance on training data: Loss = 0.257790744304657: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.0786094665527344: Accuracy = 0.7626814179111546\n",
      "\n",
      "Data shuffled. Epoch:  209\n",
      "Performance on training data: Loss = 0.31894412636756897: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.231891393661499: Accuracy = 0.7626250912879934\n",
      "\n",
      "Data shuffled. Epoch:  210\n",
      "Performance on training data: Loss = 0.29070383310317993: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.4527597427368164: Accuracy = 0.7627052258670328\n",
      "\n",
      "Data shuffled. Epoch:  211\n",
      "Performance on training data: Loss = 0.2520001530647278: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 1.8863798379898071: Accuracy = 0.7627191783887424\n",
      "\n",
      "Data shuffled. Epoch:  212\n",
      "Performance on training data: Loss = 0.3071988523006439: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 1.9246331453323364: Accuracy = 0.7624173119746497\n",
      "\n",
      "Data shuffled. Epoch:  213\n",
      "Performance on training data: Loss = 0.3299720883369446: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.0364465713500977: Accuracy = 0.7622920660533697\n",
      "\n",
      "Data shuffled. Epoch:  214\n",
      "Performance on training data: Loss = 0.3098170757293701: Accuracy = 0.8066666722297668\n",
      "Performance on test set: : Loss = 2.1497509479522705: Accuracy = 0.7621847334004793\n",
      "\n",
      "Data shuffled. Epoch:  215\n",
      "Performance on training data: Loss = 0.2978993356227875: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.9745405912399292: Accuracy = 0.7622090054667531\n",
      "\n",
      "Data shuffled. Epoch:  216\n",
      "Performance on training data: Loss = 0.28260186314582825: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 1.9963459968566895: Accuracy = 0.7621405700484953\n",
      "\n",
      "Data shuffled. Epoch:  217\n",
      "Performance on training data: Loss = 0.2722371518611908: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.5876803398132324: Accuracy = 0.7622465081987336\n",
      "\n",
      "Data shuffled. Epoch:  218\n",
      "Performance on training data: Loss = 0.3453488051891327: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.1183390617370605: Accuracy = 0.7622473454524665\n",
      "\n",
      "Data shuffled. Epoch:  219\n",
      "Performance on training data: Loss = 0.3030173182487488: Accuracy = 0.8666666746139526\n",
      "Performance on test set: : Loss = 2.132878541946411: Accuracy = 0.7622494870395221\n",
      "\n",
      "Data shuffled. Epoch:  220\n",
      "Performance on training data: Loss = 0.2831401824951172: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 1.9582127332687378: Accuracy = 0.7620397958671852\n",
      "\n",
      "Data shuffled. Epoch:  221\n",
      "Performance on training data: Loss = 0.32619211077690125: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.2802255153656006: Accuracy = 0.7617575702128193\n",
      "\n",
      "Data shuffled. Epoch:  222\n",
      "Performance on training data: Loss = 0.25303155183792114: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.137878179550171: Accuracy = 0.7617279514726506\n",
      "\n",
      "Data shuffled. Epoch:  223\n",
      "Performance on training data: Loss = 0.33113452792167664: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.3156917095184326: Accuracy = 0.7616750741078124\n",
      "\n",
      "Data shuffled. Epoch:  224\n",
      "Performance on training data: Loss = 0.27240702509880066: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.3878681659698486: Accuracy = 0.7615944517283719\n",
      "\n",
      "Data shuffled. Epoch:  225\n",
      "Performance on training data: Loss = 0.23615451157093048: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.454643487930298: Accuracy = 0.7612933443516285\n",
      "\n",
      "Data shuffled. Epoch:  226\n",
      "Performance on training data: Loss = 0.2770456075668335: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.2002108097076416: Accuracy = 0.7609138695670755\n",
      "\n",
      "Data shuffled. Epoch:  227\n",
      "Performance on training data: Loss = 0.33924147486686707: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.110058307647705: Accuracy = 0.7606808610272922\n",
      "\n",
      "Data shuffled. Epoch:  228\n",
      "Performance on training data: Loss = 0.2750430405139923: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.4142556190490723: Accuracy = 0.7607270685285799\n",
      "\n",
      "Data shuffled. Epoch:  229\n",
      "Performance on training data: Loss = 0.26070916652679443: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 2.0855510234832764: Accuracy = 0.7603996916792962\n",
      "\n",
      "Data shuffled. Epoch:  230\n",
      "Performance on training data: Loss = 0.24997861683368683: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.5078299045562744: Accuracy = 0.7603363962758984\n",
      "\n",
      "Data shuffled. Epoch:  231\n",
      "Performance on training data: Loss = 0.2800809144973755: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.248981475830078: Accuracy = 0.7603108012471421\n",
      "\n",
      "Data shuffled. Epoch:  232\n",
      "Performance on training data: Loss = 0.2602652609348297: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.133105993270874: Accuracy = 0.7601764251833424\n",
      "\n",
      "Data shuffled. Epoch:  233\n",
      "Performance on training data: Loss = 0.2785123586654663: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.3720171451568604: Accuracy = 0.7601938289216414\n",
      "\n",
      "Data shuffled. Epoch:  234\n",
      "Performance on training data: Loss = 0.2329561412334442: Accuracy = 0.8933333158493042\n",
      "Performance on test set: : Loss = 2.765256881713867: Accuracy = 0.7601200861425536\n",
      "\n",
      "Data shuffled. Epoch:  235\n",
      "Performance on training data: Loss = 0.3102230131626129: Accuracy = 0.8133333325386047\n",
      "Performance on test set: : Loss = 2.306323528289795: Accuracy = 0.7601806724985891\n",
      "\n",
      "Data shuffled. Epoch:  236\n",
      "Performance on training data: Loss = 0.29612427949905396: Accuracy = 0.8600000143051147\n",
      "Performance on test set: : Loss = 2.531987428665161: Accuracy = 0.7602184133288339\n",
      "\n",
      "Data shuffled. Epoch:  237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data: Loss = 0.23852793872356415: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 2.244762897491455: Accuracy = 0.7601619502725877\n",
      "\n",
      "Data shuffled. Epoch:  238\n",
      "Performance on training data: Loss = 0.31032121181488037: Accuracy = 0.8333333134651184\n",
      "Performance on test set: : Loss = 2.4102885723114014: Accuracy = 0.7597999903339913\n",
      "\n",
      "Data shuffled. Epoch:  239\n",
      "Performance on training data: Loss = 0.24719057977199554: Accuracy = 0.8866666555404663\n",
      "Performance on test set: : Loss = 2.342911720275879: Accuracy = 0.759647000472352\n",
      "\n",
      "Data shuffled. Epoch:  240\n",
      "Performance on training data: Loss = 0.27177268266677856: Accuracy = 0.8799999952316284\n",
      "Performance on test set: : Loss = 2.472515344619751: Accuracy = 0.7596194691026014\n",
      "\n",
      "Data shuffled. Epoch:  241\n",
      "Performance on training data: Loss = 0.29994526505470276: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.3395638465881348: Accuracy = 0.7594908895779301\n",
      "\n",
      "Data shuffled. Epoch:  242\n",
      "Performance on training data: Loss = 0.27691763639450073: Accuracy = 0.8399999737739563\n",
      "Performance on test set: : Loss = 2.2740957736968994: Accuracy = 0.7594115659998752\n",
      "\n",
      "Data shuffled. Epoch:  243\n",
      "Performance on training data: Loss = 0.2505088448524475: Accuracy = 0.8999999761581421\n",
      "Performance on test set: : Loss = 2.3034543991088867: Accuracy = 0.7591857588106011\n",
      "\n",
      "Data shuffled. Epoch:  244\n",
      "Performance on training data: Loss = 0.3147399425506592: Accuracy = 0.8266666531562805\n",
      "Performance on test set: : Loss = 2.3891947269439697: Accuracy = 0.7591338592472132\n",
      "\n",
      "Data shuffled. Epoch:  245\n",
      "Performance on training data: Loss = 0.24017833173274994: Accuracy = 0.8733333349227905\n",
      "Performance on test set: : Loss = 2.742128610610962: Accuracy = 0.7591962045852151\n",
      "\n",
      "Data shuffled. Epoch:  246\n",
      "Performance on training data: Loss = 0.2976173162460327: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.480543375015259: Accuracy = 0.7590603315609535\n",
      "\n",
      "Data shuffled. Epoch:  247\n",
      "Performance on training data: Loss = 0.32042112946510315: Accuracy = 0.8199999928474426\n",
      "Performance on test set: : Loss = 2.8554158210754395: Accuracy = 0.7591851131063094\n",
      "\n",
      "Data shuffled. Epoch:  248\n",
      "Performance on training data: Loss = 0.29179900884628296: Accuracy = 0.846666693687439\n",
      "Performance on test set: : Loss = 2.4073472023010254: Accuracy = 0.7592818900722814\n",
      "\n",
      "Data shuffled. Epoch:  249\n",
      "Performance on training data: Loss = 0.26009401679039: Accuracy = 0.8533333539962769\n",
      "Performance on test set: : Loss = 2.145982503890991: Accuracy = 0.7591500169293337\n",
      "\n",
      "Optimisation finished!\n"
     ]
    }
   ],
   "source": [
    "%run trainRNN_utils.py\n",
    "%run trainRNN_network_utils.py\n",
    "\n",
    "trainLosses = {}\n",
    "testLosses = {}\n",
    "F1_scores = {}\n",
    "trainAccuracy = {}\n",
    "attention_matrixA = {}\n",
    "attention_matrixB = {}\n",
    "tst_prediction = {}\n",
    "\n",
    "# Create network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Gene A and Gene B input and output placeholders\n",
    "## Input placeholders\n",
    "with tf.variable_scope('geneA'):\n",
    "\n",
    "    rSnpRnaA_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum_A + 1, iSnum_A])\n",
    "\n",
    "    hidden_output_A, current_state_A = dynamicLSTM_Attention(rSnpRnaA_pXNS, \n",
    "                                                                 n_layer, \n",
    "                                                                 n_hidden, \n",
    "                                                                 dropout)\n",
    "\n",
    "hidden_state_A = current_state_A[-1].h\n",
    "\n",
    "with tf.variable_scope('geneB'):\n",
    "\n",
    "    rSnpRnaB_pXNS = tf.placeholder(tf.float32, shape = [None, iNnum_A + 1, iSnum_A])\n",
    "\n",
    "    hidden_output_B, current_state_B = dynamicLSTM_Attention(rSnpRnaB_pXNS, \n",
    "                                                                 n_layer, \n",
    "                                                                 n_hidden, \n",
    "                                                                 dropout)\n",
    "\n",
    "hidden_state_B = current_state_B[-1].h\n",
    "\n",
    "rRelated_pXC = tf.placeholder(tf.float32, \n",
    "                              shape = [None, iCnum_A],\n",
    "                              name = 'rRelated_pXC')\n",
    "\n",
    "context_vectorA, attention_weightsA = attention(hidden_state_A, hidden_output_A, n_hidden)\n",
    "context_vectorB, attention_weightsB = attention(hidden_state_B, hidden_output_B, n_hidden)\n",
    "\n",
    "encoding = tf.concat((context_vectorA, context_vectorB), axis=1)\n",
    "\n",
    "# Dense Layer\n",
    "logits = tf.layers.dense(encoding,\n",
    "                        units = n_classes, \n",
    "                        activation = None,\n",
    "                        kernel_regularizer=tf.contrib.layers.l2_regularizer(0.4),\n",
    "                        kernel_initializer = tf.initializers.random_normal() )\n",
    "\n",
    "prediction = tf.argmax(logits, 1)\n",
    "\n",
    "l2 = lambda_l2_reg * sum(\n",
    "    tf.nn.l2_loss(tf_var)\n",
    "        for tf_var in tf.trainable_variables()\n",
    "        if not (\"bias\" in tf_var.name))\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                                     labels=tf.argmax(rRelated_pXC,1)) + l2)\n",
    "\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy; precision, and recall for f1 score\n",
    "correct_pred = tf.equal(prediction, tf.argmax(rRelated_pXC,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Precision and recall\n",
    "rec, rec_op = tf.metrics.recall(labels = tf.argmax(rRelated_pXC, 1), predictions = prediction)\n",
    "pre, pre_op = tf.metrics.precision(labels = tf.argmax(rRelated_pXC, 1), predictions = prediction)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    # Train the network \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    train_f1_score = [None] * n_epoch\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    test_f1_score = []\n",
    "\n",
    "    # Reshape rSnpRnaA_tst_nXSN_H, rRnaA_tst_nXS_H,  rSnpRnaB_tst_nXSN_H, and rRnaB_tst_nXS_H before \n",
    "    # feeding it to the network ( Reason: iSnum_A = 206, iSnum_H = 434). For HBTRC data, randomly select 206\n",
    "    # subjects to align iSnum.\n",
    "    rand_iSnum = np.random.permutation(iSnum_H)[0:206] \n",
    "    rSnpA_tst_nXSN_H_2 = rSnpA_tst_nXSN_H[:, rand_iSnum, :]\n",
    "    rRnaA_tst_nXS_H_2 = rRnaA_tst_nXS_H[:, rand_iSnum]\n",
    "    rSnpB_tst_nXSN_H_2 = rSnpB_tst_nXSN_H[:, rand_iSnum, :]\n",
    "    rRnaB_tst_nXS_H_2 = rRnaB_tst_nXS_H[:, rand_iSnum]\n",
    "\n",
    "    # Reshape and retrive the merged training and test data\n",
    "    rSnpRnaA_tr_nXNS = input_reshape(rSnpA_tr_nXSN_A, rRnaA_tr_nXS_A)\n",
    "    rSnpRnaB_tr_nXNS = input_reshape(rSnpB_tr_nXSN_A, rRnaB_tr_nXS_A)\n",
    "    rSnpRnaA_tst_nXNS = input_reshape(rSnpA_tst_nXSN_H_2, rRnaA_tst_nXS_H_2)\n",
    "    rSnpRnaB_tst_nXNS = input_reshape(rSnpB_tst_nXSN_H_2, rRnaB_tst_nXS_H_2)\n",
    "\n",
    "\n",
    "    for epoch_idx in range(n_epoch): \n",
    "\n",
    "        print(\"Data shuffled.\" + \\\n",
    "              \" Epoch: \", epoch_idx)\n",
    "\n",
    "        # Shuffle classes\n",
    "        rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS = shuffle_classes(rSnpRnaA_tr_nXNS, rSnpRnaB_tr_nXNS)\n",
    "\n",
    "        for batch_idx in range(n_batch):\n",
    "\n",
    "            batch_rSnpRnaA_tXNS = extract_batch_size(rSnpRnaA_tr_nXNS, batch_idx, batch_size)\n",
    "            batch_rSnpRnaB_tXNS = extract_batch_size(rSnpRnaB_tr_nXNS, batch_idx, batch_size)\n",
    "            batch_rRelated_tXC = extract_batch_size(rRelated_tr_nXC_A, batch_idx, batch_size)\n",
    "\n",
    "            # Fit training data\n",
    "            opt, tr_loss, tr_acc = sess.run(\n",
    "                [optimiser, cost, accuracy], \n",
    "                feed_dict = {\n",
    "                    rSnpRnaA_pXNS: batch_rSnpRnaA_tXNS,\n",
    "                    rSnpRnaB_pXNS: batch_rSnpRnaB_tXNS,\n",
    "                    rRelated_pXC: batch_rRelated_tXC               \n",
    "                })\n",
    "\n",
    "            tst_loss, tst_pre, _, tst_rec, _ = sess.run(\n",
    "                [cost, pre, pre_op, rec, rec_op],\n",
    "                feed_dict = {\n",
    "                    rSnpRnaA_pXNS: rSnpRnaA_tst_nXNS,\n",
    "                    rSnpRnaB_pXNS: rSnpRnaB_tst_nXNS,\n",
    "                    rRelated_pXC: rRelated_tst_nXC_H\n",
    "                })            \n",
    "\n",
    "            if batch_idx == (n_batch - 1):\n",
    "\n",
    "                train_losses.append(tr_loss)\n",
    "                train_accuracies.append(tr_acc)\n",
    "\n",
    "                tst_f1_score = 2 * ( tst_rec * tst_pre ) / (tst_rec + tst_pre) \n",
    "\n",
    "                test_losses.append(tst_loss)\n",
    "                test_f1_score.append(tst_f1_score)\n",
    "\n",
    "        print(\"Performance on training data\" + \n",
    "             \": Loss = {}\".format(tr_loss) + \n",
    "             \": Accuracy = {}\".format( tr_acc ) )\n",
    "\n",
    "        print(\"Performance on test set: \" + \n",
    "              \": Loss = {}\".format(tst_loss) + \n",
    "              \": Accuracy = {}\".format(tst_f1_score) )\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "        if epoch_idx == (n_epoch-1):\n",
    "\n",
    "            for i in range(rSnpRnaA_tst_nXNS.shape[0]):\n",
    "                rSnpRnaA_tst_nXNSA = np.expand_dims(rSnpRnaA_tst_nXNS[i], axis=0)\n",
    "                rSnpRnaB_tst_nXNSB = np.expand_dims(rSnpRnaB_tst_nXNS[i], axis=0)\n",
    "                rRelated_tst_nXC_ = np.expand_dims(rRelated_tst_nXC_H[i], axis=0)\n",
    "\n",
    "                pred, at_weightA, at_weightB = sess.run(\n",
    "                    [prediction, attention_weightsA, attention_weightsB],\n",
    "                    feed_dict = {\n",
    "                            rSnpRnaA_pXNS: rSnpRnaA_tst_nXNSA,\n",
    "                            rSnpRnaB_pXNS: rSnpRnaB_tst_nXNSB,\n",
    "                            rRelated_pXC: rRelated_tst_nXC_\n",
    "                            }) \n",
    "\n",
    "                at_weightA = np.reshape(at_weightA, (-1, 1))\n",
    "                at_weightB = np.reshape(at_weightB, (-1, 1))\n",
    "\n",
    "                attention_matrixA[dropout] = at_weightA\n",
    "                attention_matrixB[dropout] = at_weightB                    \n",
    "                tst_prediction[dropout] = pred\n",
    "\n",
    "    trainLosses[dropout] = train_losses\n",
    "    testLosses[dropout] = test_losses\n",
    "    trainAccuracy[dropout] = train_accuracies\n",
    "    F1_scores[dropout] = test_f1_score\n",
    "    print(\"Optimisation finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run trainRNN_plot_utils.py\n",
    "plot_one_input(F1_scores, trainLosses, testLosses, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved into pickle.\n"
     ]
    }
   ],
   "source": [
    "# SAVE DATA\n",
    "# Save the created samples, such tha the NNs can load them easily\n",
    "\n",
    "# Save data into Python file\n",
    "import pickle\n",
    "with open('resultsAttention_ANM_HBTRC.pickle', 'wb') as f:\n",
    "    pickle.dump( rSnpRnaA_tst_nXNS, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( rSnpRnaB_tst_nXNS, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( trainLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( testLosses, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( F1_scores, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( trainAccuracy, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( attention_matrixA, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( attention_matrixB, f, pickle.HIGHEST_PROTOCOL )\n",
    "    pickle.dump( tst_prediction, f, pickle.HIGHEST_PROTOCOL )\n",
    "    print( 'Data saved into pickle.' )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
